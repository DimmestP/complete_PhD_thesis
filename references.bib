@article{JACOB1964,
   author = {F Jacob and A Ullman and J Monod},
   journal = {Comptes rendus hebdomadaires des seances de l'Academie des sciences},
   month = {3},
   pages = {3125-3128},
   title = {Le promoteur, élément génétique nécessaire à l’expression d’un opéron},
   volume = {258},
   url = {https://gallica.bnf.fr/ark:/12148/bpt6k4011c/f713.item},
   year = {1964},
}
@article{Saiki1988,
   abstract = {A thermostable DNA polymerase was used in an in vitro DNA amplification procedure, the polymerase chain reaction. The enzyme, isolated from Thermus aquaticus, greatly simplifies the procedure and, ...},
   author = {Randall K. Saiki and David H. Gelfand and Susanne Stoffel and Stephen J. Scharf and Russell Higuchi and Glenn T. Horn and Kary B. Mullis and Henry A. Erlich},
   doi = {10.1126/SCIENCE.2448875},
   issn = {00368075},
   issue = {4839},
   journal = {Science},
   pages = {487-491},
   pmid = {2448875},
   publisher = {
        American Association for the Advancement of Science
      },
   title = {Primer-Directed Enzymatic Amplification of DNA with a Thermostable DNA Polymerase},
   volume = {239},
   url = {https://www.science.org/doi/10.1126/science.2448875},
   year = {1988},
}
@article{Meselson1968,
   abstract = {An endonuclease which degrades foreign DNA has been isolated. The enzyme requires S-adenosylmethionine, ATP and Mg++.},
   author = {Matthew Meselson and Robert Yuan},
   doi = {10.1038/2171110a0},
   issn = {1476-4687},
   issue = {5134},
   journal = {Nature 1968 217:5134},
   keywords = {Humanities and Social Sciences,Science,multidisciplinary},
   pages = {1110-1114},
   pmid = {4868368},
   publisher = {Nature Publishing Group},
   title = {DNA Restriction Enzyme from E. coli},
   volume = {217},
   url = {https://www.nature.com/articles/2171110a0},
   year = {1968},
}
@article{Arber2003,
   author = {Arber, W and Linn, S},
   title = {DNA Modification and Restriction},
   journal = {Annual Review of Biochemistry},
   volume = {38},
   number = {1},
   pages = {467-500},
   year = {1969},
   doi = {10.1146/annurev.bi.38.070169.002343},
   note ={PMID: 4897066},
   URL = {https://doi.org/10.1146/annurev.bi.38.070169.002343}
}
@article{Kelly1970,
   abstract = {Hemophilus influenzae strain Rd contains an enzyme, endonuolease R, which specifically degrades foreign DNA. With phage T7 DNA as substrate the endonuclease introduces a limited number (about 40) double-strand breaks (5′-phosphoryl, 3′-hydroxyl). The limit product has an average length of about 1000 nucleotide pairs and contains no single-strand breaks. We have explored the nucleotide sequences at the 5′-ends of the limit product by labeling the 5′- phosphoryl groups (using polynucleotide kinase) and characterizing the labeled fragments released by various nucleases. Two classes of 5′-terminal sequences were obtained: pApApCpNp ... (60%) and pGpApCpNp ... (40%), where N indicates that the base in the 4th position is not unique. The dinucleoside monophosphates at the 3′-ends were isolated after micrococcal nuclease digestion of the limit product and identified as TpT(60%) and TpC (40%). We conclude that endonuclease R of H. influenzae recognizes the following specific nucleotide sequence: 5′ ... pGpTpPy |pPupApCp ... 3′ 3′ ... pCpApPup |PypTpGp ... 5′ The implications of the twofold rotational symmetry of this sequence are discussed. © 1970.},
   author = {Thomas J. Kelly and Hamilton O. Smith},
   doi = {10.1016/0022-2836(70)90150-6},
   issn = {0022-2836},
   issue = {2},
   journal = {Journal of Molecular Biology},
   month = {7},
   pages = {393-409},
   pmid = {5312501},
   publisher = {Academic Press},
   title = {A restriction enzyme from Hemophilus influenzae: II. Base sequence of the recognition site},
   volume = {51},
   year = {1970},
}
@article{Smith1970,
   abstract = {Extracts of Hemophilus influenzae strain Rd contain an endonuclease activity which produces a rapid decrease in the specific viscosity of a variety of foreign native DNA's; the specific viscosity of H. influenzae DNA is not altered under the same conditions. This "restriction" endonuclease activity has been purified approximately 200-fold. The purified enzyme contains no detectable exo- or endonucleolytic activity against H. influenzae DNA. However, with native phage T7 DNA as substrate, it produces about 40 double-strand 5′-phosphoryl, 3′-hydroxyl cleavages. The limit product has an average length of about 1000 nucleotide pairs and contains no single-strand breaks. The enzyme is inactive on denatured DNA and it requires no special co-factors other than magnesium ions. © 1970.},
   author = {Hamilton O. Smith and K. W. Welcox},
   doi = {10.1016/0022-2836(70)90149-X},
   issn = {0022-2836},
   issue = {2},
   journal = {Journal of Molecular Biology},
   month = {7},
   pages = {379-391},
   pmid = {5312500},
   publisher = {Academic Press},
   title = {A Restriction enzyme from Hemophilus influenzae: I. Purification and general properties},
   volume = {51},
   year = {1970},
}
@article{Jackson1972,
   abstract = {We have developed methods for covalently joining duplex DNA molecules to one another and have used these techniques to construct circular dimers of SV40 DNA and to insert a DNA segment containing l...},
   author = {David A Jackson and Robert H Symonst and Paul Berg - and Drs Peter Lobban and A D Kaiser},
   doi = {10.1073/PNAS.69.10.2904},
   issn = {00278424},
   issue = {10},
   journal = {Proceedings of the National Academy of Sciences},
   keywords = {DNA joining,genetic transfer,molecular hybrids,viral transformation},
   month = {10},
   pages = {2904-2909},
   pmid = {4342968},
   publisher = {Proceedings of the National Academy of Sciences},
   title = {Biochemical Method for Inserting New Genetic Information into DNA of Simian Virus 40: Circular SV40 DNA Molecules Containing Lambda Phage Genes and the Galactose Operon of Escherichia coli},
   volume = {69},
   url = {https://www.pnas.org/doi/abs/10.1073/pnas.69.10.2904},
   year = {1972},
}
@article{Cohen1973,
   abstract = {The construction of new plasmid DNA species by in vitro joining of restriction endonuclease-generated fragments of separate plasmids is described. Newly constructed plasmids that are inserted into Esch-erichia coli by transformation are shown to be biologically functional replicons that possess genetic properties and nucleotide base sequences from both of the parent DNA molecules. Functional plasmids can be obtained by reassociation of endonuclease-generated fragments of larger replicons, as well as by joining of plasmid DNA molecules of entirely different origins. Controlled shearing of antibiotic resistance (R) factor DNA leads to formation of plasmid DNA segments that can be taken up by appropriately treated Escherichia coli cells and that recircularize to form new, autonomously replicating plasmids (1). One such plasmid that is formed after transformation of E. coli by a fragment of sheared R6-5 DNA, pSC101 (previously referred to as Tc6-5), has a molecular weight of 5.8 X 106, which represents about 10% of the genome of the parent R factor. This plasmid carries genetic information necessary for its own replication and for expression of resistance to tetracycline, but lacks the other drug resistance determinants and the fertility functions carried by R6-5 (1). Two recently described restriction endonucleases, EcoRI and EcoRII, cleave double-stranded DNA so as to produce short overlapping single-stranded ends. The nucleotide sequences cleaved are unique and self-complementary (2-6) so that DNA fragments produced by one of these enzymes can associate by hydrogen-bonding with other fragments produced by the same enzyme. After hydrogen-bonding, the 3'-hydroxyl and 5'-phosphate ends can be joined by DNA ligase (6). Thus, these restriction endonucleases appeared to have great potential value for the construction of new plasmid species by joining DNA molecules from different sources. The EcoRI endonuclease seemed especially useful for this purpose, because on a random basis the sequence cleaved is expected to occur only about once for every 4,000 to 16,000 nucleotide pairs (2); thus, most EcoRI-generated DNA fragments should contain one or more intact genes. We describe here the construction of new plasmid DNA species by in vitro association of the EcoRI-derived DNA fragments from separate plasmids. In one instance a new plasmid has been constructed from two DNA species of entirely different origin, while in another, a plasmid which has itself been derived from EcoRI-generated DNA fragments of a larger parent plasmid genome has been joined to another rep-licon derived independently from the same parent plasmid. Plasmids that have been constructed by the in vitro joining of 3240 EcoRI-generated fragments have been inserted into appropriately treated E. coli by transformation (7) and have been shown to form biologically functional replicons that possess genetic properties and nucleotide base sequences of both parent DNA species. MATERIALS AND METHODS E. coli strain W1485 containing the RSF1010 plasmid, which carries resistance to streptomycin and sulfonamide, was obtained from S. Falkow. Other bacterial strains and R factors and procedures for DNA isolation, electron microscopy, and transformation of E. coli by plasmid DNA have been described (1, 7, 8). Purification and use of the EcoRI restriction endonuclease have been described (5). Plasmid hetero-duplex studies were performed as previously described (9, 10). E. coli DNA ligase was a gift from P. Modrich and R. L. Lehman and was used as described (11). The detailed procedures for gel electrophoresis of DNA will be described elsewhere (Helling, Goodman, and Boyer, in preparation); in brief, duplex DNA was subjected to electrophoresis in a tube-type apparatus (Hoefer Scientific Instrument) (0.6 X 15-cm gel) at about 200 in 0.7% agarose at 22.5 V with 40 mM Tris-acetate buffer (pH 8.05) containing 20 mM sodium acetate , 2 mM EDTA, and 18 mM sodium chloride. The gels were then soaked in ethidium bromide (5 ,g/ml) and the DNA was visualized by fluorescence under long wavelength ultraviolet light ("black light"). The molecular weight of each fragment in the range of 1 to 200 X 105 was determined from its mobility relative to the mobilities of DNA standards of known molecular weight included in the same gel (Helling, Goodman, and Boyer, in preparation). RESULTS R6-5 and pSC101 plasmid DNA preparations were treated with the EcoRI restriction endonuclease, and the resulting DNA products were analyzed by electrophoresis in agarose gels. Photographs of the fluorescing DNA bands derived from these plasmids are presented in Fig. lb and c. Only one band is observed after EcoRI endonucleolytic digestion of pSC101 DNA (Fig. 1c), suggesting that this plasmid has a single site susceptible to cleavage by the enzyme. In addition, endonuclease-treated pSC101 DNA is located at the position in the gel that would be.expected if the covalently closed circular plasmid is cleaved once to form noncircular DNA of the same molecular weight. The molecular weight of the linear fragment estimated from its mobility in the gel is 5.8 X 106, in agreement with independent measurements of the size of the intact molecule (1). Because pSC101 has a single EcoRI cleavage site and is derived from R6-5, the equivalent DNA sequences of},
   author = {S. N. Cohen and A. C.Y. Chang and H. W. Boyer and R. B. Helling},
   doi = {10.1073/PNAS.70.11.3240},
   issn = {00278424},
   issue = {11},
   journal = {Proceedings of the National Academy of Sciences of the United States of America},
   pages = {3240},
   pmid = {4594039},
   publisher = {National Academy of Sciences},
   title = {Construction of Biologically Functional Bacterial Plasmids In Vitro},
   volume = {70},
   url = {/pmc/articles/PMC427208/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC427208/},
   year = {1973},
}
@article{Beggs1978,
   abstract = {Chimaeric plasmids have been constructed containing a yeast plasmid and fragments of yeast nuclear DNA linked to pMB9, a derivative of the ColEl plasmid from E. coli. Two plasmids were isolated which complement leuB mutations in E. coli. These plasmids have been used to develop a method for transforming a leu2 strain of S. cerevisiae to Leu+ with high frequency. The yeast transformants contained multiple plasmid copies which were recovered by transformation in E. coli. The yeast plasmid sequence recombined intramolecularly during propagation in yeast.},
   author = {Jean D. Beggs},
   doi = {10.1038/275104a0},
   issn = {1476-4687},
   issue = {5676},
   journal = {Nature 1978 275:5676},
   keywords = {Humanities and Social Sciences,Science,multidisciplinary},
   month = {9},
   pages = {104-109},
   pmid = {357984},
   publisher = {Nature Publishing Group},
   title = {Transformation of yeast by a replicating hybrid plasmid},
   volume = {275},
   url = {https://www.nature.com/articles/275104a0},
   year = {1978},
}
@article{Capecchi1989,
   abstract = {Homologous recombination between DNA sequences residing in the chromosome and newly introduced, cloned DNA sequences (gene targeting) allows the transfer of any modification of the cloned gene into...},
   author = {Mario R. Capecchi},
   doi = {10.1126/SCIENCE.2660260},
   issn = {00368075},
   issue = {4910},
   journal = {Science},
   pages = {1288-1292},
   pmid = {2660260},
   publisher = {
        American Association for the Advancement of Science
      },
   title = {Altering the Genome by Homologous Recombination},
   volume = {244},
   url = {https://www.science.org/doi/10.1126/science.2660260},
   year = {1989},
}
@article{Gardner2000,
   abstract = {It has been proposed1 that gene-regulatory circuits with virtually any desired property can be constructed from networks of simple regulatory elements. These properties, which include multistability and oscillations, have been found in specialized gene circuits such as the bacteriophage λ switch2 and the Cyanobacteria circadian oscillator3. However, these behaviours have not been demonstrated in networks of non-specialized regulatory components. Here we present the construction of a genetic toggle switch—a synthetic, bistable gene-regulatory network—in Escherichia coli and provide a simple theory that predicts the conditions necessary for bistability. The toggle is constructed from any two repressible promoters arranged in a mutually inhibitory network. It is flipped between stable states using transient chemical or thermal induction and exhibits a nearly ideal switching threshold. As a practical device, the toggle switch forms a synthetic, addressable cellular memory unit and has implications for biotechnology, biocomputing and gene therapy.},
   author = {Timothy S. Gardner and Charles R. Cantor and James J. Collins},
   doi = {10.1038/35002131},
   issn = {1476-4687},
   issue = {6767},
   journal = {Nature 2000 403:6767},
   keywords = {Humanities and Social Sciences,Science,multidisciplinary},
   month = {1},
   pages = {339-342},
   pmid = {10659857},
   publisher = {Nature Publishing Group},
   title = {Construction of a genetic toggle switch in Escherichia coli},
   volume = {403},
   url = {https://www.nature.com/articles/35002131},
   year = {2000},
}
@article{Elowitz2000,
   abstract = {Networks of interacting biomolecules carry out many essential functions in living cells1, but the ‘design principles’ underlying the functioning of such intracellular networks remain poorly understood, despite intensive efforts including quantitative analysis of relatively simple systems2. Here we present a complementary approach to this problem: the design and construction of a synthetic network to implement a particular function. We used three transcriptional repressor systems that are not part of any natural biological clock3,4,5 to build an oscillating network, termed the repressilator, in Escherichia coli. The network periodically induces the synthesis of green fluorescent protein as a readout of its state in individual cells. The resulting oscillations, with typical periods of hours, are slower than the cell-division cycle, so the state of the oscillator has to be transmitted from generation to generation. This artificial clock displays noisy behaviour, possibly because of stochastic fluctuations of its components. Such ‘rational network design’ may lead both to the engineering of new cellular behaviours and to an improved understanding of naturally occurring networks.},
   author = {Michael B. Elowitz and Stanislas Leibier},
   doi = {10.1038/35002125},
   issn = {1476-4687},
   issue = {6767},
   journal = {Nature 2000 403:6767},
   keywords = {Humanities and Social Sciences,Science,multidisciplinary},
   month = {1},
   pages = {335-338},
   pmid = {10659856},
   publisher = {Nature Publishing Group},
   title = {A synthetic oscillatory network of transcriptional regulators},
   volume = {403},
   url = {https://www.nature.com/articles/35002125},
   year = {2000},
}
@article{Knight2003,
   abstract = {DARPA},
   author = {Thomas Knight},
   keywords = {Article,BioBricks,Standard Assembly},
   publisher = {MIT Artificial Intelligence Laboratory; MIT Synthetic Biology Working Group},
   title = {Idempotent Vector Design for Standard Assembly of Biobricks},
   url = {https://dspace.mit.edu/handle/1721.1/21168},
   year = {2003},
}
@article{Krivoruchko2015,
   abstract = {Many high-value metabolites are produced in nature by organisms that are not ideal for large-scale production. Therefore, interest exists in expressing the biosynthetic pathways of these compounds in organisms that are more suitable for industrial production. Recent years have seen developments in both the discovery of various biosynthetic pathways, as well as development of metabolic engineering tools that allow reconstruction of complex pathways in microorganisms. In the present review we discuss recent advances in reconstruction of the biosynthetic pathways of various high-value products in the yeast Saccharomyces cerevisiae, a commonly used industrial microorganism. Key achievements in the production of different isoprenoids, aromatics and polyketides are presented and the metabolic engineering strategies underlying these accomplishments are discussed.},
   author = {Anastasia Krivoruchko and Jens Nielsen},
   doi = {10.1016/J.COPBIO.2014.12.004},
   issn = {0958-1669},
   journal = {Current Opinion in Biotechnology},
   month = {12},
   pages = {7-15},
   pmid = {25544013},
   publisher = {Elsevier Current Trends},
   title = {Production of natural products through metabolic engineering of Saccharomyces cerevisiae},
   volume = {35},
   year = {2015},
}
@article{Wan2019,
   abstract = {Cell-based biosensors have great potential to detect various toxic and pathogenic contaminants in aqueous environments. However, frequently they cannot meet practical requirements due to insufficient sensing performance. To address this issue, we investigated a modular, cascaded signal amplifying methodology. We first tuned intracellular sensory receptor densities to increase sensitivity, and then engineered multi-layered transcriptional amplifiers to sequentially boost output expression level. We demonstrated these strategies by engineering ultrasensitive bacterial sensors for arsenic and mercury, and improved detection limit and output up to 5,000-fold and 750-fold, respectively. Coupled by leakage regulation approaches, we developed an encapsulated microbial sensor cell array for low-cost, portable and precise field monitoring, where the analyte can be readily quantified via displaying an easy-to-interpret volume bar-like pattern. The ultrasensitive signal amplifying methodology along with the background regulation and the sensing platform will be widely applicable to many other cell-based sensors, paving the way for their real-world applications. An engineered biosensor, which optimizes metal-sensing and couples it to transcriptional amplification cascades that produce a fluorescent protein, was applied to build a sensitive and easy-to-use sensor for the toxic metals As3+ and Hg2+.},
   author = {Xinyi Wan and Francesca Volpetti and Ekaterina Petrova and Chris French and Sebastian J. Maerkl and Baojun Wang},
   doi = {10.1038/s41589-019-0244-3},
   issn = {1552-4469},
   issue = {5},
   journal = {Nature Chemical Biology 2019 15:5},
   keywords = {Metals,Synthetic biology,Transcription factors},
   month = {3},
   pages = {540-548},
   pmid = {30911179},
   publisher = {Nature Publishing Group},
   title = {Cascaded amplifying circuits enable ultrasensitive cellular sensors for toxic metals},
   volume = {15},
   url = {https://www.nature.com/articles/s41589-019-0244-3},
   year = {2019},
}
@article{Willardson1998,
   abstract = {A bacterial biosensor for benzene, toluene, and similar compounds has been constructed, characterized, and field tested on contaminated water and soil. The biosensor is based on a plasmid incorporating the transcriptional activator xylR from the TOL plasmid of Pseudomonas putida mt-2. The XylR protein binds a subset of toluene-like compounds and activates transcription at its promoter, P(u). A reporter plasmid was constructed by placing the luc gene for firefly luciferase under the control of XyIR and P(u). When Escherichia coli cells were transformed with this plasmid vector, luminescence from the cells was induced in the presence of benzene, toluene, xylenes, and similar molecules. Accurate concentration dependencies of luminescence were obtained and exhibited K( 1/4 ) values ranging from 39.0 ± 3.8 μM for 3-xylene to 2,690 ± 160 μM for 3-methylbenzylalcohol (means ± standard deviations). The luminescence response was specific for only toluene-like molecules that bind to and activate XyIR. The biosensor cells were field tested on deep aquifer water, for which contaminant levels were known, and were able to accurately detect toluene derivative contamination in this water. The biosensor cells were also shown to detect BETX (benzene, toluene, and xylene) contamination in soil samples. These results demonstrate the capability of such a bacterial biosensor to accurately measure environmental contaminants and suggest a potential for its inexpensive application in field-ready assays.},
   author = {Barry M. Willardson and Jon F. Wilkins and Timothy A. Rand and James M. Schupp and Karen K. Hill and Paul Keim and Paul J. Jackson},
   doi = {10.1128/AEM.64.3.1006-1012.1998/ASSET/BBE3E656-4A9C-4071-8C40-76E1EC68F2B4/ASSETS/GRAPHIC/AM0381236004.JPEG},
   issn = {00992240},
   issue = {3},
   journal = {Applied and Environmental Microbiology},
   pages = {1006-1012},
   pmid = {9501440},
   publisher = {American Society for Microbiology},
   title = {Development and testing of a bacterial biosensor for toluene-based environmental contaminants},
   volume = {64},
   url = {https://journals.asm.org/doi/10.1128/AEM.64.3.1006-1012.1998},
   year = {1998},
}
@article{Tancharoen2019,
   abstract = {Zika virus (ZIKV) is a flavivirus that was first identified in 1947. Initially, the virus was of little concern for health authorities given there were very few casualties among those suffering an infection. As such, only limited studies were performed on ZIKV. Recently, the viral infection has been linked to microcephaly in infants, which has prompted a dramatic increase in scientific interest in ZIKV research, including methods to allow for rapid virus identification. In this work we report the development of a new type of ZIKV electrochemical biosensor based on surface imprinted polymers and graphene oxide composites. The biosensor was used to detect ZIKV by measuring changes in the electrical signal with changing virus concentrations in buffer and serum using standard electrochemical techniques. The detection limit of our method is similar to the detection limit of the real-time quantitative reverse transcription PCR method.},
   author = {Chompoonuch Tancharoen and Wannisa Sukjee and Chutima Thepparit and Thitigun Jaimipuk and Prasert Auewarakul and Arunee Thitithanyanont and Chak Sangma},
   doi = {10.1021/ACSSENSORS.8B00885/SUPPL_FILE/SE8B00885_SI_001.PDF},
   issn = {23793694},
   issue = {1},
   journal = {ACS Sensors},
   keywords = {Zika virus,biosensor,cyclic voltammetry,electrochemical sensor,surface imprinted polymers},
   month = {1},
   pages = {69-75},
   pmid = {30596236},
   publisher = {American Chemical Society},
   title = {Electrochemical Biosensor Based on Surface Imprinting for Zika Virus Detection in Serum},
   volume = {4},
   url = {https://pubs.acs.org/doi/abs/10.1021/acssensors.8b00885},
   year = {2019},
}
@article{Lee2015,
author = {Lee, Michael E. and DeLoache, William C. and Cervantes, Bernardo and Dueber, John E.},
title = {A Highly Characterized Yeast Toolkit for Modular, Multipart Assembly},
journal = {ACS Synthetic Biology},
volume = {4},
number = {9},
pages = {975-986},
year = {2015},

    
},
eprint = { 
    
}

}
@article{Curran2013,
   abstract = {Control of gene and protein expression of both endogenous and heterologous genes is a key component of metabolic engineering. While a large amount of work has been published characterizing promoters for this purpose, less effort has been exerted to elucidate the role of terminators in yeast. In this study, we characterize over 30 terminators for use in metabolic engineering applications in Saccharomyces cerevisiae and determine {mRNA} half-life changes to be the major cause of the varied protein and transcript expression level. We demonstrate that the difference in transcript level can be over 6.5-fold even for high strength promoters. The influence of terminator selection is magnified when coupled with a low-expression promoter, with a maximum difference in protein expression of 11-fold between an expression-enhancing terminator and the parent plasmid terminator and over 35-fold difference when compared with a no-terminator baseline. This is the first time that terminators have been investigated in the context of multiple promoters spanning orders of magnitude in activity. Finally, we demonstrate the utility of terminator selection for metabolic engineering by using a mutant xylose isomerase gene as a proof-of-concept. Through pairing an expression-enhancing terminator with a low-expression promoter, we were able to achieve the same phenotypic result as with a promoter considerably higher in strength. Moreover, we can further boost the phenotype of the high-strength promoter by pairing it with an expression-enhancing terminator. This work highlights how terminator elements can be used to control metabolic pathways in the same way that promoters are traditionally used in yeast. Together, this work demonstrates that terminators will be an important part of heterologous gene expression and metabolic engineering for yeast in the future. © 2013 Elsevier Inc..},
   author = {Kathleen A. Curran and Ashty S. Karim and Akash Gupta and Hal S. Alper},
   issn = {10967176},
   journal = {Metabolic Engineering},
   keywords = {Metabolic engineering,Saccharomyces cerevisiae,Terminator,Yeast},
   month = {9},
   pages = {88-97},
   publisher = {Academic Press},
   title = {Use of expression-enhancing terminators in Saccharomyces cerevisiae to increase {mRNA} half-life and improve gene expression control for metabolic engineering applications},
   volume = {19},
   year = {2013},
}
@article{Garcia2018,
  title={YeastFab: high-throughput genetic parts construction, measurement, and pathway engineering in yeast},
  author={Garcia-Ruiz, Eva and Auxillos, Jamie and Li, Tianyi and Dai, Junbiao and Cai, Yizhi},
  journal={Methods in enzymology},
  volume={608},
  pages={277--306},
  year={2018},
  publisher={Elsevier}
}
@article{Shalem2015,
    author = {Shalem, Ophir AND Sharon, Eilon AND Lubliner, Shai AND Regev, Ifat AND Lotan-Pompan, Maya AND Yakhini, Zohar AND Segal, Eran},
    journal = {PLOS Genetics},
    publisher = {Public Library of Science},
    title = {Systematic Dissection of the Sequence Determinants of Gene 3’ End Mediated Expression Control},
    year = {2015},
    month = {04},
    volume = {11},
    pages = {1-21},
    abstract = {Author Summary We present a large-scale experimental investigation into sequence determinants of 3’ end mediated gene expression regulation, by measuring 13,000 designed 3’ end sequences. While 3’ end sequences contribute to expression differences through a variety of mechanisms including {mRNA} stability and regulation of translation, we find a predominant effect of {mRNA} 3’ end processing efficiency. Using extensive designed mutagenesis analysis we find that out of three functional elements described in the literature as comprising the polyadenylation signal, a single element (known as the efficiency element) is responsible for most of the effect on protein expression levels. Our work highlights the importance of 3’ end processing in expression regulation and facilitates the incorporation of the effect of this region into more complete models of DNA encoded gene expression regulation.},
    number = {4},
}
@article{Sharon2012,
  title={Inferring gene regulatory logic from high-throughput measurements of thousands of systematically designed promoters},
  author={Sharon, Eilon and Kalma, Yael and Sharp, Ayala and Raveh-Sadka, Tali and Levo, Michal and Zeevi, Danny and Keren, Leeat and Yakhini, Zohar and Weinberger, Adina and Segal, Eran},
  journal={Nature biotechnology},
  volume={30},
  number={6},
  pages={521--530},
  year={2012},
  publisher={Nature Publishing Group}
}
@article{Andreou2018,
    author = {Andreou, Andreas I. AND Nakayama, Naomi},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Mobius Assembly: A versatile Golden-Gate framework towards universal {DNA} assembly},
    year = {2018},
    month = {01},
    volume = {13},
    pages = {1-18},
    abstract = {Synthetic biology builds upon the foundation of engineering principles, prompting innovation and improvement in biotechnology via a design-build-test-learn cycle. A community-wide standard in DNA assembly would enable bio-molecular engineering at the levels of predictivity and universality in design and construction that are comparable to other engineering fields. Golden Gate Assembly technology, with its robust capability to unidirectionally assemble numerous DNA fragments in a one-tube reaction, has the potential to deliver a universal standard framework for DNA assembly. While current Golden Gate Assembly frameworks (e.g. MoClo and Golden Braid) render either high cloning capacity or vector toolkit simplicity, the technology can be made more versatile—simple, streamlined, and cost/labor-efficient, without compromising capacity. Here we report the development of a new Golden Gate Assembly framework named Mobius Assembly, which combines vector toolkit simplicity with high cloning capacity. It is based on a two-level, hierarchical approach and utilizes a low-frequency cutter to reduce domestication requirements. Mobius Assembly embraces the standard overhang designs designated by MoClo, Golden Braid, and Phytobricks and is largely compatible with already available Golden Gate part libraries. In addition, dropout cassettes encoding chromogenic proteins were implemented for cost-free visible cloning screening that color-code different cloning levels. As proofs of concept, we have successfully assembled up to 16 transcriptional units of various pigmentation genes in both operon and multigene arrangements. Taken together, Mobius Assembly delivers enhanced versatility and efficiency in DNA assembly, facilitating improved standardization and automation.},
    number = {1},
}
@article{Ui1963,
   abstract = {Previous studies from this laboratory have demonstrated that in the rat uterus the early response to estradiol is characterized by a rapid acceleration of synthetic reactions leading to the accumulation of phospholipid, ribonucleic acid, and protein .1-6 Levels of puromycin which blocked protein synthesis prevented these responses, suggesting that the primary action of this hormone was to accelerate synthesis of rate-limiting enzymes for these anabolic pathways.7 Since it has been demonstrated in other biological systems that the synthesis of specific proteins depends on the antecedent synthesis of new RNA species,8-10 it was of interest to inquire whether or not the early estrogenic response required the synthesis of new RNA. The recent studies of a number of investigators have documented the ability of actinomycin D to block the DNA-dependent synthesis of RNA in cells and in isolated enzyme systems.11-14 This paper will describe the use of this agent to prevent RNA synthesis in the uterus of the intact rat. It will be shown that under conditions in which the synthesis of new RNA was blocked by actinomycin D, the early acceleration of phospholipid and protein synthesis, as well as a major portion of the imbibition of water resulting from in vivo action of estradiol, failed to occur. The requirement for the synthesis of new RNA in the early estrogenic response is discussed. Methods.-Female Holtzman rats of the same age and weighing approximately 180 gm were ovariectomized through the dorsal approach and maintained on a diet of Purina dog chow for at least 3 weeks prior to experimentation. Only rats which were ovariectomized on the same day were used in any one experiment. The rats were injected intraperitoneally with actinomycin D (375 jg in 0.5 ml of 0.154 M NaCI) or with saline alone as indicated in the figures. At zero hr 10 fg of estradiol-17j3 in 1.0 ml of buf-fered saline containing 1% ethanol6 or the control solution of buffered saline and ethanol was injected via the tail vein. To assess the in vivo synthesis of RNA, protein, and phospholipid, a combination of 25 yc of uridine-HI (specific activity = 1.0 mc/0.036 mg) and 6 uc of glycine-2CI4 (specific activity = 1 mc/12.4 mg) dissolved in 0.5 ml of saline was injected intraperitoneally at 2 and 3 hr. In certain experiments only glycine-2C14 was administered. The rats were killed 4 hr after the injection of hormone by decapitation, and the uteri were removed, stripped of accessory fat, and weighed on a Roller-Smith torsion balance. The uteri were then homogenized in cold distilled water, and the resulting dispersion was treated with 4% perchloric acid (PCA) to remove the acid-soluble fraction. The sedimented tissue residue was washed twice with 4% PCA and then was extracted successively with 90% ethanol, absolute ethanol, and twice with anhydrous ethyl ether. The combined ethanol-ether extracts, making up the crude lipid fraction, were counted in a liquid scintillation counter. The tissue residue remaining after ethanol-ether extraction was suspended in 0.01 M Tris (trishydroxymethylaminomethane) buffer at pH 7.4 and incubated at 370C for 30 min with 100 jg of RNAse. The reaction mixture was treated with 4% PCA to obtain the RNAse-released material ; this fraction was counted for H3 content in a liquid scintillation counter. The results were expressed as counts per min (CPM) per uterus. The PCA-insoluble residue was washed successively with 90% ethanol, absolute ethanol, and twice with anhydrous ethyl ether. The residual protein was spread on aluminum planchets with the aid of a small amount of formic acid, and after drying it was counted in a gas flow counter 256},
   author = {H. Ui and G. C. Mueller},
   doi = {10.1073/PNAS.50.2.256},
   issn = {00278424},
   issue = {2},
   journal = {Proceedings of the National Academy of Sciences of the United States of America},
   pages = {256},
   pmid = {14060641},
   publisher = {National Academy of Sciences},
   title = {THE ROLE OF RNA SYNTHESIS IN EARLY ESTROGEN ACTION},
   volume = {50},
   url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC221164/},
   year = {1963},
}
@article{Britten1969,
   abstract = {New facts regarding the organization of the genome provide clues to the nature of gene regulation.},
   author = {Roy J. Britten and Eric H. Davidson},
   doi = {10.1126/SCIENCE.165.3891.349/ASSET/06507E4F-7CB6-4198-AA00-D5F81781B701/ASSETS/SCIENCE.165.3891.349.FP.PNG},
   issn = {00368075},
   issue = {3891},
   journal = {Science},
   month = {7},
   pages = {349-357},
   pmid = {5789433},
   publisher = {
        American Association for the Advancement of Science
      },
   title = {Gene regulation for higher cells: A theory},
   volume = {165},
   url = {https://www.science.org/doi/10.1126/science.165.3891.349},
   year = {1969},
}

@article{Thomas1971,
   author = {C. A. Thomas},
   doi = {10.1146/ANNUREV.GE.05.120171.001321},
   issn = {00664197},
   journal = {Annual Review of Genetics},
   month = {11},
   pages = {237-256},
   pmid = {16097657},
   publisher = { Annual Reviews  4139 El Camino Way, P.O. Box 10139, Palo Alto, CA 94303-0139, USA  },
   title = {THE GENETIC ORGANIZATION OF CHROMOSOMES},
   volume = {5},
   url = {https://www.annualreviews.org/doi/abs/10.1146/annurev.ge.05.120171.001321},
   year = {1971},
}
@article{MIRSKY1951,
   abstract = {The DNA (desoxyribonucleic acid) content per cell, according to some recent investigations, is a constant for the various somatic cells of an organism, and sperm cells contain one-hail this amount per ceU (1, 2). The quantity of DNA per cell is a characteristic of each organism. In this work, done independentiy by two groups of investigators, the DNA per ceLl was found by determining the quantity of DNA in a suspension containing a known number of ceUs and then dividing the total DNA by the number of cells. For sperm and erythrocytes the cells themselves were counted; for tissue cells isolated nuclei were prepared, analyzed, and counted. Knowledge concerning the DNA content per cell has been extended along two lines. On the one hand, more examples have been brought forward. In the original work, for example, the DNA contents of erythrocytes, liver ceUs, and sperm of fowl were determined and DNA determinations for cells of fowl kidney, spleen, heart, and pancreas have now been added by Davidson and his colleagues (3). These results are given in Table I. In a series of careful measurements by Davison and Osgood on human granulocytes and lymphocytes (from leukemic blood), two quite different cell types, the DNA per cell of the former was found to be 6.25 X 10-0 rag. and that of the latter 5.84 × 10-0 rag. (4). Our own determinations on human sperm gave 2.72 X 10-9 mg. per cell, approximately one-half the value for the somatic cells. Another line of investigation has been to determine by a cytochemical procedure the DNA content per nucleus (5). In this procedure it is possible to make determinations on single nuclei, either as isolated cells and nuclei or in tissue sections. It has been found that the Feulgen nucleal reaction gives reproducible results and that a microphotometric observation serves as a measure of DNA content. The essential requirement in this procedure is a standard of known DNA content and heretofore none was available. A whole series of standards was provided by the work mentioned above in which DNA per nucleus was determined chemically. One set of standards consisted of nucleated * Dr. Ris' present address is:},
   author = {A. E. Mirsky and H. Ris},
   doi = {10.1085/JGP.34.4.451},
   issn = {00221295},
   issue = {4},
   journal = {The Journal of General Physiology},
   month = {3},
   pages = {451},
   pmid = {14824511},
   publisher = {The Rockefeller University Press},
   title = {THE DESOXYRIBONUCLEIC ACID CONTENT OF ANIMAL CELLS AND ITS EVOLUTIONARY SIGNIFICANCE},
   volume = {34},
   url = {/pmc/articles/PMC2147229/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2147229/},
   year = {1951},
}
@article{Skelly2009,
   abstract = {Variation in gene expression constitutes an important source of biological variability within and between populations that is likely to contribute significantly to phenotypic diversity. Recent conc...},
   author = {Daniel A. Skelly and James Ronald and Joshua M. Akey},
   doi = {10.1146/ANNUREV-GENOM-082908-150121},
   issn = {15278204},
   journal = {http://dx.doi.org/10.1146/annurev-genom-082908-150121},
   keywords = {allele-specific expression,eQTL,expression heterogeneity,gene expression variation,genetical genomics,microarrays},
   month = {8},
   pages = {313-332},
   pmid = {19630563},
   publisher = { Annual Reviews },
   title = {Inherited Variation in Gene Expression},
   volume = {10},
   url = {https://www.annualreviews.org/doi/abs/10.1146/annurev-genom-082908-150121},
   year = {2009},
}
@article{Hogan2008,
   author = {Daniel J Hogan and Daniel P Riordan and André P Gerber and Daniel Herschlag and Patrick O Brown},
   editor = {Sean R. Eddy},
   issn = {1545-7885},
   issue = {10},
   journal = {PLoS Biology},
   month = {10},
   pages = {e255},
   title = {Diverse {RNA}-Binding Proteins Interact with Functionally Related Sets of {RNA}s, Suggesting an Extensive Regulatory System},
   volume = {6},
   year = {2008},
}
@article{Guo2015,
  title={YeastFab: the design and construction of standard biological parts for metabolic engineering in Saccharomyces cerevisiae},
  author={Guo, Yakun and Dong, Junkai and Zhou, Tong and Auxillos, Jamie and Li, Tianyi and Zhang, Weimin and Wang, Lihui and Shen, Yue and Luo, Yisha and Zheng, Yijing and others},
  journal={Nucleic acids research},
  volume={43},
  number={13},
  pages={e88--e88},
  year={2015},
  publisher={Oxford University Press}
}
@article{Shalgi2005,
   abstract = {BACKGROUND: In recent years, intensive computational efforts have been directed towards the discovery of promoter motifs that correlate with {mRNA} expression profiles. Nevertheless, it is still not always possible to predict steady-state {mRNA} expression levels based on promoter signals alone, suggesting that other factors may be involved. Other genic regions, in particular 3' UTRs, which are known to exert regulatory effects especially through controlling RNA stability and localization, were less comprehensively investigated, and deciphering regulatory motifs within them is thus crucial. RESULTS: By analyzing 3' UTR sequences and {mRNA} decay profiles of Saccharomyces cerevisiae genes, we derived a catalog of 53 sequence motifs that may be implicated in stabilization or destabilization of {mRNA}s. Some of the motifs correspond to known RNA-binding protein sites, and one of them may act in destabilization of ribosome biogenesis genes during stress response. In addition, we present for the first time a catalog of 23 motifs associated with subcellular localization. A significant proportion of the 3' UTR motifs is highly conserved in orthologous yeast genes, and some of the motifs are strikingly similar to recently published mammalian 3' UTR motifs. We classified all genes into those regulated only at transcription initiation level, only at degradation level, and those regulated by a combination of both. Interestingly, different biological functionalities and expression patterns correspond to such classification. CONCLUSION: The present motif catalogs are a first step towards the understanding of the regulation of {mRNA} degradation and subcellular localization, two important processes which--together with transcription regulation--determine the cell transcriptome.},
   author = {Reut Shalgi and Michal Lapidot and Ron Shamir and Yitzhak Pilpel},
   issn = {14656914},
   issue = {10},
   journal = {Genome biology},
   title = {A catalog of stability-associated sequence elements in 3' {UTRs} of yeast {mRNA}s.},
   volume = {6},
   year = {2005},
}
@article{Cheng2017,
   abstract = {The stability of {mRNA} is one of the major determinants of gene expression. Although a wealth of sequence elements regulating {mRNA} stability has been described, their quantitative contributions to half-life are unknown. Here, we built a quantitative model for Saccharomyces cerevisiae based on functional {mRNA} sequence features that explains 59% of the half-life variation between genes and predicts half-life at a median relative error of 30%. The model revealed a new destabilizing 3′′ UTR motif, ATATTC, which we functionally validated. Codon usage proves to be the major determinant of {mRNA} stability. Nonetheless, single-nucleotide variations have the largest effect when occurring on 3′′ UTR motifs or upstream AUGs. Analyzing {mRNA} half-life data of 34 knockout strains showed that the effect of codon usage not only requires functional decapping and deadenylation, but also the 5′′-to-3′′ exonuclease Xrn1, the nonsense-mediated decay genes, but not no-go decay. Altogether, this study quantitatively delineates the contributions of {mRNA} sequence features on stability in yeast, reveals their functional dependencies on degradation pathways, and allows accurate prediction of half-life from {mRNA} sequence.},
   author = {Jun Cheng and Kerstin C. Maier and Žiga Avsec and R. U.S. Petra and Julien Gagneur},
   issn = {14699001},
   issue = {11},
   journal = {RNA},
   keywords = {Cis-regulatory elements,Codon optimality,MRNA half-life},
   month = {11},
   pages = {1648-1659},
   publisher = {Cold Spring Harbor Laboratory Press},
   title = {Cis-regulatory elements explain most of the {mRNA} stability variation across genes in yeast},
   volume = {23},
   year = {2017},
}
@article{Pelechano2013,
   abstract = {Transcript function is determined by sequence elements arranged on an individual RNA molecule. Variation in transcripts can affect messenger RNA stability, localization and translation, or produce truncated proteins that differ in localization or function. Given the existence of overlapping, variable transcript isoforms, determining the functional impact of the transcriptome requires identification of full-length transcripts, rather than just the genomic regions that are transcribed. Here, by jointly determining both transcript ends for millions of RNA molecules, we reveal an extensive layer of isoform diversity previously hidden among overlapping RNA molecules. Variation in transcript boundaries seems to be the rule rather than the exception, even within a single population of yeast cells. Over 26 major transcript isoforms per protein-coding gene were expressed in yeast. Hundreds of short coding RNAs and truncated versions of proteins are concomitantly encoded by alternative transcript isoforms, increasing protein diversity. In addition, approximately 70% of genes express alternative isoforms that vary in post-transcriptional regulatory elements, and tandem genes frequently produce overlapping or even bicistronic transcripts. This extensive transcript diversity is generated by a relatively simple eukaryotic genome with limited splicing, and within a genetically homogeneous population of cells. Our findings have implications for genome compaction, evolution and phenotypic diversity between single cells. These data also indicate that isoform diversity as well as RNA abundance should be considered when assessing the functional repertoire of genomes. © 2013 Macmillan Publishers Limited. All rights reserved.},
   author = {Vicent Pelechano and Wu Wei and Lars M. Steinmetz},
   issn = {00280836},
   issue = {7447},
   journal = {Nature},
   pages = {127-131},
   publisher = {Nature},
   title = {Extensive transcriptional heterogeneity revealed by isoform profiling},
   volume = {497},
   year = {2013},
}
@article{Chan2018,
   abstract = {The cytoplasmic abundance of {mRNA}s is strictly controlled through a balance of production and degradation. Whereas the control of {mRNA} synthesis through transcription has been well characterized, less is known about the regulation of {mRNA} turnover, and a consensus model explaining the wide variations in {mRNA} decay rates remains elusive. Here, we combine non-invasive transcriptome-wide {mRNA} production and stability measurements with selective and acute perturbations to demonstrate that {mRNA} degradation is tightly coupled to the regulation of translation, and that a competition between translation initiation and {mRNA} decay-but not codon optimality or elongation-is the major determinant of {mRNA} stability in yeast. Our refined measurements also reveal a remarkably dynamic transcriptome with an average {mRNA} half-life of only 4.8 min-much shorter than previously thought. Furthermore, global {mRNA} destabilization by inhibition of translation initiation induces a dose-dependent formation of processing bodies in which {mRNA}s can decay over time.},
   author = {Leon Y. Chan and Christopher F. Mugler and Stephanie Heinrich and Pascal Vallotton and Karsten Weis},
   issn = {2050084X},
   journal = {eLife},
   month = {9},
   publisher = {eLife Sciences Publications Ltd},
   title = {Non-invasive measurement of {mRNA} decay reveals translation initiation as the major determinant of {mRNA} stability},
   volume = {7},
   year = {2018},
}
@article{Guo1996,
  title={3'F-end-forming signals of yeast {mRNA}},
  author={Guo, Zijian and Sherman, Fred},
  journal={Trends in biochemical sciences},
  volume={21},
  number={12},
  pages={477--481},
  year={1996},
  publisher={Elsevier}
}
@article{Goedhart2012,
  title={Structure-guided evolution of cyan fluorescent proteins towards a quantum yield of 93\%},
  author={Goedhart, Joachim and Von Stetten, David and Noirclerc-Savoye, Marjolaine and Lelimousin, Micka{\"e}l and Joosen, Linda and Hink, Mark A and Van Weeren, Laura and Gadella, Theodorus WJ and Royant, Antoine},
  journal={Nature communications},
  volume={3},
  number={1},
  pages={1--9},
  year={2012},
  publisher={Nature Publishing Group}
}
@article{Shaner2004,
  title={Improved monomeric red, orange and yellow fluorescent proteins derived from {Discosoma sp.} red fluorescent protein},
  author={Shaner, Nathan C and Campbell, Robert E and Steinbach, Paul A and Giepmans, Ben NG and Palmer, Amy E and Tsien, Roger Y},
  journal={Nature biotechnology},
  volume={22},
  number={12},
  pages={1567--1572},
  year={2004},
  publisher={Nature Publishing Group}
}
@article{Sun2013,
   abstract = {The rates of {mRNA} synthesis and degradation determine cellular {mRNA} levels and can be monitored bycomparative dynamic transcriptome analysis (cDTA) that uses nonperturbing metabolic RNA labeling. Here we present cDTA data for 46 yeast strains lacking genes involved in {mRNA} degradation and metabolism. In these strains, changes in {mRNA} degradation rates are generally compensated by changes in {mRNA} synthesis rates, resulting in a buffering of {mRNA} levels. We show that buffering of {mRNA} levels requires the RNA exonuclease Xrn1. The buffering is rapidly established when {mRNA} synthesis is impaired, but is delayed when {mRNA} degradation is impaired, apparently due to Xrn1-dependent transcription repressor induction. Cluster analysis of the data defines the general {mRNA} degradation machinery, reveals different substrate preferences for the two {mRNA} deadenylase complexes Ccr4-Not and Pan2-Pan3, and unveils an interwoven cellular {mRNA} surveillance network. © 2013 Elsevier Inc.},
   author = {Mai Sun and Björn Schwalb and Nicole Pirkl and Kerstin C. Maier and Arne Schenk and Henrik Failmezger and Achim Tresch and Patrick Cramer},
   issn = {10972765},
   issue = {1},
   journal = {Molecular Cell},
   month = {10},
   pages = {52-62},
   title = {Global analysis of Eukaryotic {mRNA} degradation reveals {Xrn1}-dependent buffering of transcript levels},
   volume = {52},
   year = {2013},
}
@article{Pelechano2016,
   abstract = {5PSeq is a method for studying ribosome dynamics based on co-translational mRNA decay. Genome-wide sequencing and quantification of 5′ phosphorylated mRNA degradation products allows the positions of the last translating ribosomes to be determined. Co-translational mRNA degradation is a widespread process in which 5′–3′ exonucleolytic degradation follows the last translating ribosome, thus producing an in vivo ribosomal footprint that delimits the 5′ position of the mRNA molecule within the ribosome. To study this degradation process and ribosome dynamics, we developed 5PSeq, which is a method that profiles the genome-wide abundance of mRNA degradation intermediates by virtue of their 5′-phosphorylated (5′P) ends. The approach involves targeted ligation of an oligonucleotide to the 5′P end of mRNA degradation intermediates, followed by depletion of rRNA molecules, reverse transcription of 5′P mRNAs and Illumina high-throughput sequencing. 5PSeq can identify translational pauses at rare codons that are often masked when using alternative methods. This approach can be applied to previously extracted RNA samples, and it is straightforward and does not require polyribosome purification or in vitro RNA footprinting. The protocol we describe here can be applied to Saccharomyces cerevisiae and potentially to other eukaryotic organisms. Three days are required to generate 5PSeq libraries.},
   author = {Vicent Pelechano and Wu Wei and Lars M. Steinmetz},
   issn = {1750-2799},
   issue = {2},
   journal = {Nature Protocols 2016 11:2},
   keywords = {RNA decay,RNA sequencing,Translation},
   month = {1},
   pages = {359-376},
   publisher = {Nature Publishing Group},
   title = {Genome-wide quantification of 5'-phosphorylated mRNA degradation intermediates for analysis of ribosome dynamics},
   volume = {11},
   year = {2016},
}
@article{Moll2014,
   abstract = {QuantSeq provides an easy protocol to generate highly strand-specific next-generation sequencing (NGS) libraries close to the 3′ end of polyadenylated RNAs within 4.5 h. Only one fragment per transcript is generated, directly linking the number of reads mapping to a gene to its expression. QuantSeq reduces data analysis time and enables a higher level of multiplexing per run. QuantSeq is the RNA sample preparation method for accurate and affordable gene expression measurement.},
   author = {Pamela Moll and Michael Ante and Alexander Seitz and Torsten Reda},
   issn = {1548-7105},
   issue = {12},
   journal = {Nature Methods 2014 11:12},
   keywords = {Next,RNA sequencing,generation sequencing},
   month = {11},
   pages = {i-iii},
   publisher = {Nature Publishing Group},
   title = {QuantSeq 3' mRNA sequencing for RNA quantification},
   volume = {11},
   year = {2014},
}
@article{Vijayabaskar2019,
   abstract = {Gene expression governs cell fate, and is regulated via a complex interplay of transcription factors and molecules that change chromatin structure. Advances in sequencing-based assays have enabled investigation of these processes genome-wide, leading to large datasets that combine information on the dynamics of gene expression, transcription factor binding and chromatin structure as cells differentiate. While numerous studies focus on the effects of these features on broader gene regulation, less work has been done on the mechanisms of gene-specific transcriptional control. In this study, we have focussed on the latter by integrating gene expression data for the in vitro differentiation of murine ES cells to macrophages and cardiomyocytes, with dynamic data on chromatin structure, epigenetics and transcription factor binding. Combining a novel strategy to identify communities of related control elements with a penalized regression approach, we developed individual models to identify the potential control elements predictive of the expression of each gene. Our models were compared to an existing method and evaluated using the existing literature and new experimental data from embryonic stem cell differentiation reporter assays. Our method is able to identify transcriptional control elements in a gene specific manner that reflect known regulatory relationships and to generate useful hypotheses for further testing.},
   author = {M. S. Vijayabaskar and Debbie K. Goode and Nadine Obier and Monika Lichtinger and Amber M.L. Emmett and Fatin N.Zainul Abidin and Nisar Shar and Rebecca Hannah and Salam A. Assi and Michael Lie-A-Ling and Berthold Gottgens and Georges Lacaud and Valerie Kouskoff and Constanze Bonifer and David R. Westhead},
   issn = {15537358},
   issue = {11},
   journal = {PLoS Computational Biology},
   pages = {e1007337},
   publisher = {Public Library of Science},
   title = {Identification of gene specific cis-regulatory elements during differentiation of mouse embryonic stem cells: An integrative approach using high-throughput datasets},
   volume = {15},
   year = {2019},
}
@article{Kretz2013,
   abstract = {Several of the thousands of human long non-coding RNAs (lncRNAs) have been functionally characterized; however, potential roles for lncRNAs in somatic tissue differentiation remain poorly understood. Here we show that a 3.7-kilobase lncRNA, terminal differentiation-induced ncRNA (TINCR), controls human epidermal differentiation by a post-transcriptional mechanism. TINCR is required for high messenger RNA abundance of key differentiation genes, many of which are mutated in human skin diseases, including FLG, LOR, ALOXE3, ALOX12B, ABCA12, CASP14 and ELOVL3. TINCR-deficient epidermis lacked terminal differentiation ultrastructure, including keratohyalin granules and intact lamellar bodies. Genome-scale RNA interactome analysis revealed that TINCR interacts with a range of differentiation {mRNA}s. TINCR-{mRNA} interaction occurs through a 25-nucleotide 'TINCR box' motif that is strongly enriched in interacting {mRNA}s and required for TINCR binding. A high-throughput screen to analyse TINCR binding capacity to approximately 9,400 human recombinant proteins revealed direct binding of TINCR RNA to the staufen1 (STAU1) protein. STAU1-deficient tissue recapitulated the impaired differentiation seen with TINCR depletion. Loss of UPF1 and UPF2, both of which are required for STAU1-mediated RNA decay, however, did not have differentiation effects. Instead, the TINCR-STAU1 complex seems to mediate stabilization of differentiation {mRNA}s, such as KRT80. These data identify TINCR as a key lncRNA required for somatic tissue differentiation, which occurs through lncRNA binding to differentiation {mRNA}s to ensure their expression. © 2013 Macmillan Publishers Limited. All rights reserved.},
   author = {Markus Kretz and Zurab Siprashvili and Ci Chu and Dan E. Webster and Ashley Zehnder and Kun Qu and Carolyn S. Lee and Ross J. Flockhart and Abigail F. Groff and Jennifer Chow and Danielle Johnston and Grace E. Kim and Robert C. Spitale and Ryan A. Flynn and Grace X.Y. Zheng and Subhadra Aiyer and Arjun Raj and John L. Rinn and Howard Y. Chang and Paul A. Khavari},
   issn = {00280836},
   issue = {7431},
   journal = {Nature},
   keywords = {Differentiation,Long non,Transcriptomics,coding RNAs},
   month = {1},
   pages = {231-235},
   publisher = {Nature Publishing Group},
   title = {Control of somatic tissue differentiation by the long non-coding {RNA TINCR}},
   volume = {493},
   year = {2013},
}
@article{Elemento2007,
   abstract = {Deciphering the noncoding regulatory genome has proved a formidable challenge. Despite the wealth of available gene expression data, there currently exists no broadly applicable method for characterizing the regulatory elements that shape the rich underlying dynamics. We present a general framework for detecting such regulatory DNA and RNA motifs that relies on directly assessing the mutual information between sequence and gene expression measurements. Our approach makes minimal assumptions about the background sequence model and the mechanisms by which elements affect gene expression. This provides a versatile motif discovery framework, across all data types and genomes, with exceptional sensitivity and near-zero false-positive rates. Applications from yeast to human uncover putative and established transcription-factor binding and miRNA target sites, revealing rich diversity in their spatial configurations, pervasive co-occurrences of DNA and RNA motifs, context-dependent selection for motif avoidance, and the strong impact of posttranscriptional processes on eukaryotic transcriptomes. © 2007 Elsevier Inc. All rights reserved.},
   author = {Olivier Elemento and Noam Slonim and Saeed Tavazoie},
   issn = {10972765},
   issue = {2},
   journal = {Molecular Cell},
   keywords = {DNA},
   month = {10},
   pages = {337-350},
   publisher = {Elsevier},
   title = {A Universal Framework for Regulatory Element Discovery across All Genomes and Data Types},
   volume = {28},
   year = {2007},
}
@article{Bailey2015,
   abstract = {The MEME Suite is a powerful, integrated set of webbased tools for studying sequencemotifs in proteins, DNA and RNA. Such motifs encode many biological functions, and their detection and characterization is important in the study of molecular interactions in the cell, including the regulation of gene expression. Since the previous description of the MEME Suite in the 2009 Nucleic Acids Research Web Server Issue, we have added six new tools. Here we describe the capabilities of all the tools within the suite, give advice on their best use and provide several case studies to illustrate how to combine the results of various MEME Suite tools for successful motif-based analyses. The MEME Suite is freely available for academic use at http://meme-suite.org, and source code is also available for download and local installation.},
   author = {Timothy L. Bailey and James Johnson and Charles E. Grant and William S. Noble},
   issn = {13624962},
   issue = {W1},
   journal = {Nucleic Acids Research},
   pages = {W39-W49},
   publisher = {Oxford University Press},
   title = {The {MEME} Suite},
   volume = {43},
   year = {2015},
}
@article{Li2020,
   abstract = {In December 2019, a new coronavirus disease (COVID-19) outbreak occurred in Wuhan, China. Severe acute respiratory syndrome-coronavirus-2 (SARS-CoV-2), which is the seventh coronavirus known to infect humans, is highly contagious and has rapidly expanded worldwide since its discovery. Quantitative nucleic acid testing has become the gold standard for diagnosis and guiding clinical decisions regarding the use of antiviral therapy. However, the RT-qPCR assays targeting SARS-CoV-2 have a number of challenges, especially in terms of primer design. Primers are the pivotal components of a RT-qPCR assay. Once virus mutation and recombination occur, it is difficult to effectively diagnose viral infection by existing RT-qPCR primers. Some primers and probes have also been made available on the WHO website for reference. However, no previous review has systematically compared the previously reported primers and probes and described how to design new primers in the event of a new coronavirus infection. This review focuses on how primers and probes can be designed methodically and rationally, and how the sensitivity and specificity of the detection process can be improved. This brief review will be useful for the accurate diagnosis and timely treatment of the new coronavirus pneumonia.},
   author = {Dandan Li and Jiawei Zhang and Jinming Li},
   doi = {10.7150/THNO.47649},
   issn = {18387640},
   issue = {16},
   journal = {Theranostics},
   keywords = {Coronavirus,Primer design,Quantitative nucleic acid testing,SARS-CoV-2,Sensitivity},
   pages = {7150-7162},
   pmid = {32641984},
   publisher = {Ivyspring International Publisher},
   title = {Primer design for quantitative real-time PCR for the emerging Coronavirus SARS-CoV-2},
   volume = {10},
   year = {2020},
}
@article{Bustin2021,
   abstract = {Although molecular testing, and RT-qPCR in particular, has been an indispensable component in the scientific armoury targeting SARS-CoV-2, there are numerous falsehoods, misconceptions, assumptions and exaggerated expectations with regards to capability, performance and usefulness of the technology. It is essential that the true strengths and limitations, although publicised for at least twenty years, are restated in the context of the current COVID-19 epidemic. The main objective of this commentary is to address and help stop the unfounded and debilitating speculation surrounding its use.},
   author = {Stephen Bustin and Reinhold Mueller and Gregory Shipley and Tania Nolan},
   doi = {10.3390/IJMS22052459},
   issn = {1422-0067},
   issue = {5},
   journal = {International Journal of Molecular Sciences 2021, Vol. 22, Page 2459},
   keywords = {19,2,COVID,CoV,RT,SARS,molecular diagnostics,qPCR,quantification cycle},
   month = {2},
   pages = {2459},
   pmid = {33671091},
   publisher = {Multidisciplinary Digital Publishing Institute},
   title = {COVID-19 and Diagnostic Testing for SARS-CoV-2 by RT-qPCR—Facts and Fallacies},
   volume = {22},
   url = {https://www.mdpi.com/1422-0067/22/5/2459/htm https://www.mdpi.com/1422-0067/22/5/2459},
   year = {2021},
}
@article{Tajadini2014,
   abstract = {BACKGROUND: Progesterone is a steroid hormone that modulates proliferation and differentiation in a cell phase and tissue-specific manner. Its function in breast cancer cells is of great significance since it can predict susceptibility of tumor cells to inhibitory effects of progesterone as adjuvant therapy.\n\nMATERIALS AND METHODS: Stable clones overexpressing cyclin E (EL) and its low molecular weight isoforms (LMW-Es) were generated and treated with various concentrations of progesterone. Cell proliferation was assessed 24 and 48 h after the treatment. Changes in progesterone receptor (PR) expression were measured by real-time polymerase chain reaction.\n\nRESULTS: Here we demonstrated that overexpression of EL and LMW-Es have divergent effects with regard to progesterone response. We found that progesterone could significantly decrease the growth rate of EL-expressing cells in the second cell cycle after treatment; however, progesterone was ineffective to arrest growth of LMW-Es expressing cells. PR expression level was at control level in EL-expressing cells but was downregulatedin LMW-Esexpressing clones.\n\nCONCLUSION: These results were in line with progesterone response of studied cells. The drop in PR expression together with altered distribution of p21 and p27 can explain different effects of cyclin E isoforms expression on progesterone responsivity. These data bring cyclin E status of cancer cells as a marker for predicting the efficacy of progesterone treatment.},
   author = {Mohamadhasan Tajadini and Mojtaba Panjehpour and Shaghayegh Haghjooy Javanmard},
   doi = {10.4103/2277-9175.127998},
   issn = {2277-9175},
   issue = {1},
   journal = {Advanced Biomedical Research},
   keywords = {Quantitative real-time polymerase chain reaction,SYBR Green,TaqMan},
   pages = {85},
   pmid = {24761393},
   publisher = {Wolters Kluwer -- Medknow Publications},
   title = {Comparison of SYBR Green and TaqMan methods in quantitative real-time polymerase chain reaction analysis of four adenosine receptor subtypes},
   volume = {3},
   url = {/pmc/articles/PMC3988599/ /pmc/articles/PMC3988599/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3988599/},
   year = {2014},
}
@article{Holland1991,
   abstract = {The 5′ → 3′ exonuclease activity of the thermostable enzyme Thermus aquatic us DNA polymerase may be employed in a polymerase chain reaction product detection system to generate a specific detectable signal concomitantly with amplification. An oligonucleotide probe, nonextendable at the 3′ end, labeled at the 5′ end, and designed to hybridize within the target sequence, is introduced into the polymerase chain reaction assay. Annealing of probe to one of the polymerase chain reaction product strands during the course of amplification generates a substrate suitable for exonuclease activity. During amplification, the 5′ → 3′ exonuclease activity of T. aquaticus DNA polymerase degrades the probe into smaller fragments that can be differentiated from undegraded probe. The assay is sensitive and specific and is a significant improvement over more cumbersome detection methods.},
   author = {Pamela M. Holland and Richard D. Abramson and Robert Watson and David H. Gelfand},
   doi = {10.1073/PNAS.88.16.7276},
   issn = {00278424},
   issue = {16},
   journal = {Proceedings of the National Academy of Sciences of the United States of America},
   keywords = {Human immunodeficiency virus,Oligonucleotide probe},
   pages = {7276-7280},
   pmid = {1871133},
   publisher = {National Academy of Sciences},
   title = {Detection of specific polymerase chain reaction product by utilizing the 5′ → 3′ exonuclease activity of Thermus aquaticus DNA polymerase},
   volume = {88},
   url = {https://www.pnas.org},
   year = {1991},
}
@article{Schindler2022,
   abstract = {Science across all disciplines has become increasingly data-driven, leading to additional needs with respect to software for collecting, processing and analysingdata. Thus, transparency about software used as part of the scientific process iscrucial to understand provenance of individual research data and insights, is aprerequisite for reproducibility and can enable macro-analysis of the evolution ofscientific methods over time. However, missing rigor in software citation practicesrenders the automated detection and disambiguation of software mentions achallenging problem. In this work, we provide a large-scale analysis of software usageand citation practices facilitated through an unprecedented knowledge graph ofsoftware mentions and affiliated metadata generated through supervised informationextraction models trained on a unique gold standard corpus and applied to more than3 million scientific articles. Our information extraction approach distinguishesdifferent types of software and mentions, disambiguates mentions and outperformsthe state-of-the-art significantly, leading to the most comprehensive corpus of 11.8Msoftware mentions that are described through a knowledge graph consisting of morethan 300 M triples. Our analysis provides insights into the evolution of softwareusage and citation patterns across various fields, ranks of journals, and impact ofpublications. Whereas, to the best of our knowledge, this is the most comprehensiveanalysis of software use and citation at the time, all data and models are sharedpublicly to facilitate further research into scientific use and citation of software},
   author = {David Schindler and Felix Bensmann and Stefan Dietze and Frank Krüger},
   doi = {10.7717/PEERJ-CS.835/SUPP-1},
   issn = {23765992},
   journal = {PeerJ Computer Science},
   keywords = {Knowledge graph,Named entity recognition,Software citation,Software mention,Subjects Data Mining and Machine Learning,World Wide Web and Web Science Keywords Knowledge graph},
   month = {1},
   pages = {e835},
   publisher = {PeerJ},
   title = {The role of software in science: a knowledge graph-based analysis of software mentions in PubMed Central},
   volume = {8},
   url = {https://peerj.com/articles/cs-835},
   year = {2022},
}
@article{Prause2010,
   abstract = {The EU subsidizes research projects in the ICT area with hundreds of millions of Euros per year with the aim of strengthening Europe's global competitiveness. A key requirement of EU projects is the involvement of partners from at least three different countries. This leads to highly distributed software environments where company, country, and culture boundaries run in the midst of tasks like requirements engineering, architectural design, implementation or testing. We present results from an empirical study involving more than 50 transnational, multimillion Euro projects of the Sixth Framework Programme. The results show which tools are accepted by developers and used in practice in the respective phases of the software process. Finally, we shape the idea of Research Software Engineering. © 2010 IEEE.},
   author = {Christian R. Prause and René Reiners and Silviya Dencheva},
   doi = {10.1109/ICGSE.2010.13},
   isbn = {9780769541228},
   journal = {Proceedings - 5th International Conference on Global Software Engineering, ICGSE 2010},
   pages = {23-32},
   publisher = {IEEE Computer Society},
   title = {Empirical study of tool support in highly distributed research projects},
   year = {2010},
}
@article{Mallona2017,
   abstract = {Chainy is a cross-platform web tool providing systematic pipelines and steady criteria to process real-time PCR data, including the calculation of efficiencies from raw data by kinetic methods, evaluation of the suitability of multiple references, standardized normalization using one or more references, and group-wise relative quantification statistical testing. We illustrate the utility of Chainy for differential expression and chromatin immunoprecipitation enrichment (ChIP-QPCR) analysis.},
   author = {Izaskun Mallona and Anna Díez-Villanueva and Berta Martín and Miguel A. Peinado},
   doi = {10.1093/BIOINFORMATICS/BTW839},
   issn = {1367-4803},
   issue = {9},
   journal = {Bioinformatics},
   month = {5},
   pages = {1411-1413},
   pmid = {28453678},
   publisher = {Oxford Academic},
   title = {Chainy: an universal tool for standardized relative quantification in real-time PCR},
   volume = {33},
   url = {https://academic.oup.com/bioinformatics/article/33/9/1411/2840141},
   year = {2017},
}
@article{Forward2002,
   abstract = {This paper highlights the results of a survey of software professionals. One of the goals of this survey was to uncover the perceived relevance (or lack thereof) of software documentation, and the tools and technologies used to maintain, verify and validate such documents. The survey results highlight the preferences for and aversions against software documentation tools. Participants agree that documentation tools should seek to better extract knowledge from core resources. These resources include the system's source code, test code and changes to both. Resulting technologies could then help reduce the effort required for documentation maintenance, something that is shown to rarely occur. Our data reports compelling evidence that software professionals value technologies that improve automation of the documentation process, as well as facilitating its maintenance.},
   author = {Andrew Forward and Timothy C. Lethbridge},
   city = {New York, New York, USA},
   doi = {10.1145/585058.585065},
   isbn = {1581135947},
   journal = {Proceedings of the 2002 ACM symposium on Document engineering  - DocEng '02},
   keywords = {D27 [Distribution,Experimentation,Human Factors,Maintenance,Measurement Keywords Software documentation,and Enhancement]: Docu-mentation General Terms Documentation,documentation relevance,documentation survey,documentation technologies,program comprehension,software engineering,software maintenance},
   pages = {26},
   publisher = {ACM Press},
   title = {The relevance of software documentation, tools and technologies},
   url = {http://portal.acm.org/citation.cfm?doid=585058.585065},
   year = {2002},
}
@article{Aghajani2019,
   abstract = {(Good) Software documentation provides developers and users with a description of what a software system does, how it operates, and how it should be used. For example, technical documentation (e.g., an API reference guide) aids developers during evolution/maintenance activities, while a user manual explains how users are to interact with a system. Despite its intrinsic value, the creation and the maintenance of documentation is often neglected, negatively impacting its quality and usefulness, ultimately leading to a generally unfavourable take on documentation. Previous studies investigating documentation issues have been based on surveying developers, which naturally leads to a somewhat biased view of problems affecting documentation. We present a large scale empirical study, where we mined, analyzed, and categorized 878 documentation-related artifacts stemming from four different sources, namely mailing lists, Stack Overflow discussions, issue repositories, and pull requests. The result is a detailed taxonomy of documentation issues from which we infer a series of actionable proposals both for researchers and practitioners.},
   author = {Emad Aghajani and Csaba Nagy and Olga Lucero Vega-Marquez and Mario Linares-Vasquez and Laura Moreno and Gabriele Bavota and Michele Lanza},
   doi = {10.1109/ICSE.2019.00122},
   isbn = {9781728108698},
   issn = {02705257},
   journal = {Proceedings - International Conference on Software Engineering},
   keywords = {Documentation,Empirical Study},
   month = {5},
   pages = {1199-1210},
   publisher = {IEEE Computer Society},
   title = {Software Documentation Issues Unveiled},
   volume = {2019-May},
   year = {2019},
}
@article{Taschuk2017,
   abstract = {Software produced for research, published and otherwise, suffers from a number of common problems that make it difficult or impossible to run outside the original institution or even off the primary developer’s computer. We present ten simple rules to make such software robust enough to be run by anyone, anywhere, and thereby delight your users and collaborators.},
   author = {Morgan Taschuk and Greg Wilson},
   doi = {10.1371/JOURNAL.PCBI.1005412},
   isbn = {1111111111},
   issn = {1553-7358},
   issue = {4},
   journal = {PLOS Computational Biology},
   keywords = {Bioinformatics,Computer software,Open source software,Operating systems,Reproducibility,Software development,Software engineering,Software tools},
   month = {4},
   pages = {e1005412},
   pmid = {28407023},
   publisher = {Public Library of Science},
   title = {Ten simple rules for making research software more robust},
   volume = {13},
   url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005412},
   year = {2017},
}
@article{Leprevost2014,
   author = {Felipe da Veiga Leprevost and Valmir C. Barbosa and Eduardo L. Francisco and Yasset Perez-Riverol and Paulo C. Carvalho},
   doi = {10.3389/FGENE.2014.00199/BIBTEX},
   issn = {16648021},
   issue = {JUL},
   journal = {Frontiers in Genetics},
   keywords = {Best practices,Bioinformatics,Repository,Source control,Test},
   pages = {199},
   publisher = {Frontiers Research Foundation},
   title = {On best practices in the development of bioinformatics software},
   volume = {5},
   year = {2014},
}
@article{Wilson2017,
   abstract = {Author summary Computers are now essential in all branches of science, but most researchers are never taught the equivalent of basic lab skills for research computing. As a result, data can get lost, analyses can take much longer than necessary, and researchers are limited in how effectively they can work with software and data. Computing workflows need to follow the same practices as lab projects and notebooks, with organized data, documented steps, and the project structured for reproducibility, but researchers new to computing often don't know where to start. This paper presents a set of good computing practices that every researcher can adopt, regardless of their current level of computational skill. These practices, which encompass data management, programming, collaborating with colleagues, organizing projects, tracking work, and writing manuscripts, are drawn from a wide variety of published sources from our daily lives and from our work with volunteer organizations that have delivered workshops to over 11,000 people since 2010.},
   author = {Greg Wilson and Jennifer Bryan and Karen Cranston and Justin Kitzes and Lex Nederbragt and Tracy K. Teal},
   doi = {10.1371/JOURNAL.PCBI.1005510},
   isbn = {1111111111},
   issn = {1553-7358},
   issue = {6},
   journal = {PLOS Computational Biology},
   keywords = {Computer software,Control systems,Data management,Metadata,Programming languages,Reproducibility,Software tools,Source code},
   month = {6},
   pages = {e1005510},
   pmid = {28640806},
   publisher = {Public Library of Science},
   title = {Good enough practices in scientific computing},
   volume = {13},
   url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510},
   year = {2017},
}
@article{Geiger2018,
   abstract = {Computational research and data analytics increasingly relies on complex ecosystems of open source software (OSS) “libraries” – curated collections of reusable code that programmers import to perform a specific task. Software documentation for these libraries is crucial in helping programmers/analysts know what libraries are available and how to use them. Yet documentation for open source software libraries is widely considered low-quality. This article is a collaboration between CSCW researchers and contributors to data analytics OSS libraries, based on ethnographic fieldwork and qualitative interviews. We examine several issues around the formats, practices, and challenges around documentation in these largely volunteer-based projects. There are many different kinds and formats of documentation that exist around such libraries, which play a variety of educational, promotional, and organizational roles. The work behind documentation is similarly multifaceted, including writing, reviewing, maintaining, and organizing documentation. Different aspects of documentation work require contributors to have different sets of skills and overcome various social and technical barriers. Finally, most of our interviewees do not report high levels of intrinsic enjoyment for doing documentation work (compared to writing code). Their motivation is affected by personal and project-specific factors, such as the perceived level of credit for doing documentation work versus more ‘technical’ tasks like adding new features or fixing bugs. In studying documentation work for data analytics OSS libraries, we gain a new window into the changing practices of data-intensive research, as well as help practitioners better understand how to support this often invisible and infrastructural work in their projects.},
   author = {R. Stuart Geiger and Nelle Varoquaux and Charlotte Mazel-Cabasse and Chris Holdgraf},
   doi = {10.1007/S10606-018-9333-1/TABLES/2},
   issn = {15737551},
   issue = {3-6},
   journal = {Computer Supported Cooperative Work: CSCW: An International Journal},
   keywords = {Collaboration,Documentation,Ethnography,Infrastructure,Invisible work,Motivations,Open source,Peer production,Standards},
   month = {12},
   pages = {767-802},
   publisher = {Springer Netherlands},
   title = {The Types, Roles, and Practices of Documentation in Data Analytics Open Source Software Libraries: A Collaborative Ethnography of Documentation Work},
   volume = {27},
   url = {https://link.springer.com/article/10.1007/s10606-018-9333-1},
   year = {2018},
}
@article{ValeroMora2012,
   abstract = {Since R was first launched, it has managed to gain the support of an ever-increasing percentage of academic and professional statisticians. However, the spread of its use among novice and occasional users of statistics have not progressed at the same pace, which can be attributed partially to the lack of a graphical user interface (GUI). Nevertheless, this situation has changed in the last years and there is currently several projects that have added GUIs to R. This article discusses briefly the history of GUIs for data analysis and then introduces the papers submitted to an special issue of the Journal of Statistical Software on GUIs for R.},
   author = {Pedro M. Valero-Mora and Rubén D. Ledesma},
   doi = {10.18637/JSS.V049.I01},
   issn = {1548-7660},
   journal = {Journal of Statistical Software},
   keywords = {GUI,R,Statistical software},
   month = {6},
   pages = {1-8},
   publisher = {American Statistical Association},
   title = {Graphical User Interfaces for R},
   volume = {49},
   url = {https://www.jstatsoft.org/index.php/jss/article/view/v049i01},
   year = {2012},
}
@article{Staggers2000,
   abstract = {Despite the general adoption of graphical users interfaces (GUIs) in health care, few empirical data document the impact of this move on system users. This study compares two distinctly different user interfaces, a legacy text-based interface and a prototype graphical interface, for differences in nurses' response time (RT), errors, and satisfaction when the interfaces are used in the performance of computerized nursing order tasks. In a medical center on the East Coast of the United States, 98 randomly selected male and female nurses completed 40 tasks using each interface. Nurses completed four different types of order tasks (create, activate, modify, and discontinue). Using a repeated-measures and Latin square design, the study was counterbalanced for tasks, interface types, and blocks of trials. Overall, nurses had significantly faster response times (P < 0.0001) and fewer errors (P < 0.0001) using the prototype GUI than the text-based interface. The GUI was also rated significantly higher for satisfaction than the text system, and the GUI was faster to learn (P < 0.0001). Therefore, the results indicated that the use of a prototype GUI for nursing orders significantly enhances user performance and satisfaction. Consideration should be given to redesigning older user interfaces to create more modern ones by using human factors principles and input from user-centered focus groups. Future work should examine prospective nursing interfaces for highly complex interactions in computer-based patient records, detail the severity of errors made on line, and explore designs to optimize interactions in life-critical systems.},
   author = {Nancy Staggers and David Kobus},
   doi = {10.1136/JAMIA.2000.0070164},
   issn = {1067-5027},
   issue = {2},
   journal = {Journal of the American Medical Informatics Association : JAMIA},
   keywords = {Analysis of Variance,Attitude to Computers,Comparative Study,Computer Graphics*,Computerized*,Consumer Behavior*,D Kobus,Female,Humans,MEDLINE,Male,Medical Records Systems,N Staggers,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Non-U.S. Gov't,Nurses,Nursing Care / organization & administration*,PMC61470,PubMed Abstract,Research Support,Time Factors,User-Computer Interface*,doi:10.1136/jamia.2000.0070164,pmid:10730600},
   pages = {164-176},
   pmid = {10730600},
   publisher = {J Am Med Inform Assoc},
   title = {Comparing response time, errors, and satisfaction between text-based and graphical user interfaces during nursing order tasks},
   volume = {7},
   url = {https://pubmed.ncbi.nlm.nih.gov/10730600/},
   year = {2000},
}
@article{Unwin2012,
   abstract = {Graphical user interfaces (GUIs) are gradually becoming more powerful and more accepted. They are the standard way of interacting with the web and play an increasing role in many software applications. Nevertheless, they have not been generally adopted, and critics point to particular weaknesses and disadvantages. Many of these are due more to flaws in design and implementation than to the basic concepts of GUIs. More attention could be paid to what users want to do and how a GUI might be developed to support these goals. Using a dataset about Oscar nominees and winners, this paper considers what analyses statisticians might carry out and what kind of GUI would be appropriate for these tasks. (It also offers some insights into the Oscars dataset.)},
   author = {Antony Unwin},
   doi = {10.18637/JSS.V049.I11},
   issn = {1548-7660},
   journal = {Journal of Statistical Software},
   keywords = {GUI,Iplots,JMP,Mondrian,Oscars},
   month = {6},
   pages = {1-18},
   publisher = {American Statistical Association},
   title = {Oscars and Interfaces},
   volume = {49},
   url = {https://www.jstatsoft.org/index.php/jss/article/view/v049i11},
   year = {2012},
}
@article{Perkins2012,
   abstract = {Background: Measuring gene transcription using real-time reverse transcription polymerase chain reaction (RT-qPCR) technology is a mainstay of molecular biology. Technologies now exist to measure the abundance of many transcripts in parallel. The selection of the optimal reference gene for the normalisation of this data is a recurring problem, and several algorithms have been developed in order to solve it. So far nothing in R exists to unite these methods, together with other functions to read in and normalise the data using the chosen reference gene(s).Results: We have developed two R/Bioconductor packages, ReadqPCR and NormqPCR, intended for a user with some experience with high-throughput data analysis using R, who wishes to use R to analyse RT-qPCR data. We illustrate their potential use in a workflow analysing a generic RT-qPCR experiment, and apply this to a real dataset. Packages are available from http://www.bioconductor.org/packages/release/bioc/html/ReadqPCR.htmland http://www.bioconductor.org/packages/release/bioc/html/NormqPCR.html. Conclusions: These packages increase the repetoire of RT-qPCR analysis tools available to the R user and allow them to (amongst other things) read their data into R, hold it in an ExpressionSet compatible R object, choose appropriate reference genes, normalise the data and look for differential expression between samples. © 2012 Perkins et al.; licensee BioMed Central Ltd.},
   author = {James R. Perkins and John M. Dawes and Steve B. McMahon and David L.H. Bennett and Christine Orengo and Matthias Kohl},
   doi = {10.1186/1471-2164-13-296/FIGURES/4},
   issn = {14712164},
   issue = {1},
   journal = {BMC Genomics},
   keywords = {Animal Genetics and Genomics,Life Sciences,Microarrays,Microbial Genetics and Genomics,Plant Genetics and Genomics,Proteomics,general},
   month = {7},
   pages = {1-8},
   pmid = {22748112},
   publisher = {BioMed Central},
   title = {ReadqPCR and NormqPCR: R packages for the reading, quality checking and normalisation of RT-qPCR quantification cycle (Cq) data},
   volume = {13},
   url = {https://bmcgenomics.biomedcentral.com/articles/10.1186/1471-2164-13-296},
   year = {2012},
}
@article{Baebler2017,
   abstract = {Background: Quantitative molecular biology remains a challenge for researchers due to inconsistent approaches for control of errors in the final results. Due to several factors that can influence the final result, quantitative analysis and interpretation of qPCR data are still not trivial. Together with the development of high-throughput qPCR platforms, there is a need for a tool allowing for robust, reliable and fast nucleic acid quantification. Results: We have developed "quantGenius" ( http://quantgenius.nib.si ), an open-access web application for a reliable qPCR-based quantification of nucleic acids. The quantGenius workflow interactively guides the user through data import, quality control (QC) and calculation steps. The input is machine- and chemistry-independent. Quantification is performed using the standard curve approach, with normalization to one or several reference genes. The special feature of the application is the implementation of user-guided QC-based decision support system, based on qPCR standards, that takes into account pipetting errors, assay amplification efficiencies, limits of detection and quantification of the assays as well as the control of PCR inhibition in individual samples. The intermediate calculations and final results are exportable in a data matrix suitable for further statistical analysis or visualization. We additionally compare the most important features of quantGenius with similar advanced software tools and illustrate the importance of proper QC system in the analysis of qPCR data in two use cases. Conclusions: To our knowledge, quantGenius is the only qPCR data analysis tool that integrates QC-based decision support and will help scientists to obtain reliable results which are the basis for biologically meaningful data interpretation.},
   author = {Špela Baebler and Miha Svalina and Marko Petek and Katja Stare and Ana Rotter and Maruša Pompe-Novak and Kristina Gruden},
   doi = {10.1186/S12859-017-1688-7/FIGURES/5},
   issn = {14712105},
   issue = {1},
   journal = {BMC Bioinformatics},
   keywords = {Decision support system,Nucleic acid quantification,Quantitative PCR,Quantitative molecular biology,Web application},
   month = {5},
   pages = {1-11},
   pmid = {28545393},
   publisher = {BioMed Central Ltd.},
   title = {QuantGenius: Implementation of a decision support system for qPCR-based gene quantification},
   volume = {18},
   url = {https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-017-1688-7},
   year = {2017},
}
@article{Feuer2015,
   abstract = {Background: Gene expression analysis is an essential part of biological and medical investigations. Quantitative real-time PCR (qPCR) is characterized with excellent sensitivity, dynamic range, reproducibility and is still regarded to be the gold standard for quantifying transcripts abundance. Parallelization of qPCR such as by microfluidic Taqman Fluidigm Biomark Platform enables evaluation of multiple transcripts in samples treated under various conditions. Despite advanced technologies, correct evaluation of the measurements remains challenging. Most widely used methods for evaluating or calculating gene expression data include geNorm and ΔΔCt, respectively. They rely on one or several stable reference genes (RGs) for normalization, thus potentially causing biased results. We therefore applied multivariable regression with a tailored error model to overcome the necessity of stable RGs. Results We developed a RG independent data normalization approach based on a tailored linear error model for parallel qPCR data, called LEMming. It uses the assumption that the mean Ct values within samples of similarly treated groups are equal. Performance of LEMming was evaluated in three data sets with different stability patterns of RGs and compared to the results of geNorm normalization. Data set 1 showed that both methods gave similar results if stable RGs are available. Data set 2 included RGs which are stable according to geNorm criteria, but became differentially expressed in normalized data evaluated by a t-test. geN-orm-normalized data showed an effect of a shifted mean per gene per condition whereas LEMming-normalized data did not. Comparing the decrease of standard deviation from raw data to geNorm and to LEMming, the latter was superior. In data set 3 according to geNorm calculated average expression stability and pairwise variation, stable RGs were available, but t-tests of raw data contradicted this. Normalization with RGs resulted in distorted data contradicting literature, while LEMming normalized data did not. Conclusions: If RGs are coexpressed but are not independent of the experimental conditions the stability criteria based on inter- and intragroup variation fail. The linear error model developed, LEMming, overcomes the dependency of using RGs for parallel qPCR measurements, besides resolving biases of both technical and biological nature in qPCR. However, to distinguish systematic errors per treated group from a global treatment effect an additional measurement is needed. Quantification of total cDNA content per sample helps to identify systematic errors.},
   author = {Ronny Feuer and Sebastian Vlaic and Janine Arlt and Oliver Sawodny and Uta Dahmen and Ulrich M. Zanger and Maria Thomas and Lars Kaderali},
   doi = {10.1371/JOURNAL.PONE.0135852},
   issn = {19326203},
   issue = {9},
   journal = {PLoS ONE},
   month = {9},
   pmid = {26325269},
   publisher = {Public Library of Science},
   title = {LEMming: A linear error model to normalize parallel quantitative real-time PCR (qPCR) data as an alternative to reference gene based methods},
   volume = {10},
   year = {2015},
}
@article{Rodiger2015,
   abstract = {There is an ever-increasing number of applications, which use quantitative PCR (qPCR) or digital PCR (dPCR) to elicit fundamentals of biological processes. Moreover, quantitative isothermal amplification (qIA) methods have become more prominent in life sciences and point-of-carediagnostics. Additionally, the analysis of melting data is essential during many experiments. Several software packages have been developed for the analysis of such datasets. In most cases, the software is either distributed as closed source software or as monolithic block with little freedom to perform highly customized analysis procedures. We argue, among others, that R is an excellent foundation for reproducible and transparent data analysis in a highly customizable cross-platform environment. However, for novices it is often challenging to master R or learn capabilities of the vast number of packages available. In the paper, we describe exemplary workflows for the analysis of qPCR, qIA or dPCR experiments including the analysis of melting curve data. Our analysis relies entirely on R packages available from public repositories. Additionally, we provide information related to standardized and reproducible research.},
   author = {Stefan Rödiger and Michał Burdukiewicz and Konstantin Blagodatskikh and Michael Jahn and Peter Schierack},
   doi = {10.32614/RJ-2015-011},
   issn = {20734859},
   issue = {1},
   journal = {R Journal},
   pages = {127-150},
   publisher = {Technische Universitaet Wien},
   title = {R as an environment for reproducible analysis of DNA amplification experiments},
   volume = {7},
   year = {2015},
}
@article{Rodiger2017,
   abstract = {Motivation: Reproducibility, a cornerstone of research, requires defined data formats, which include the setup and output of experiments. The real-time PCR data markup language (RDML) is a recommended standard of the minimum information for publication of quantitative real-time PCR experiments guidelines. Despite the popularity of the RDML format for analysis of quantitative PCR data, handling of RDML files is not yet widely supported in all PCR curve analysis softwares. Results: This study describes the open-source RDML package for the statistical computing language R. RDML is compatible with RDML versions 1.2 and provides functionality to (i) import RDML data; (ii) extract sample information (e.g. targets and concentration); (iii) transform data to various formats of the R environment; (iv) generate human-readable run summaries; and (v) to create RDML files from user data. In addition, RDML offers a graphical user interface to read, edit and create RDML files.},
   author = {Stefan Rödiger and Michal Burdukiewicz and Andrej Nikolai Spiess and Konstantin Blagodatskikh},
   doi = {10.1093/BIOINFORMATICS/BTX528},
   issn = {1367-4803},
   issue = {24},
   journal = {Bioinformatics},
   month = {12},
   pages = {4012-4014},
   pmid = {28961912},
   publisher = {Oxford Academic},
   title = {Enabling reproducible real-time quantitative PCR research: the RDML package},
   volume = {33},
   url = {https://academic.oup.com/bioinformatics/article/33/24/4012/4095640},
   year = {2017},
}
@article{Pabinger2014,
   abstract = {Real-time quantitative polymerase-chain-reaction (qPCR) is a standard technique in most laboratoriesused for various applications in basic research. Analysis of qPCR data is a crucial part of the entire experiment,which has led to the development of a plethora of methods. The released tools either cover specificparts of the workflow or provide complete analysis solutions. Here, we surveyed 27 open-access software packages and tools for the analysis of qPCR data. The surveyincludes 8 Microsoft Windows, 5 web-based, 9 R-based and 5 tools from other platforms. Reviewedpackages and tools support the analysis of different qPCR applications, such as RNA quantification, DNAmethylation, genotyping, identification of copy number variations, and digital PCR. We report an overviewof the functionality, features and specific requirements of the individual software tools, such as dataexchange formats, availability of a graphical user interface, included procedures for graphical data presentation,and offered statistical methods. In addition, we provide an overview about quantificationstrategies, and report various applications of qPCR. Our comprehensive survey showed that most tools use their own file format and only a fraction ofthe currently existing tools support the standardized data exchange format RDML. To allow a morestreamlined and comparable analysis of qPCR data, more vendors and tools need to adapt the standardizedformat to encourage the exchange of data between instrument software, analysis tools, and researchers.},
   author = {Stephan Pabinger and Stefan Rödiger and Albert Kriegner and Klemens Vierlinger and Andreas Weinhäusel},
   doi = {10.1016/J.BDQ.2014.08.002},
   issn = {22147535},
   issue = {1},
   journal = {Biomolecular Detection and Quantification},
   keywords = {Data analysis,MIQE,RDML,Software,Tools,qPCR},
   pages = {23-33},
   publisher = {Elsevier GmbH},
   title = {A survey of tools for the analysis of quantitative PCR (qPCR) data},
   volume = {1},
   year = {2014},
}
@article{Krahenbuhl2019,
   abstract = {The Electronic Laboratory Information and Management Utensil for Molecular Diagnostics (ELIMU-MDx) is a user-friendly platform designed and built to accelerate the turnaround time of diagnostic qPCR assays. ELIMU-MDx is compliant with the MIQE guidelines and has extensive data-import capabilities for all major qPCR instruments by using the RDML data standard. This platform was designed as an open-source software tool and can be accessed through the web browser on all major operating systems. METHOD SUMMARY ELIMU-MDx is an open-source web-application developed using PHP to analyze, manage, validate and store user-provided qPCR data in a MySQL database.},
   author = {Silvan Krähenbühl and Fabian Studer and Etienne Guirou and Anna Deal and Philipp Mächler and Salome Hosch and Maximilian Mpina and Sarah Mswata and Claudia Daubenberger and Tobias Schindler},
   doi = {10.2144/BTN-2019-0064/ASSET/IMAGES/LARGE/FIGURE3.JPEG},
   issn = {19409818},
   issue = {1},
   journal = {BioTechniques},
   keywords = {Diagnostic,ELIMU-MDx,Infectious diseases,MIQE,QPCR,RDML},
   month = {10},
   pages = {22-27},
   pmid = {31588775},
   publisher = {Future Science Ltd},
   title = {ELIMU-MDx: A web-based, open-source platform for storage, management and analysis of diagnostic qPCR data},
   volume = {68},
   url = {https://www.future-science.com/doi/abs/10.2144/btn-2019-0064},
   year = {2019},
}
@article{Rancurel2019,
   abstract = {SATQPCR is a web tool providing statistical analysis of real-time quantitative PCR data including all MIQE rules (gene efficiency, selection of reference genes and normalization with them). Our application is a quick tool that provides to the biologist, graphs as well as statistical tables summarizing their results with the chosen methods (t-test or ANOVA with Tukey test). The application is available at http://satqpcr.sophia.inra.fr with a demo dataset. Source code can be found at https://framagit.org/. Supplementary information: Tutorials at http://satqpcr.sophia.inra.fr/cgi/help.cgi;},
   author = {Corinne Rancurel and T. van Tran and Céline Elie and Frédérique Hilliou},
   doi = {10.1016/J.MCP.2019.07.001},
   issn = {0890-8508},
   journal = {Molecular and Cellular Probes},
   keywords = {Data analysis,MIQE,Real-time quantitative PCR,Statistics,Transcriptomic,Web-application},
   month = {8},
   pages = {101418},
   pmid = {31283967},
   publisher = {Academic Press},
   title = {SATQPCR: Website for statistical analysis of real-time quantitative PCR data},
   volume = {46},
   year = {2019},
}
@article{Bustin2017,
   abstract = {Poorly executed and inadequately reported molecular measurement methods are amongst the causes underlying the lack of reproducibility of much biomedical research. Although several high impact factor journals have acknowledged their past failure to scrutinise adequately the technical soundness of manuscripts, there is a perplexing reluctance to implement basic corrective measures. The reverse transcription real-time quantitative PCR (RT-qPCR) is probably the most straightforward measurement technique available for RNA quantification and is widely used in research, diagnostic, forensic and biotechnology applications. Despite the impact of the minimum information for the publication of quantitative PCR experiments (MIQE) guidelines, which aim to improve the robustness and the transparency of reporting of RT-qPCR data, we demonstrate that elementary protocol errors, inappropriate data analysis and inadequate reporting continue to be rife and conclude that the majority of published RT-qPCR data are likely to represent technical noise.},
   author = {Stephen Bustin and Tania Nolan},
   doi = {10.1111/ECI.12801},
   issn = {1365-2362},
   issue = {10},
   journal = {European Journal of Clinical Investigation},
   keywords = {Gene expression,qPCR,quantification,reverse transcription},
   month = {10},
   pages = {756-774},
   pmid = {28796277},
   publisher = {John Wiley & Sons, Ltd},
   title = {Talking the talk, but not walking the walk: RT-qPCR as a paradigm for the lack of reproducibility in molecular research},
   volume = {47},
   url = {https://onlinelibrary.wiley.com/doi/full/10.1111/eci.12801 https://onlinelibrary.wiley.com/doi/abs/10.1111/eci.12801 https://onlinelibrary.wiley.com/doi/10.1111/eci.12801},
   year = {2017},
}
@article{Courts2019,
   author = {Cornelius Courts and Michael W. Pfaffl and Eva Sauer and Walther Parson},
   doi = {10.1016/J.FSIGEN.2019.06.021},
   issn = {1872-4973},
   journal = {Forensic Science International: Genetics},
   month = {9},
   pages = {e21-e24},
   pmid = {31270013},
   publisher = {Elsevier},
   title = {Pleading for adherence to the MIQE-Guidelines when reporting quantitative PCR data in forensic genetic research},
   volume = {42},
   year = {2019},
}
@article{Zanardi2019,
   abstract = {Reverse transcription quantitative real-time polymerase chain reaction (RT-qPCR) is an accurate and fast method to measure gene expression. Reproducibility of the analyses is the main limitation of RT-qPCR experiments. Galaxy is an open, web-based, genomic workbench for a reproducible, transparent, and accessible science. Our aim was developing a new Galaxy tool for the analysis of RT-qPCR expression data. Our tool was developed using Galaxy workbench version 19.01 and functions implemented in several R packages. We developed PIPE-T, a new Galaxy tool implementing a workflow, which offers several options for parsing, filtering, normalizing, imputing, and analyzing RT-qPCR data. PIPE-T requires two input files and returns seven output files. We tested the ability of PIPE-T to analyze RT-qPCR data on two example datasets available in the gene expression omnibus repository. In both cases, our tool successfully completed execution returning expected results. PIPE-T can be easily installed from the Galaxy main tool shed or from Docker. Source code, step-by-step instructions, and example files are available on GitHub to assist new users to install, execute, and test PIPE-T. PIPE-T is a new tool suitable for the reproducible, transparent, and accessible analysis of RT-qPCR expression data.},
   author = {Nicolò Zanardi and Martina Morini and Marco Antonio Tangaro and Federico Zambelli and Maria Carla Bosco and Luigi Varesio and Alessandra Eva and Davide Cangelosi},
   doi = {10.1038/s41598-019-53155-9},
   issn = {2045-2322},
   issue = {1},
   journal = {Scientific Reports 2019 9:1},
   keywords = {Software,Statistical methods,Transcriptomics},
   month = {11},
   pages = {1-12},
   pmid = {31772190},
   publisher = {Nature Publishing Group},
   title = {PIPE-T: a new Galaxy tool for the analysis of RT-qPCR expression data},
   volume = {9},
   url = {https://www.nature.com/articles/s41598-019-53155-9},
   year = {2019},
}
@article{Ahmed2018,
   abstract = {Background. Real-time quantitative PCR (qPCR) is a broadly used technique in the biomedical research. Currently, few different analysis models are used to determine the quality of data and to quantify the mRNA level across the experimental conditions. Methods. We developed an R package to implement methods for quality assessment, analysis and testing qPCR data for statistical significance. Double Delta CT and standard curve models were implemented to quantify the relative expression of target genes from CT in standard qPCR control-group experiments. In addition, calculation of amplification efficiency and curves from serial dilution qPCR experiments are used to assess the quality of the data. Finally, two-group testing and linear models were used to test for significance of the difference in expression control groups and conditions of interest. Results. Using two datasets from qPCR experiments, we applied different quality assessment, analysis and statistical testing in the pcr package and compared the results to the original published articles. The final relative expression values from the different models, as well as the intermediary outputs, were checked against the expected results in the original papers and were found to be accurate and reliable. Conclusion. The pcr package provides an intuitive and unified interface for its main functions to allow biologist to perform all necessary steps of qPCR analysis and produce graphs in a uniform way.},
   author = {Mahmoud Ahmed and Deok Ryong Kim},
   doi = {10.7717/PEERJ.4473},
   issn = {2167-8359},
   issue = {3},
   journal = {PeerJ},
   keywords = {Deok Ryong Kim,MEDLINE,Mahmoud Ahmed,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,PMC5858653,PubMed Abstract,doi:10.7717/peerj.4473,pmid:29576953},
   pmid = {29576953},
   publisher = {PeerJ},
   title = {pcr: an R package for quality assessment, analysis and testing of qPCR data},
   volume = {6},
   url = {https://pubmed.ncbi.nlm.nih.gov/29576953/},
   year = {2018},
}
@article{OlaecheaLazaro2021,
   abstract = {Background: Quantitative, reverse transcription PCR (qRT-PCR) is currently the gold-standard for SARS-CoV-2 detection and it is also used for detection of other virus. Manual data analysis of a small number of qRT-PCR plates per day is a relatively simple task, but automated, integrative strategies are needed if a laboratory is dealing with hundreds of plates per day, as is being the case in the COVID-19 pandemic. Results: Here we present shinyCurves, an online shiny-based, free software to analyze qRT-PCR amplification data from multi-plate and multi-platform formats. Our shiny application does not require any programming experience and is able to call samples Positive, Negative or Undetermined for viral infection according to a number of user-defined settings, apart from providing a complete set of melting and amplification curve plots for the visual inspection of results. Conclusions: shinyCurves is a flexible, integrative and user-friendly software that speeds-up the analysis of massive qRT-PCR data from different sources, with the possibility of automatically producing and evaluating melting and amplification curve plots.},
   author = {S. Olaechea-Lázaro and I. García-Santisteban and J. R. Pineda and I. Badiola and S. Alonso and Jose Ramon Bilbao and Nora Fernandez-Jimenez},
   doi = {10.1186/S12859-021-04392-1/FIGURES/1},
   issn = {14712105},
   issue = {1},
   journal = {BMC Bioinformatics},
   keywords = {COVID-19,Data analysis,Diagnosis,Medical informatics,Melting and amplification curves,Shiny application,Virology,qRT-PCR},
   month = {12},
   pages = {1-6},
   pmid = {34602053},
   publisher = {BioMed Central Ltd},
   title = {shinyCurves, a shiny web application to analyse multisource qPCR amplification data: a COVID-19 case study},
   volume = {22},
   url = {https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-021-04392-1},
   year = {2021},
}
@article{Ng2021,
   abstract = {Relative quantification is a popular analysis in gene expression studies using quantitative real-time PCR (qPCR). However, the calculation steps using the major algorithms for this analysis are rather complicated. In this study, we developed an easy-to-use spreadsheet-based method for relative quantification. The inputs from end-users are the efficiencies of both target and reference genes and the Cq values of those genes from cases and controls. This method performed normalization (with one or more reference genes), calculation of fold change of gene expression, and statistical analysis to analyze the difference between the groups in a step-by-step manner, which would allow the end-users to understand how the analysis arrived at the conclusion. Four previously published data sets with different experimental designs were used as examples. The calculated results were concordant with the results computed by the Relative Expression Software Tool (REST) 2009, a popular tool for relative quantification. Altogether, our method, which offers easy-to-understand calculation steps and does not require specialized instruments, software, or expertise to operate, would be a useful tool for students, educators, and scientists in the field of molecular biology.},
   author = {Hien Fuh Ng and Yun Fong Ngeow and Abdul Rahman and Malaysia Correspondence and Yun Fong Ngeow},
   doi = {10.1002/BMB.21596},
   issn = {1539-3429},
   journal = {Biochemistry and Molecular Biology Education},
   keywords = {gene expression studies,quantitative real time PCR,relative quantification,spreadsheet},
   publisher = {John Wiley & Sons, Ltd},
   title = {A simple spreadsheet-based method for relative quantification using quantitative real-time PCR},
   url = {https://onlinelibrary.wiley.com/doi/full/10.1002/bmb.21596 https://onlinelibrary.wiley.com/doi/abs/10.1002/bmb.21596 https://iubmb.onlinelibrary.wiley.com/doi/10.1002/bmb.21596},
   year = {2021},
}
@article{Maussion2021,
   abstract = {Quantifying changes in DNA and RNA levels is essential in numerous molecular biology protocols. Quantitative real time PCR (qPCR) techniques have evolved to become commonplace, however, data analysis includes many time-consuming and cumbersome steps, which can lead to mistakes and misinterpretation of data. To address these bottlenecks, we have developed an open-source Python software to automate processing of result spreadsheets from qPCR machines, employing calculations usually performed manually. Auto-qPCR is a tool that saves time when computing qPCR data, helping to ensure reproducibility of qPCR experiment analyses. Our web-based app (
                https://auto-q-pcr.com/
                
              ) is easy to use and does not require programming knowledge or software installation. Using Auto-qPCR, we provide examples of data treatment, display and statistical analyses for four different data processing modes within one program: (1) DNA quantification to identify genomic deletion or duplication events; (2) assessment of gene expression levels using an absolute model, and relative quantification (3) with or (4) without a reference sample. Our open access Auto-qPCR software saves the time of manual data analysis and provides a more systematic workflow, minimizing the risk of errors. Our program constitutes a new tool that can be incorporated into bioinformatic and molecular biology pipelines in clinical and research labs.},
   author = {Gilles Maussion and Rhalena A. Thomas and Iveta Demirova and Gracia Gu and Eddie Cai and Carol X.Q. Chen and Narges Abdian and Theodore J.P. Strauss and Sabah Kelaï and Angela Nauleau-Javaudin and Lenore K. Beitel and Nicolas Ramoz and Philip Gorwood and Thomas M. Durcan},
   doi = {10.1038/s41598-021-99727-6},
   isbn = {0123456789},
   issn = {2045-2322},
   issue = {1},
   journal = {Scientific Reports 2021 11:1},
   keywords = {Bioinformatics,Data processing,PCR,Pluripotent stem cells,Reverse transcription polymerase chain reaction,Software,Stem,Transcriptomics,based techniques,cell differentiation},
   month = {10},
   pages = {1-14},
   pmid = {34716395},
   publisher = {Nature Publishing Group},
   title = {Auto-qPCR; a python-based web app for automated and reproducible analysis of qPCR data},
   volume = {11},
   url = {https://www.nature.com/articles/s41598-021-99727-6},
   year = {2021},
}
@article{Bustin2009,
   abstract = {BACKGROUND: Currently, a lack of consensus exists on how best to perform and interpret quantitative real- time PCR (qPCR) experiments. The problem is exac- erbated by a lack of sufficient experimental detail in many publications, which impedes a reader's ability to evaluate critically the quality of the results presented or to repeat the experiments. CONTENT: The Minimum Information for Publication of Quantitative Real-Time PCR Experiments (MIQE) guidelines target the reliability of results to help ensure the integrity of the scientific literature, promote con- sistency between laboratories, and increase experimen- tal transparency. MIQE is a set of guidelines that de- scribe the minimum information necessary for evaluating qPCR experiments. Included is a checklist to accompany the initial submission of a manuscript to the publisher. By providing all relevant experimental conditions and assay characteristics, reviewers can as- sess the validity of the protocols used. Full disclosure of all reagents, sequences, and analysis methods is neces- sary to enable other investigators to reproduce results. MIQE details should be published either in abbreviated form or as an online supplement. SUMMARY: Following these guidelines will encourage better experimental practice, allowing more reliable and unequivocal interpretation of qPCR results. © 2009 American Association for Clinical Chemistry.},
   author = {Stephen A. Bustin and Vladimir Benes and Jeremy A. Garson and Jan Hellemans and Jim Huggett and Mikael Kubista and Reinhold Mueller and Tania Nolan and Michael W. Pfaffl and Gregory L. Shipley and Jo Vandesompele and Carl T. Wittwer},
   doi = {10.1373/CLINCHEM.2008.112797},
   issn = {1530-8561},
   issue = {4},
   journal = {Clinical chemistry},
   keywords = {Carl T Wittwer,Guideline,Humans,MEDLINE,Molecular Diagnostic Techniques,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Non-U.S. Gov't,Nucleic Acids / chemistry,Nucleic Acids / genetics,Polymerase Chain Reaction / methods*,Polymerase Chain Reaction / standards*,PubMed Abstract,Publishing / standards*,Research Support,Reverse Transcription / genetics,Stephen A Bustin,Terminology as Topic,Time Factors,Vladimir Benes,doi:10.1373/clinchem.2008.112797,pmid:19246619},
   month = {4},
   pages = {611-622},
   pmid = {19246619},
   publisher = {Clin Chem},
   title = {The MIQE guidelines: minimum information for publication of quantitative real-time PCR experiments},
   volume = {55},
   url = {https://pubmed.ncbi.nlm.nih.gov/19246619/},
   year = {2009},
}
@article{Geiger2017,
   abstract = {This report is a high-level summary analysis of the 2017 GitHub Open Source Survey dataset, presenting frequency counts, proportions, and frequency or proportion bar plots for every question asked in the survey.},
   author = {R. Stuart Geiger},
   doi = {10.17605/OSF.IO/ENRQ5},
   month = {6},
   title = {Summary Analysis of the 2017 GitHub Open Source Survey},
   url = {http://arxiv.org/abs/1706.02777 http://dx.doi.org/10.17605/OSF.IO/ENRQ5},
   year = {2017},
}
@article{Dvinge2009,
   abstract = {Motivation: Quantitative real-time polymerase chain reaction (qPCR) is routinely used for RNA expression profiling, validation of microarray hybridization data and clinical diagnostic assays. Although numerous statistical tools are available in the public domain for the analysis of microarray experiments, this is not the case for qPCR. Proprietary software is typically provided by instrument manufacturers, but these solutions are not amenable to the tandem analysis of multiple assays. This is problematic when an experiment involves more than a simple comparison between a control and treatment sample, or when many qPCR datasets are to be analyzed in a high-throughput facility.Results: We have developed HTqPCR, a package for the R statistical computing environment, to enable the processing and analysis of qPCR data across multiple conditions and replicates. © The Author(s) 2009. Published by Oxford University Press.},
   author = {Heidi Dvinge and Paul Bertone},
   doi = {10.1093/BIOINFORMATICS/BTP578},
   issn = {1367-4811},
   issue = {24},
   journal = {Bioinformatics (Oxford, England)},
   keywords = {Computational Biology / methods*,Databases,Gene Expression Profiling,Genetic,Heidi Dvinge,MEDLINE,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Non-U.S. Gov't,PMC2788924,Paul Bertone,Polymerase Chain Reaction / methods*,PubMed Abstract,Research Support,Software*,doi:10.1093/bioinformatics/btp578,pmid:19808880},
   month = {10},
   pages = {3325-3326},
   pmid = {19808880},
   publisher = {Bioinformatics},
   title = {HTqPCR: high-throughput analysis and visualization of quantitative real-time PCR data in R},
   volume = {25},
   url = {https://pubmed.ncbi.nlm.nih.gov/19808880/},
   year = {2009},
}
@article{Ritz2008,
   abstract = {Summary: The qpcR library is an add-on to the free R statistical environment performing sigmoidal model selection in real-time quantitative polymerase chain reaction (PCR) data analysis. Additionally, the package implements the most commonly used algorithms for real-time PCR data analysis and is capable of extensive statistical comparison for the selection and evaluation of the different models based on several measures of goodness of fit. © The Author 2008. Published by Oxford University Press. All rights reserved.},
   author = {Christian Ritz and Andrej Nikolai Spiess},
   doi = {10.1093/BIOINFORMATICS/BTN227},
   issn = {1367-4803},
   issue = {13},
   journal = {Bioinformatics},
   month = {7},
   pages = {1549-1551},
   pmid = {18482995},
   publisher = {Oxford Academic},
   title = {qpcR: an R package for sigmoidal model selection in quantitative real-time polymerase chain reaction analysis},
   volume = {24},
   url = {https://academic.oup.com/bioinformatics/article/24/13/1549/238435},
   year = {2008},
}
@article{Stahlberg2004,
   abstract = {Background: In most measurements of gene expression, mRNA is first reverse-transcribed into cDNA. We studied the reverse transcription reaction and its consequences for quantitative measurements of gene expression. Methods: We used SYBR green I-based quantitative real-time PCR (QPCR) to measure the properties of reverse transcription reaction for the β-tubulin, glyceraldehyde-3-phosphate dehydrogenase, Glut2, CaV1D, and insulin II genes, using random hexamers, oligo(dT), and gene-specific reverse transcription primers. Results: Experimental variation in reverse transcription-QPCR (RT-QPCR) was mainly attributable to the reverse transcription step. Reverse transcription efficiency depended on priming strategy, and the dependence was different for the five genes studied. Reverse transcription yields also depended on total RNA concentration. Conclusions: RT-QPCR gene expression measurements are comparable only when the same priming strategy and reaction conditions are used in all experiments and the samples contain the same total amount of RNA. Experimental accuracy is improved by running samples in (at least) duplicate starting with the reverse transcription reaction. © 2004 American Association for Clinical Chemistry.},
   author = {Anders Ståhlberg and Joakim Håkansson and Xiaojie Xian and Henrik Semb and Mikael Kubista},
   doi = {10.1373/CLINCHEM.2003.026161},
   issn = {0009-9147},
   issue = {3},
   journal = {Clinical Chemistry},
   month = {3},
   pages = {509-515},
   pmid = {14726469},
   publisher = {Oxford Academic},
   title = {Properties of the Reverse Transcription Reaction in mRNA Quantification},
   volume = {50},
   url = {https://academic.oup.com/clinchem/article/50/3/509/5639817},
   year = {2004},
}

@Manual{,
    title = {tm: Text Mining Package},
    author = {Ingo Feinerer and Kurt Hornik},
    year = {2020},
    note = {R package version 0.7-8},
    url = {https://CRAN.R-project.org/package=tm},
}

@Article{,
    title = {Text Mining Infrastructure in R},
    author = {Ingo Feinerer and Kurt Hornik and David Meyer},
    year = {2008},
    journal = {Journal of Statistical Software},
    volume = {25},
    number = {5},
    pages = {1--54},
    url = {https://www.jstatsoft.org/v25/i05/},
    month = {March},
}

@Manual{,
    title = {wordcloud: Word Clouds},
    author = {Ian Fellows},
    year = {2018},
    note = {R package version 2.6},
    url = {https://CRAN.R-project.org/package=wordcloud},
  }
  
@Manual{,
    title = {pluralize: Pluralize and 'Singularize' Any (English) Word},
    author = {Bob Rudis and Blake Embrey},
    year = {2020},
    note = {R package version 0.2.0},
    url = {https://CRAN.R-project.org/package=pluralize},
}
@article{AbdelNour2020,
   abstract = {The Polymerase Chain Reaction (PCR) is the most valuable tool that marked the history of molecular biology since the discovery of the DNA structure by Watson and Crick. Its impact on human health over the last 30 years had lead researchers in the field to put strict rules referred to as the Minimum Information for publication of Quantitative real-time PCR Experiments (MIQE) guidelines since 2009. The aim of the current analysis is to shed light on the practice of applying and citing the original MIQE in the published articles over the last decade. We showed that qPCR is a global technique, but the usage of the MIQE is still lagging in the emerging economies around the globe. We have shown that researchers following the MIQE have better chances of publishing highly cited papers. The MIQE represent the laws for this technique: they enslave us, molecular biologists, into a strict path with financial burdens, but they free us from the “human-errors” a machine would impose on us. As science seeks perfection especially when dealing with human problems, the MIQE, as assessed by the publications' quality over the years, did indeed achieve this step forward towards making the PCR an infallible tool.},
   author = {Afif M. Abdel Nour and Georges Nemer and Athar Khalil},
   doi = {10.1016/J.GENREP.2020.100630},
   issn = {2452-0144},
   journal = {Gene Reports},
   keywords = {CiteSCore,MIQE,qPCR},
   month = {6},
   pages = {100630},
   publisher = {Elsevier},
   title = {The MIQE Guidelines' tenth anniversary: The good and bad students},
   volume = {19},
   year = {2020},
}
@article{Burns2005,
   abstract = {Background: As real-time quantitative PCR (RT-QPCR) is increasingly being relied upon for the enforcement of legislation and regulations dependent upon the trace detection of DNA, focus has increased on the quality issues related to the technique. Recent work has focused on the identification of factors that contribute towards significant measurement uncertainty in the real-time quantitative PCR technique, through investigation of the experimental design and operating procedure. However, measurement uncertainty contributions made during the data analysis procedure have not been studied in detail. This paper presents two additional approaches for standardising data analysis through the novel application of statistical methods to RT-QPCR, in order to minimise potential uncertainty in results. Results: Experimental data was generated in order to develop the two aspects of data handling and analysis that can contribute towards measurement uncertainty in results. This paper describes preliminary aspects in standardising data through the application of statistical techniques to the area of RT-QPCR. The first aspect concerns the statistical identification and subsequent handling of outlying values arising from RT-QPCR, and discusses the implementation of ISO guidelines in relation to acceptance or rejection of outlying values. The second aspect relates to the development of an objective statistical test for the comparison of calibration curves. Conclusions: The preliminary statistical tests for outlying values and comparisons between calibration curves can be applied using basic functions found in standard spreadsheet software. These two aspects emphasise that the comparability of results arising from RT-QPCR needs further refinement and development at the data-handling phase. The implementation of standardised approaches to data analysis should further help minimise variation due to subjective judgements. The aspects described in this paper will help contribute towards the development of a set of best practice guidelines regarding standardising handling and interpretation of data arising from RT-QPCR experiments. © 2005 Burns et al., licensee BioMed Central Ltd.},
   author = {Malcolm J. Burns and Gavin J. Nixon and Carole A. Foy and Neil Harris},
   doi = {10.1186/1472-6750-5-31},
   issn = {1472-6750},
   journal = {BMC biotechnology},
   keywords = {Biotechnology / methods*,Calibration,Clinical Laboratory Techniques,DNA Primers,Data Interpretation,Evaluation Studies as Topic,Gavin J Nixon,Glyceraldehyde-3-Phosphate Dehydrogenase (Phosphorylating) / genetics,Humans,MEDLINE,Malcolm J Burns,Models,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Neil Harris,Non-U.S. Gov't,PMC1326201,PubMed Abstract,Reference Standards,Regression Analysis,Reproducibility of Results,Research Design,Research Support,Reverse Transcriptase Polymerase Chain Reaction / methods*,Sensitivity and Specificity,Software,Statistical,Theoretical,doi:10.1186/1472-6750-5-31,pmid:16336641},
   month = {12},
   pmid = {16336641},
   publisher = {BMC Biotechnol},
   title = {Standardisation of data from real-time quantitative PCR methods - evaluation of outliers and comparison of calibration curves},
   volume = {5},
   url = {https://pubmed.ncbi.nlm.nih.gov/16336641/},
   year = {2005},
}
@article{Lefever2009,
   abstract = {The XML-based Real-Time PCR Data Markup Language (RDML) has been developed by the RDML consortium (http://www.rdml.org) to enable straightforward exchange of qPCR data and related information between qPCR instruments and third party data analysis software, between colleagues and collaborators and between experimenters and journals or public repositories. We here also propose data related guidelines as a subset of the Minimum Information for Publication of Quantitative Real-Time PCR Experiments (MIQE) to guarantee inclusion of key data information when reporting experimental results.},
   author = {Steve Lefever and Jan Hellemans and Filip Pattyn and Daniel R. Przybylski and Chris Taylor and René Geurts and Andreas Untergasser and Jo Vandesompele},
   doi = {10.1093/NAR/GKP056},
   issn = {1362-4962},
   issue = {7},
   journal = {Nucleic acids research},
   keywords = {CollabAuthor(name='RDML consortium',Guidelines as Topic*,Internet,Jan Hellemans,MEDLINE,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Non-U.S. Gov't,PMC2673419,Polymerase Chain Reaction / standards*,PubMed Abstract,Research Support,Software*,Steve Lefever,Terminology as Topic*,affs=[]),doi:10.1093/nar/gkp056,investigators=[],pmid:19223324},
   pages = {2065-2069},
   pmid = {19223324},
   publisher = {Nucleic Acids Res},
   title = {RDML: structured language and reporting guidelines for real-time quantitative PCR data},
   volume = {37},
   url = {https://pubmed.ncbi.nlm.nih.gov/19223324/},
   year = {2009},
}
@article{Ruijter2015,
   abstract = {Background: The universal qPCR data exchange file format RDML is today well accepted by the scientific community, part of the MIQE guidelines and implemented in many qPCR instruments. With the increased use of RDML new challenges emerge. The flexibility of the RDML format resulted in some implementations that did not meet the expectations of the consortium in the level of support or the use of elements. Results: In the current RDML version 1.2 the description of the elements was sharpened. The open source editor RDML-Ninja was released (http://sourceforge.net/projects/qpcr-ninja/). RDML-Ninja allows to visualize, edit and validate RDML files and thus clarifies the use of RDML elements. Furthermore RDML-Ninja serves as reference implementation for RDML and enables migration between RDML versions independent of the instrument software. The database RDMLdb will serve as an online repository for RDML files and facilitate the exchange of RDML data (http://www.rdmldb.org). Authors can upload their RDML files and reference them in publications by the unique identifier provided by RDMLdb. The MIQE guidelines propose a rich set of information required to document each qPCR run. RDML provides the vehicle to store and maintain this information and current development aims at further integration of MIQE requirements into the RDML format. Conclusions: The editor RDML-Ninja and the database RDMLdb enable scientists to evaluate and exchange qPCR data in the instrument-independent RDML format. We are confident that this infrastructure will build the foundation for standardized qPCR data exchange among scientists, research groups, and during publication.},
   author = {Jan M. Ruijter and Steve Lefever and Jasper Anckaert and Jan Hellemans and Michael W. Pfaffl and Vladimir Benes and Stephen A. Bustin and Jo Vandesompele and Andreas Untergasser},
   doi = {10.1186/S12859-015-0637-6},
   issn = {1471-2105},
   issue = {1},
   journal = {BMC bioinformatics},
   keywords = {CollabAuthor(name='RDML consortium',Computer Communication Networks / standards*,Databases,Factual*,Humans,Jan M Ruijter,MEDLINE,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,PMC4474546,Polymerase Chain Reaction / methods*,PubMed Abstract,Software*,Steve Lefever,affs=[]),doi:10.1186/s12859-015-0637-6,investigators=[],pmid:26087842},
   month = {6},
   pmid = {26087842},
   publisher = {BMC Bioinformatics},
   title = {RDML-Ninja and RDMLdb for standardized exchange of qPCR data},
   volume = {16},
   url = {https://pubmed.ncbi.nlm.nih.gov/26087842/},
   year = {2015},
}
@software{Kleinschmidt2022,
author = {Kleinschmidt, N.},
year = {2022},
title = {qpcr - a python module for easy and versatile qPCR data analysis for small-scale datasets and high-throughput},
version = {3.1.5},
url =  {https://github.com/NoahHenrikKleinschmidt/qpcr.git},
}
@article{Kubista2006,
title = {The real-time polymerase chain reaction},
journal = {Molecular Aspects of Medicine},
volume = {27},
number = {2},
pages = {95-125},
year = {2006},
note = {Real-time Polymerase Chain Reaction},
issn = {0098-2997},
doi = {https://doi.org/10.1016/j.mam.2005.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S0098299705000907},
author = {Mikael Kubista and José Manuel Andrade and Martin Bengtsson and Amin Forootan and Jiri Jonák and Kristina Lind and Radek Sindelka and Robert Sjöback and Björn Sjögreen and Linda Strömbom and Anders Ståhlberg and Neven Zoric},
keywords = {Real-time PCR, Gene expression profiling, GenEx, Principal component analysis, PCA, Multidimensional expression profiling},
abstract = {The scientific, medical, and diagnostic communities have been presented the most powerful tool for quantitative nucleic acids analysis: real-time PCR [Bustin, S.A., 2004. A–Z of Quantitative PCR. IUL Press, San Diego, CA]. This new technique is a refinement of the original Polymerase Chain Reaction (PCR) developed by Kary Mullis and coworkers in the mid 80:ies [Saiki, R.K., et al., 1985. Enzymatic amplification of β-globin genomic sequences and restriction site analysis for diagnosis of sickle cell anemia, Science 230, 1350], for which Kary Mullis was awarded the 1993 year’s Nobel prize in Chemistry. By PCR essentially any nucleic acid sequence present in a complex sample can be amplified in a cyclic process to generate a large number of identical copies that can readily be analyzed. This made it possible, for example, to manipulate DNA for cloning purposes, genetic engineering, and sequencing. But as an analytical technique the original PCR method had some serious limitations. By first amplifying the DNA sequence and then analyzing the product, quantification was exceedingly difficult since the PCR gave rise to essentially the same amount of product independently of the initial amount of DNA template molecules that were present. This limitation was resolved in 1992 by the development of real-time PCR by Higuchi et al. [Higuchi, R., Dollinger, G., Walsh, P.S., Griffith, R., 1992. Simultaneous amplification and detection of specific DNA-sequences. Bio-Technology 10(4), 413–417]. In real-time PCR the amount of product formed is monitored during the course of the reaction by monitoring the fluorescence of dyes or probes introduced into the reaction that is proportional to the amount of product formed, and the number of amplification cycles required to obtain a particular amount of DNA molecules is registered. Assuming a certain amplification efficiency, which typically is close to a doubling of the number of molecules per amplification cycle, it is possible to calculate the number of DNA molecules of the amplified sequence that were initially present in the sample. With the highly efficient detection chemistries, sensitive instrumentation, and optimized assays that are available today the number of DNA molecules of a particular sequence in a complex sample can be determined with unprecedented accuracy and sensitivity sufficient to detect a single molecule. Typical uses of real-time PCR include pathogen detection, gene expression analysis, single nucleotide polymorphism (SNP) analysis, analysis of chromosome aberrations, and most recently also protein detection by real-time immuno PCR.}
}
@article{Bustin2002,
   abstract = {The fluorescence-based real-time reverse transcription PCR (RT-PCR) is widely used for the quantification of steady-state mRNA levels and is a critical tool for basic research, molecular medicine and biotechnology. Assays are easy to perform, capable of high throughput, and can combine high sensitivity with reliable specificity. The technology is evolving rapidly with the introduction of new enzymes, chemistries and instrumentation. However, while real-time RT-PCR addresses many of the difficulties inherent in conventional RT-PCR, it has become increasingly clear that it engenders new problems that require urgent attention. Therefore, in addition to providing a snapshot of the state-of-the-art in real-time RT-PCR, this review has an additional aim: it will describe and discuss critically some of the problems associated with interpreting results that are numerical and lend themselves to statistical analysis, yet whose accuracy is significantly affected by reagent and operator variability.},
   author = {S. A. Bustin},
   doi = {10.1677/JME.0.0290023},
   issn = {1479-6813},
   issue = {1},
   journal = {Journal of Molecular Endocrinology},
   month = {8},
   pages = {23-39},
   pmid = {12200227},
   publisher = {BioScientifica},
   title = {Quantification of mRNA using real-time reverse transcription PCR (RT-PCR): trends and problems},
   volume = {29},
   url = {https://jme.bioscientifica.com/view/journals/jme/29/1/23.xml},
   year = {2002},
}
@article{Bustin2013,
   author = {Stephen A. Bustin},
   doi = {10.5772/52844},
   isbn = {978-953-51-1021-7},
   journal = {Recent Advances in Autism Spectrum Disorders - Volume I},
   month = {3},
   publisher = {IntechOpen},
   title = {Why There Is no Link Between Measles Virus and Autism},
   url = {https://www.intechopen.com/chapters/41291},
   year = {2013},
}
@article{Garson2009,
   author = {Jeremy A. Garson and Jim F. Huggett and Stephen A. Bustin and Michael W. Pfaffl and Vladimir Benes and Jo Vandesompele and Gregory L. Shipley},
   doi = {10.1089/AID.2008.0270},
   issn = {08892229},
   issue = {3},
   journal = {https://home.liebertpub.com/aid},
   month = {3},
   pages = {377-378},
   pmid = {19292592},
   publisher = { Mary Ann Liebert, Inc.  140 Huguenot Street, 3rd Floor New Rochelle, NY 10801 USA  },
   title = {Unreliable Real-Time PCR Analysis of Human Endogenous Retrovirus-W (HERV-W) RNA Expression and DNA Copy Number in Multiple Sclerosis},
   volume = {25},
   url = {https://www.liebertpub.com/doi/abs/10.1089/aid.2008.0270},
   year = {2009},
}
@article{Stahlberg2004,
   author = {Anders Ståhlberg and Mikael Kubista and Michael Pfaffl},
   doi = {10.1373/CLINCHEM.2004.035469},
   issn = {0009-9147},
   issue = {9},
   journal = {Clinical chemistry},
   keywords = {5-HT1A / chemistry,5-HT1A / genetics,5-HT1B / chemistry,5-HT1B / genetics,5-HT2B / chemistry,5-HT2B / genetics,Actins / chemistry,Actins / genetics,Anders Ståhlberg,Animals,Cattle,Comparative Study,Gene Expression Profiling / methods*,Glyceraldehyde-3-Phosphate Dehydrogenases / chemistry,Glyceraldehyde-3-Phosphate Dehydrogenases / genetics,MEDLINE,Messenger / chemistry,Messenger / genetics,Michael Pfaffl,Mikael Kubista,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Non-U.S. Gov't,PubMed Abstract,RNA,RNA-Directed DNA Polymerase / chemistry*,Receptor,Research Support,Reverse Transcriptase Polymerase Chain Reaction / methods*,Serotonin,doi:10.1373/clinchem.2004.035469,pmid:15331507},
   month = {9},
   pages = {1678-1680},
   pmid = {15331507},
   publisher = {Clin Chem},
   title = {Comparison of reverse transcriptases in gene expression analysis},
   volume = {50},
   url = {https://pubmed.ncbi.nlm.nih.gov/15331507/},
   year = {2004},
}
@article{Dagnall2017,
   abstract = {Telomeres, long nucleotide repeats and a protein complex at chromosome ends, shorten with each cell division and are susceptible to oxidative damage. Quantitative PCR (qPCR) is a widely-used technique to measure relative telomere length (RTL) in DNA samples but is challenging to optimize and significant lab-to-lab variability has been reported. In this study, we evaluated factors that may contribute to qPCR RTL measurement variability including DNA extraction methods, methods used for removing potential residual PCR inhibitors, sample storage conditions, and sample location in the PCR plate. Our results show that the DNA extraction and purification techniques, as well as sample storage conditions introduce significant variability in qPCR RTL results. We did not find significant differences in results based on sample location in the PCR plate or qPCR instrument used. These data suggest that lack of reproducibility in published association studies of RTL could be, in part, due to methodological inconsistencies. This study illustrates the importance of uniform sample handling, from DNA extraction through data generation and analysis, in using qPCR to determine RTL.},
   author = {Casey L. Dagnall and Belynda Hicks and Kedest Teshome and Amy A. Hutchinson and Shahinaz M. Gadalla and Payal P. Khincha and Meredith Yeager and Sharon A. Savage},
   doi = {10.1371/JOURNAL.PONE.0184098},
   isbn = {1111111111},
   issn = {1932-6203},
   issue = {9},
   journal = {PLOS ONE},
   keywords = {DNA extraction,DNA purification,Extraction techniques,Polymerase chain reaction,Purification techniques,Reproducibility,Specimen storage,Telomere length},
   month = {9},
   pages = {e0184098},
   pmid = {28886139},
   publisher = {Public Library of Science},
   title = {Effect of pre-analytic variables on the reproducibility of qPCR relative telomere length measurement},
   volume = {12},
   url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0184098},
   year = {2017},
}
@article{Williams1992,
   abstract = {DNA amplification utilizing the poly-merase chain reaction (PCR) has greatly enhanced the ability to detect the presence of rare mRNA species in cells. By employing specific sense and antisense oligonucleotide primers with thermo-stable DNA polymerase, PCR allows amplification of target sequences by several log orders of magnitude. (l'z) This technique is being used increasingly to quantify rare mRNA species from cells. (3-6) In these studies, it is critical that the initial cDNA synthesis step be well controlled and optimized to produce a uniform substrate for amplification. We have examined RNA concentration in the initial cDNA synthesis reaction to optimize it for PCR amplification of both high-and low-abundance messages. MATERIALS AND METHODS Cells Jurkat cells (kindly provided by G. Gaul-ton, Department of Pathology, University of Pennsylvania School of Medicine) were grown in RPMI-1640 with added penicillin/streptomycin, L-glu-tamine, and 10% fetal calf serum, and passaged twice weekly prior to use. RNA Isolation and cDNA Synthesis Cells were centrifuged (1200 rpm/10 min) and lysed in GITC-containing lysis buffer (4 M guanidine isothiocyanate, 0.5% N-lauroyl sarcosyl, 25 mM sodium citrate, 0.1 M [3-mercaptoethanol). The lysate was extracted once with phenol, once with phenol/chloroform/isoamyl alcohol, and RNA-precipitated in 50% EtOH. The RNA pellet was resuspended in 50 ~l diethylpyrocarbonate (DEP)-treated water, analyzed by agarose gel electrophoresis, and quantified spectro-photometrically (OD26o). Varying concentrations of RNA were utilized to synthesize cDNA with random priming in the following reaction mixture of 20 ~1: 200 or 400 units of Moloney murine leu-kemia virus reverse transcriptase with a 1:5 dilution of 5x reverse transcriptase buffer (includes dithiothreitol), and 4 units of RNase inhibitor (all from GIBCO/BRL, Gaithersburg, MD), 0.6 or 1.2 ~g of random oligonucleotides (mostly hexamers) (from Pharmacia LKB Biotechnology, Piscataway, NJ), and 0.5 or 1 mM dNTPs (equimolar in each dNTP, from Boehringer Mannheim GmbH, Germany). Following a 10-min preincubation at 25~ the reaction was carried out for 1 hr at 42~ then 95~ for 5 min, followed by storage at-20~ until use. DNA Amplification cDNA was amplified utilizing Thermus aquaticus DNA polymerase (Taq poly-merase) and standard reaction conditions suggested by the manufacturer (Perkin-Elmer Cetus Corp., Norwalk, CT). If cDNA was used directly, it was diluted at least 1:20 in the PCR reaction, thereby minimizing the concentration of reagents from the cDNA synthesis step. The reaction mixture (25 ~l) contained a 1:10 dilution of 10x reaction buffer, dNTPs (final concentration 200 ~M in each dNTP), 1 ~l of each oligonu-cleotide primer at 20 ~M (final concentration 0.8 ~M in each primer), and 1.25 ~l of cDNA. This was heated to 95~ for 5 min prior to the addition of MgC12 (2.5 mM final concentration) and 1 unit of Taq polymerase. Primers were synthesized by the Wistar Institute oligonucle-otide synthesis facility. The samples were covered with a drop of mineral oil, and amplified with a Programmable Thermal Cycler (MJ Research, Water-town, MA). This program was: melting at 94~ for 3 min; 15 cycles of melting at 94~ for 1 min, annealing at 60~ for 1 min, elongation at 72~ for 1 min; 15 cycles of melting at 94~ for 1 min, an-nealing at 60~ for 1.5 min, elongation at 72~ for 2 min; final elongation at 72~ for 7 rain; cooling to 4~ The reaction products were run on a 3% agarose gel, stained with ethidium bromide, and photographed under UV light. RESULTS Primers The primers utilized for a low-abundance message were derived from the sequence of the human c-myc oncogene. (3) The sequences are: c-rnyc 5' 1763 GCTTCTCAGAGGCTFGG 1779 c-rnyc 3' 2205 CGTCTAAGCAGCTGCAAG 2188 The primers utilized for a highly expressed message were derived from the sequences of human and murine ~/-ac-tin. (7-9) These sequences were aligned for maximal homology utilizing the programs Wordsearch and Segments. ~176 86 PCR Methods andAppllcatJons 2:86-888 9 by Cold Spring Harbor Laboratory ISSN 1054-9803/92 $3.00 Cold Spring Harbor Laboratory Press on September 12, 2022-Published by genome.cshlp.org Downloaded from},
   author = {William V Williams and Helga Rosenbaum and David B Weiner},
   issue = {2},
   journal = {Genome Res},
   pages = {86-88},
   title = {Technical Effect of RNA Concentration on cDNA Synthesis for DNA Amplification},
   year = {1992},
}
@article{Brooks1995,
   abstract = {The secondary structure in mRNA is essential for many processes, but it can present a technical problem in making full-length cDNA with reverse transcriptases. Furthermore, different reverse transcriptases have differing abilities to transcribe through regions with secondary structure, which can alter the products obtained by reverse-transcribing RNA and then PCR- amplifying the product (RT-PCR). We have been interested in studying the posttranscriptional regulation of epidermal growth factor by RT-PCR and have tested the ability of several reverse transcriptases to reverse transcribe the 3'-untranslated region (3'UTR), a region that contains substantial secondary structure. When low levels of either total RNA or poly(A)+ mRNA were used, we found avian myeloblastosis virus reverse transcriptase (AMV- RT) to be the most robust of all the enzymes tested. Furthermore, contrary to reports that AMV-RT is inhibited by tRNA-which should make it less effective than Moloney murine leukemia virus reverse transcriptase (MMLV-RT) at reverse transcribing total RNA-adding tRNA to poly(A)+ RNA actually increased the amount of specific RT-PCR actually increased the amount of specific RT-PCR product obtained with AMV-RT while it decreased the amount of product and enhanced mispriming with MMLV-RT. We found that pre-incubation of the oligo(dT) primer with total RNA at elevated temperature prior to reverse transcription improved the efficiency of both native and modified MMLV-RTs. These findings support the concept that secondary structures in RNA differentially affect the abilities of different reverse transcriptases to detect transcript diversity and raise the possibility that such structures could affect quantitation using RT-PCR with internal mRNA standards.},
   author = {E. M. Brooks and L. G. Sheflin and S. W. Spaulding},
   issn = {0736-6205},
   issue = {5},
   journal = {Biotechniques},
   keywords = {Europe PMC,Europe PubMed Central,ORCIDs,REST APIs,abstracts,bioinformatics,biological patents,biomedical journals,biomedical research,citation networks,citation search,clinical guidelines,full text,journal articles,life sciences,literature search,open access,research articles,text mining},
   month = {11},
   pages = {806-12, 814},
   pmid = {8588921},
   title = {Secondary structure in the 3' UTR of EGF and the choice of reverse transcriptases affect the detection of message diversity by RT-PCR.},
   volume = {19},
   url = {https://europepmc.org/article/med/8588921},
   year = {1995},
}
@article{Eisenberg2015,
   abstract = {Objectives: Telomere length (TL) is commonly measured using quantitative PCR (qPCR). Although, easier than the southern blot of terminal restriction fragments (TRF) TL measurement method, one drawback of qPCR is that it introduces greater measurement error and thus reduces the statistical power of analyses. To address a potential source of measurement error, we consider the effect of well position on qPCR TL measurements. Methods: qPCR TL data from 3,638 people run on a Bio-Rad iCycler iQ are reanalyzed here. To evaluate measurement validity, correspondence with TRF, age, and between mother and offspring are examined. Results: First, we present evidence for systematic variation in qPCR TL measurements in relation to thermocycler well position. Controlling for these well-position effects consistently improves measurement validity and yields estimated improvements in statistical power equivalent to increasing sample sizes by 16%. We additionally evaluated the linearity of the relationships between telomere and single copy gene control amplicons and between qPCR and TRF measures. We find that, unlike some previous reports, our data exhibit linear relationships. We introduce the standard error in percent, a superior method for quantifying measurement error as compared to the commonly used coefficient of variation. Using this measure, we find that excluding samples with high measurement error does not improve measurement validity in our study. Conclusions: Future studies using block-based thermocyclers should consider well position effects. Since additional information can be gleaned from well position corrections, rerunning analyses of previous results with well position correction could serve as an independent test of the validity of these results.},
   author = {Dan T.A. Eisenberg and Christopher W. Kuzawa and M. Geoffrey Hayes},
   doi = {10.1002/AJHB.22690},
   issn = {1520-6300},
   issue = {4},
   journal = {American Journal of Human Biology},
   month = {7},
   pages = {570-575},
   pmid = {25757675},
   publisher = {John Wiley & Sons, Ltd},
   title = {Improving qPCR telomere length assays: Controlling for well position effects increases statistical power},
   volume = {27},
   url = {https://onlinelibrary.wiley.com/doi/full/10.1002/ajhb.22690 https://onlinelibrary.wiley.com/doi/abs/10.1002/ajhb.22690 https://onlinelibrary.wiley.com/doi/10.1002/ajhb.22690},
   year = {2015},
}

@article{Wickham2011,
   abstract = {Many data analysis problems involve the application of a split-apply-combine strategy, where you break up a big problem into manageable pieces, operate on each piece independently and then put all the pieces back together. This insight gives rise to a new R package that allows you to smoothly apply this strategy, without having to worry about the type of structure in which your data is stored.

The paper includes two case studies showing how these insights make it easier to work with batting records for veteran baseball players and a large 3d array of spatio-temporal ozone measurements.},
   author = {Hadley Wickham},
   doi = {10.18637/JSS.V040.I01},
   issn = {1548-7660},
   issue = {1},
   journal = {Journal of Statistical Software},
   keywords = {Apply,Data analysis,R,Split},
   month = {4},
   pages = {1-29},
   publisher = {American Statistical Association},
   title = {The Split-Apply-Combine Strategy for Data Analysis},
   volume = {40},
   url = {https://www.jstatsoft.org/index.php/jss/article/view/v040i01},
   year = {2011},
}
@article{Wickham2014,
   abstract = {A huge amount of effort is spent cleaning data to get it ready for analysis, but there has been little research on how to make data cleaning as easy and effective as possible. This paper tackles a small, but important, component of data cleaning: data tidying. Tidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. This framework makes it easy to tidy messy datasets because only a small set of tools are needed to deal with a wide range of un-tidy datasets. This structure also makes it easier to develop tidy tools for data analysis, tools that both input and output tidy datasets. The advantages of a consistent data structure and matching tools are demonstrated with a case study free from mundane data manipulation chores.},
   author = {Hadley Wickham},
   doi = {10.18637/JSS.V059.I10},
   issn = {1548-7660},
   issue = {10},
   journal = {Journal of Statistical Software},
   keywords = {Data cleaning,Data tidying,R,Relational databases},
   month = {9},
   pages = {1-23},
   publisher = {American Statistical Association},
   title = {Tidy Data},
   volume = {59},
   url = {https://www.jstatsoft.org/index.php/jss/article/view/v059i10},
   year = {2014},
}
@article{Dean2004,
title	= {MapReduce: Simplified Data Processing on Large Clusters},
author	= {Jeffrey Dean and Sanjay Ghemawat},
year	= {2004},
booktitle	= {OSDI'04: Sixth Symposium on Operating System Design and Implementation},
pages	= {137--150},
address	= {San Francisco, CA}
}
@article{Chua2004,
   abstract = {This paper illustrates a bioinformatics workflow and its execution in a parallel and distributed environment. Our paper is organized into two main parts. The first part describes a bioinformatics study of a genome wide analysis based on full length human transcripts (cDNA information) to determine gene expression in various tissues. The second part is the execution of the workflow in a parallel and distributed environment. We show the embarrassingly parallel structure of the workflow, its implementation in a distributed cluster environment and the efficiency that can be achieved by automation of the workflow through a parallel scripting language.},
   author = {Ching Lian Chua and Francis Tang and Yun Ping Lim and Liang Yoong Ho and Arun Krishnan},
   doi = {10.1007/978-3-540-30501-9_1/COVER},
   issn = {03029743},
   journal = {Lecture Notes in Computer Science},
   keywords = {Bioinformatics,Parallel Computing,Workflow},
   pages = {1-4},
   publisher = {Springer Verlag},
   title = {Implementing a bioinformatics workflow in a parallel and distributed environment},
   volume = {3320},
   url = {https://link.springer.com/chapter/10.1007/978-3-540-30501-9_1},
   year = {2004},
}
@Article{Hughes2016,
  doi = {10.21105/joss.00106},
  url = {http://dx.doi.org/10.21105/joss.00106},
  year = {2016},
  month = {nov},
  publisher = {The Open Journal},
  volume = {1},
  number = {7},
  author = {Sean M Hughes},
  title = {plater: Read,  Tidy,  and Display Data from Microtiter Plates},
  journal = {The Journal of Open Source Software},
}
  @Article{Roediger2017,
    author = {Stefan Roediger and Michal Burdukiewicz and
      Andrej-Nikolai Spiess and Konstantin Blagodatskikh},
    title = {Enabling reproducible real-time quantitative PCR research:
      the RDML package},
    year = {2017},
    journal = {Bioinformatics},
    doi = {10.1093/bioinformatics/btx528},
  }

@Manual{Wickham2022,
    title = {scales: Scale Functions for Visualization},
    author = {Hadley Wickham and Dana Seidel},
    year = {2022},
    note = {R package version 1.2.0},
    url = {https://CRAN.R-project.org/package=scales},
  }

@article{Benjamini1995,
 ISSN = {00359246},
 URL = {http://www.jstor.org/stable/2346101},
 abstract = {The common approach to the multiplicity problem calls for controlling the familywise error rate (FWER). This approach, though, has faults, and we point out a few. A different approach to problems of multiple significance testing is presented. It calls for controlling the expected proportion of falsely rejected hypotheses-the false discovery rate. This error rate is equivalent to the FWER when all hypotheses are true but is smaller otherwise. Therefore, in problems where the control of the false discovery rate rather than that of the FWER is desired, there is potential for a gain in power. A simple sequential Bonferroni-type procedure is proved to control the false discovery rate for independent test statistics, and a simulation study shows that the gain in power is substantial. The use of the new procedure and the appropriateness of the criterion are illustrated with examples.},
 author = {Yoav Benjamini and Yosef Hochberg},
 journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
 number = {1},
 pages = {289--300},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing},
 urldate = {2022-10-01},
 volume = {57},
 year = {1995}
}
@article{Mann1947,
   abstract = {Let $x$ and $y$ be two random variables with continuous cumulative distribution functions $f$ and $g$. A statistic $U$ depending on the relative ranks of the $x$'s and $y$'s is proposed for testing the hypothesis $f = g$. Wilcoxon proposed an equivalent test in the Biometrics Bulletin, December, 1945, but gave only a few points of the distribution of his statistic. Under the hypothesis $f = g$ the probability of obtaining a given $U$ in a sample of $n x's$ and $m y's$ is the solution of a certain recurrence relation involving $n$ and $m$. Using this recurrence relation tables have been computed giving the probability of $U$ for samples up to $n = m = 8$. At this point the distribution is almost normal. From the recurrence relation explicit expressions for the mean, variance, and fourth moment are obtained. The 2rth moment is shown to have a certain form which enabled us to prove that the limit distribution is normal if $m, n$ go to infinity in any arbitrary manner. The test is shown to be consistent with respect to the class of alternatives $f(x) > g(x)$ for every $x$.},
   author = {H. B. Mann and D. R. Whitney},
   doi = {10.1214/AOMS/1177730491},
   issn = {0003-4851},
   issue = {1},
   journal = {https://doi.org/10.1214/aoms/1177730491},
   month = {3},
   pages = {50-60},
   publisher = {Institute of Mathematical Statistics},
   title = {On a Test of Whether one of Two Random Variables is Stochastically Larger than the Other},
   volume = {18},
   url = {https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-18/issue-1/On-a-Test-of-Whether-one-of-Two-Random-Variables/10.1214/aoms/1177730491.full https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-18/issue-1/On-a-Test-of-Whether-one-of-Two-Random-Variables/10.1214/aoms/1177730491.short},
   year = {1947},
}
@article{Kittleson2012,
   abstract = {Synthetic biology relies on engineering concepts such as abstraction, standardization, and decoupling to develop systems that address environmental, clinical, and industrial needs. Recent advances in applying modular design to system development have enabled creation of increasingly complex systems. However, several challenges to module and system development remain, including syntactic errors, semantic errors, parameter mismatches, contextual sensitivity, noise and evolution, and load and stress. To combat these challenges, researchers should develop a framework for describing and reasoning about biological information, design systems with modularity in mind, and investigate how to predictively describe the diverse sources and consequences of metabolic load and stress. © 2012 Elsevier Ltd.},
   author = {Joshua T. Kittleson and Gabriel C. Wu and J. Christopher Anderson},
   doi = {10.1016/J.CBPA.2012.06.009},
   issn = {1367-5931},
   issue = {3-4},
   journal = {Current Opinion in Chemical Biology},
   month = {8},
   pages = {329-336},
   pmid = {22818777},
   publisher = {Elsevier Current Trends},
   title = {Successes and failures in modular genetic engineering},
   volume = {16},
   year = {2012},
}
@Manual{Fellows2018,
    title = {wordcloud: Word Clouds},
    author = {Ian Fellows},
    year = {2018},
    note = {R package version 2.6},
    url = {https://CRAN.R-project.org/package=wordcloud},
  }
@Manual{Rudis2020,
    title = {pluralize: Pluralize and 'Singularize' Any (English) Word},
    author = {Bob Rudis and Blake Embrey},
    year = {2020},
    note = {R package version 0.2.0},
    url = {https://CRAN.R-project.org/package=pluralize},
  }
@Article{Feinerer2008,
    title = {Text Mining Infrastructure in R},
    author = {Ingo Feinerer and Kurt Hornik and David Meyer},
    year = {2008},
    journal = {Journal of Statistical Software},
    volume = {25},
    number = {5},
    pages = {1--54},
    url = {https://www.jstatsoft.org/v25/i05/},
    month = {March},
  }
@article{Gietz2002a,
  title={Transformation of yeast by lithium acetate/single-stranded carrier {DNA}/polyethylene glycol method},
  author={Gietz, R Daniel and Woods, Robin A},
  journal={Methods in enzymology},
  volume={350},
  pages={87--96},
  year={2002},
  publisher={Elsevier}
}
@article{Lichten2014,
  title={Unmixing of fluorescence spectra to resolve quantitative time-series measurements of gene expression in plate readers},
  author={Lichten, Catherine A and White, Rachel and Clark, Ivan BN and Swain, Peter S},
  journal={BMC biotechnology},
  volume={14},
  number={1},
  pages={1--11},
  year={2014},
  publisher={BioMed Central}
}
@article{Swain2016,
   abstract = {Often the time derivative of a measured variable is of as much interest as the variable itself. For a growing population of biological cells, for example, the population's growth rate is typically more important than its size. Here we introduce a non-parametric method to infer first and second time derivatives as a function of time from time-series data. Our approach is based on Gaussian processes and applies to a wide range of data. In tests, the method is at least as accurate as others, but has several advantages: it estimates errors both in the inference and in any summary statistics, such as lag times, and allows interpolation with the corresponding error estimation. As illustrations, we infer growth rates of microbial cells, the rate of assembly of an amyloid fibril and both the speed and acceleration of two separating spindle pole bodies. Our algorithm should thus be broadly applicable.},
   author = {Peter S. Swain and Keiran Stevenson and Allen Leary and Luis F. Montano-Gutierrez and Ivan B.N. Clark and Jackie Vogel and Teuta Pilizota},
   issn = {20411723},
   issue = {1},
   journal = {Nature Communications},
   keywords = {Bioinformatics,Microbiology,Time series},
   month = {12},
   pages = {1-8},
   publisher = {Nature Publishing Group},
   title = {Inferring time derivatives including cell growth rates using Gaussian processes},
   volume = {7},
   year = {2016},
}
@article{DiTommaso2017,
   author = {Paolo DI Tommaso and Maria Chatzou and Evan W. Floden and Pablo Prieto Barja and Emilio Palumbo and Cedric Notredame},
   issn = {1546-1696},
   issue = {4},
   journal = {Nature Biotechnology 2017 35:4},
   keywords = {Computational biology and bioinformatics,Data publication and archiving},
   month = {4},
   pages = {316-319},
   publisher = {Nature Publishing Group},
   title = {Nextflow enables reproducible computational workflows},
   volume = {35},
   year = {2017},
}
@article{Ewels2020,
   author = {Philip A. Ewels and Alexander Peltzer and Sven Fillinger and Harshil Patel and Johannes Alneberg and Andreas Wilm and Maxime Ulysse Garcia and Paolo Di Tommaso and Sven Nahnsen},
   doi = {10.1038/s41587-020-0439-x},
   isbn = {2018M3A9H3020459},
   issn = {1546-1696},
   issue = {3},
   journal = {Nature Biotechnology 2020 38:3},
   keywords = {Computational biology and bioinformatics,Scientific community},
   month = {2},
   pages = {276-278},
   pmid = {32055031},
   publisher = {Nature Publishing Group},
   title = {The nf-core framework for community-curated bioinformatics pipelines},
   volume = {38},
   url = {https://www.nature.com/articles/s41587-020-0439-x},
   year = {2020},
}
@article{Zhang2021,
   abstract = {RNA degradation is critical for gene expression and mRNA quality control. mRNA degradation is connected to the translation process up to the degree that 5'-3' mRNA degradation follows the last translating ribosome. Here, we present an improved high-throughput 5'P degradome RNA-sequencing method (HT-5Pseq). HT-5Pseq is easy, scalable, and uses affordable duplex-specific nuclease-based rRNA depletion. We investigate in vivo ribosome stalls focusing on translation termination. By comparing ribosome stalls identified by ribosome profiling, disome-seq and HT-5Pseq, we find that degradation-associated ribosome stalls are often enriched in Arg preceding the stop codon. On the contrary, mRNAs depleted for those stalls use more frequently a TAA stop codon preceded by hydrophobic amino acids. Finally, we show that termination stalls found by HT-5Pseq, and not by other approaches, are associated with decreased mRNA stability. Our work suggests that ribosome stalls associated with mRNA decay can be easily captured by investigating the 5'P degradome.},
   author = {Yujie Zhang and Vicent Pelechano},
   issn = {2667-2375},
   issue = {1},
   journal = {Cell Reports Methods},
   keywords = {RNA degradation,co-translational decay,degradome,ribosome stalls},
   month = {5},
   pages = {100001},
   publisher = {Cell Press},
   title = {High-throughput 5'P sequencing enables the study of degradation-associated ribosome stalls},
   volume = {1},
   year = {2021},
}
@article{Ewels2016,
   abstract = {Motivation: Fast and accurate quality control is essential for studies involving next-generation sequencing data. Whilst numerous tools exist to quantify QC metrics, there is no common approach to flexibly integrate these across tools and large sample sets. Assessing analysis results across an entire project can be time consuming and error prone; batch effects and outlier samples can easily be missed in the early stages of analysis. Results: We present MultiQC, a tool to create a single report visualising output from multiple tools across many samples, enabling global trends and biases to be quickly identified. MultiQC can plot data from many common bioinformatics tools and is built to allow easy extension and customization. Availability and implementation: MultiQC is available with an GNU GPLv3 license on GitHub, the Python Package Index and Bioconda. Documentation and example reports are available at http://multiqc.info.},
   author = {Philip Ewels and Måns Magnusson and Sverker Lundin and Max Käller},
   issn = {1367-4803},
   issue = {19},
   journal = {Bioinformatics},
   month = {10},
   pages = {3047-3048},
   publisher = {Oxford University Press},
   title = {MultiQC: summarize analysis results for multiple tools and samples in a single report},
   volume = {32},
   year = {2016},
}
@article{Martin2011,
   abstract = {When small RNA is sequenced on current sequencing machines, the resulting reads are usually longer than the RNA and therefore contain parts of the 3' adapter. That adapter must be found and removed error-tolerantly from each read before read mapping. Previous solutions are either hard to use or do not offer required features, in particular support for color space data. As an easy to use alternative, we developed the command-line tool cutadapt, which supports 454, Illumina and SOLiD (color space) data, offers two adapter trimming algorithms, and has other useful features.   Cutadapt, including its MIT-licensed source code, is available for download at  http://code.google.com/p/cutadapt/},
   author = {Marcel Martin},
   issue = {1},
   journal = {EMBnet.journal},
   keywords = {adapter removal,microRNA,next generation sequencing,small RNA},
   month = {5},
   pages = {10},
   publisher = {EMBnet Stichting},
   title = {Cutadapt removes adapter sequences from high-throughput sequencing reads},
   volume = {17},
   year = {2011},
}
@article{Kim2019,
   abstract = {The human reference genome represents only a small number of individuals, which limits its usefulness for genotyping. We present a method named HISAT2 (hierarchical indexing for spliced alignment of transcripts 2) that can align both DNA and RNA sequences using a graph Ferragina Manzini index. We use HISAT2 to represent and search an expanded model of the human reference genome in which over 14.5 million genomic variants in combination with haplotypes are incorporated into the data structure used for searching and alignment. We benchmark HISAT2 using simulated and real datasets to demonstrate that our strategy of representing a population of genomes, together with a fast, memory-efficient search algorithm, provides more detailed and accurate variant analyses than other methods. We apply HISAT2 for HLA typing and DNA fingerprinting; both applications form part of the HISAT-genotype software that enables analysis of haplotype-resolved genes or genomic regions. HISAT-genotype outperforms other computational methods and matches or exceeds the performance of laboratory-based assays.},
   author = {Daehwan Kim and Joseph M. Paggi and Chanhee Park and Christopher Bennett and Steven L. Salzberg},
   issn = {15461696},
   issue = {8},
   journal = {Nature Biotechnology},
   keywords = {Genetics research,Genome informatics,Population genetics},
   month = {8},
   pages = {907-915},
   publisher = {Nature Publishing Group},
   title = {Graph-based genome alignment and genotyping with HISAT2 and HISAT-genotype},
   volume = {37},
   year = {2019},
}
@article{Ng2020,
   abstract = {The Saccharomyces Genome Database (SGD; www.yeastgenome.org) maintains the official annotation of all genes in the Saccharomyces cerevisiae reference genome and aims to elucidate the function of these genes and their products by integrating manually curated experimental data. Technological advances have allowed researchers to profile RNA expression and identify transcripts at high resolution. These data can be configured in web-based genome browser applications for display to the general public. Accordingly, SGD has incorporated published transcript isoform data in our instance of JBrowse, a genome visualization platform. This resource will help clarify S. cerevisiae biological processes by furthering studies of transcriptional regulation, untranslated regions, genome engineering, and expression quantification in S. cerevisiae.},
   author = {Patrick C. Ng and Edith D. Wong and Kevin A. MacPherson and Suzi Aleksander and Joanna Argasinska and Barbara Dunn and Robert S. Nash and Marek S. Skrzypek and Felix Gondwe and Sagar Jha and Kalpana Karra and Shuai Weng and Stuart Miyasato and Matt Simison and Stacia R. Engel and J. Michael Cherry},
   issn = {0305-1048},
   issue = {D1},
   journal = {Nucleic Acids Research},
   keywords = {engineering,genes,genome,internet,protein isoforms,saccharomyces,saccharomyces cerevisiae,transcription, genetic,transcriptional control,untranslated regions},
   month = {1},
   pages = {D743-D748},
   publisher = {Oxford Academic},
   title = {Transcriptome visualization and data availability at the Saccharomyces Genome Database},
   volume = {48},
   year = {2020},
}
@article{Nersisyan2020,
   abstract = {In eukaryotes, 5'-3' co-translation degradation machinery follows the last translating ribosome providing an in vivo footprint of its position. Thus, 5' monophosphorylated (5'P) degradome sequencing, in addition to informing about RNA decay, also provides information regarding ribosome dynamics. Multiple experimental methods have been developed to investigate the mRNA degradome; however, computational tools for their reproducible analysis are lacking. Here, we present fivepseq: an easy-to-use application for analysis and interactive visualization of 5'P degradome data. This tool performs both metagene- and gene-specific analysis, and enables easy investigation of codon-specific ribosome pauses. To demonstrate its ability to provide new biological information, we investigate gene-specific ribosome pauses in Saccharomyces cerevisiae after eIF5A depletion. In addition to identifying pauses at expected codon motifs, we identify multiple genes with strain-specific degradation frameshifts. To show its wide applicability, we investigate 5'P degradome from Arabidopsis thaliana and discover both motif-specific ribosome protection associated with particular developmental stages and generally increased ribosome protection at termination level associated with age. Our work shows how the use of improved analysis tools for the study of 5'P degradome can significantly increase the biological information that can be derived from such datasets and facilitate its reproducible analysis.},
   author = {Lilit Nersisyan and Maria Ropat and Vicent Pelechano},
   issn = {26319268},
   issue = {4},
   journal = {NAR Genomics and Bioinformatics},
   month = {12},
   publisher = {Oxford Academic},
   title = {Improved computational analysis of ribosome dynamics from 5'P degradome data using fivepseq},
   volume = {2},
   year = {2020},
}
@article{Sanchez2008,
  title={Transcriptional control of noise in gene expression},
  author={S{\'a}nchez, {\'A}lvaro and Kondev, Jan{\'e}},
  journal={Proceedings of the National Academy of Sciences},
  volume={105},
  number={13},
  pages={5081--5086},
  year={2008},
  publisher={National Acad Sciences}
}
@Article{Wickham2019,
    title = {Welcome to the {tidyverse}},
    author = {Hadley Wickham and Mara Averick and Jennifer Bryan and Winston Chang and Lucy D'Agostino McGowan and Romain François and Garrett Grolemund and Alex Hayes and Lionel Henry and Jim Hester and Max Kuhn and Thomas Lin Pedersen and Evan Miller and Stephan Milton Bache and Kirill Müller and Jeroen Ooms and David Robinson and Dana Paige Seidel and Vitalie Spinu and Kohske Takahashi and Davis Vaughan and Claus Wilke and Kara Woo and Hiroaki Yutani},
    year = {2019},
    journal = {Journal of Open Source Software},
    volume = {4},
    number = {43},
    pages = {1686},
  }
  
  @Book{Wickham2016,
    author = {Hadley Wickham},
    title = {ggplot2: Elegant Graphics for Data Analysis},
    publisher = {Springer-Verlag New York},
    year = {2016},
    isbn = {978-3-319-24277-4},
  }
@article{Lorenz2011,
   abstract = {Background: Secondary structure forms an important intermediate level of description of nucleic acids that encapsulates the dominating part of the folding energy, is often well conserved in evolution, and is routinely used as a basis to explain experimental findings. Based on carefully measured thermodynamic parameters, exact dynamic programming algorithms can be used to compute ground states, base pairing probabilities, as well as thermodynamic properties.Results: The ViennaRNA Package has been a widely used compilation of RNA secondary structure related computer programs for nearly two decades. Major changes in the structure of the standard energy model, the Turner 2004 parameters, the pervasive use of multi-core CPUs, and an increasing number of algorithmic variants prompted a major technical overhaul of both the underlying RNAlib and the interactive user programs. New features include an expanded repertoire of tools to assess RNA-RNA interactions and restricted ensembles of structures, additional output information such as centroid structures and maximum expected accuracy structures derived from base pairing probabilities, or z-scores for locally stable secondary structures, and support for input in fasta format. Updates were implemented without compromising the computational efficiency of the core algorithms and ensuring compatibility with earlier versions.Conclusions: The ViennaRNA Package 2.0, supporting concurrent computations via OpenMP, can be downloaded from http://www.tbi.univie.ac.at/RNA. © 2011 Lorenz et al; licensee BioMed Central Ltd.},
   author = {Ronny Lorenz and Stephan H. Bernhart and Christian Höner zu Siederdissen and Hakim Tafer and Christoph Flamm and Peter F. Stadler and Ivo L. Hofacker},
   issn = {17487188},
   issue = {1},
   journal = {Algorithms for Molecular Biology},
   keywords = {Algorithms,Bioinformatics,Cellular and Medical Topics,Computational Biology/Bioinformatics,Physiological},
   month = {11},
   pages = {26},
   publisher = {BioMed Central},
   title = {ViennaRNA Package 2.0},
   volume = {6},
   year = {2011},
}
@article{Liao2014,
   abstract = {Motivation: Next-generation sequencing technologies generate millions of short sequence reads, which are usually aligned to a reference genome. In many applications, the key information required for downstream analysis is the number of reads mapping to each genomic feature, for example to each exon or each gene. The process of counting reads is called read summarization. Read summarization is required for a great variety of genomic analyses but has so far received relatively little attention in the literature.Results: We present featureCounts, a read summarization program suitable for counting reads generated from either RNA or genomic DNA sequencing experiments. featureCounts implements highly efficient chromosome hashing and feature blocking techniques. It is considerably faster than existing methods (by an order of magnitude for gene-level summarization) and requires far less computer memory. It works with either single or paired-end reads and provides a wide range of options appropriate for different sequencing applications. © 2013 The Author 2013. Published by Oxford University Press. All rights reserved.},
   author = {Yang Liao and Gordon K. Smyth and Wei Shi},
   issn = {14602059},
   issue = {7},
   journal = {Bioinformatics},
   month = {4},
   pages = {923-930},
   publisher = {Oxford University Press},
   title = {FeatureCounts: An efficient general purpose program for assigning sequence reads to genomic features},
   volume = {30},
   year = {2014},
}
@article{Smith2017,
   abstract = {Unique Molecular Identifiers (UMIs) are random oligonucleotide barcodes that are increasingly used in high-throughput sequencing experiments. Through a UMI, identical copies arising from distinct molecules can be distinguished from those arising through PCR amplification of the same molecule. However, bioinformatic methods to leverage the information from UMIs have yet to be formalized. In particular, sequencing errors in the UMI sequence are often ignored or else resolved in an ad hoc manner. We show that errors in the UMI sequence are common and introduce network-based methods to account for these errors when identifying PCR duplicates. Using these methods, we demonstrate improved quantification accuracy both under simulated conditions and real iCLIP and single-cell RNA-seq data sets. Reproducibility between iCLIP replicates and single-cell RNA-seq clustering are both improved using our proposed network-based method, demonstrating the value of properly accounting for errors in UMIs. These methods are implemented in the open source UMI-tools software package.},
   author = {Tom Smith and Andreas Heger and Ian Sudbery},
   issn = {15495469},
   issue = {3},
   journal = {Genome Research},
   month = {3},
   pages = {491-499},
   publisher = {Cold Spring Harbor Laboratory Press},
   title = {UMI-tools: Modeling sequencing errors in Unique Molecular Identifiers to improve quantification accuracy},
   volume = {27},
   year = {2017},
}
@article{Quinlan2010,
   abstract = {Motivation: Testing for correlations between different sets of genomic features is a fundamental task in genomics research. However, searching for overlaps between features with existing webbased methods is complicated by the massive datasets that are routinely produced with current sequencing technologies. Fast and flexible tools are therefore required to ask complex questions of these data in an efficient manner. Results: This article introduces a new software suite for the comparison, manipulation and annotation of genomic features in Browser Extensible Data (BED) and General Feature Format (GFF) format. BEDTools also supports the comparison of sequence alignments in BAM format to both BED and GFF features. The tools are extremely efficient and allow the user to compare large datasets (e.g. next-generation sequencing data) with both public and custom genome annotation tracks. BEDTools can be combined with one another as well as with standard UNIX commands, thus facilitating routine genomics tasks as well as pipelines that can quickly answer intricate questions of large genomic datasets. Availability and implementation: BEDTools was written in C++. Source code and a comprehensive user manual are freely available at http://code.google.com/p/bedtools. Contact: aaronquinlan@gmail.com; imh4y@virginia.edu. Supplementary information: Supplementary data are available at Bioinformatics online. © The Author(s) 2010. Published by Oxford University Press.},
   author = {Aaron R. Quinlan and Ira M. Hall},
   issn = {13674803},
   issue = {6},
   journal = {Bioinformatics},
   month = {1},
   pages = {841-842},
   publisher = {Bioinformatics},
   title = {BEDTools: A flexible suite of utilities for comparing genomic features},
   volume = {26},
   year = {2010},
}
@article{Li2009,
   abstract = {Summary: The Sequence Alignment/Map (SAM) format is a generic alignment format for storing read alignments against reference sequences, supporting short and long reads (up to 128 Mbp) produced by different sequencing platforms. It is flexible in style, compact in size, efficient in random access and is the format in which alignments from the 1000 Genomes Project are released. SAM tools implements various utilities for post-processing alignments in the SAM format, such as indexing, variant caller and alignment viewer, and thus provides universal tools for processing read alignments. © 2009 The Author(s).},
   author = {Heng Li and Bob Handsaker and Alec Wysoker and Tim Fennell and Jue Ruan and Nils Homer and Gabor Marth and Goncalo Abecasis and Richard Durbin},
   issn = {13674803},
   issue = {16},
   journal = {Bioinformatics},
   month = {8},
   pages = {2078-2079},
   publisher = {Bioinformatics},
   title = {The Sequence Alignment/Map format and SAMtools},
   volume = {25},
   year = {2009},
}
@article{Akaike1998,
   abstract = {In this paper it is shown that the classical maximum likelihood principle can be considered to be a method of asymptotic realization of an optimum estimate with respect to a very general information theoretic criterion. This observation shows an extension of the principle to provide answers to many practical problems of statistical model fitting.},
   author = {Hirotogu Akaike},
   pages = {199-213},
   publisher = {Springer, New York, NY},
   title = {Information Theory and an Extension of the Maximum Likelihood Principle},
   year = {1998},
}
@Manual{Rstats,
    title = {R: A Language and Environment for Statistical Computing},
    author = {{R Core Team}},
    organization = {R Foundation for Statistical Computing},
    address = {Vienna, Austria},
    year = {2020},
  }
@book{Ripley2002,
   abstract = {Functions and datasets to support Venables and Ripley, ``Modern Applied Statistics with S'' (4th edition, 2002).},
   author = {B. Ripley and B. Venables},
   publisher = {Springer},
   edition = {4th},
   title = {Modern Applied Statistics with S},
   year = {2002},
}
@article{Ito2013,
title = {Characterization of five terminator regions that increase the protein yield of a transgene in Saccharomyces cerevisiae},
journal = {Journal of Biotechnology},
volume = {168},
number = {4},
pages = {486-492},
year = {2013},
issn = {0168-1656},
author = {Yoichiro Ito and Mamoru Yamanishi and Akinori Ikeuchi and Chie Imamura and Kenro Tokuhiro and Takao Kitagawa and Takashi Matsuyama},
keywords = {Metabolic engineering, Terminator region, 3′-UTR activity, Fluorescent protein, Cellulase},
abstract = {Strong terminator regions could be used to improve metabolically engineered yeasts by increasing the target enzyme protein yields above those achieved with traditional terminator regions. We recently identified five strong terminator regions (RPL41Bt, RPL15At, DIT1t, RPL3t, and IDP1t) in a comprehensive analysis of Saccharomyces cerevisiae. The effect of the terminator regions was analyzed by measuring the protein production of a linked transgene, and was shown to be twice that of a traditional terminator region (PGK1t). Here, we investigated whether the activity of the terminator regions is affected by exchange of a strong promoter or reporter in the linked transgene, carbon source for cell growth, stress factors, host yeast strain, or stage of the growth phase. Our results indicate that the activities of all five terminator regions were twice that of PGK1t in all conditions tested. In addition, we demonstrated that the strong activity of these terminator regions could be used to improve secretory production of endoglucanase II derived from Tricoderma ressei, and that the DIT1t strain was the best of the five strains for this purpose. We therefore propose that DIT1t, and the four other terminator regions, could be applied to the development of improved metabolically engineered yeasts.}
}
@article{Zid2014,
   abstract = {Transcription and translation are generally thought of as disconnected processes in eukaryotes; however, under starvation conditions in yeast, the promoter sequence influences not only messenger RNA levels but also several processes downstream of transcription, including the localization of mRNA within the cytoplasm and the translation rate of mRNA. Transcription and translation are generally thought of as disconnected processes in eukaryotes. Here, Brian Zid and Erin O'Shea report that in yeast under starvation conditions, promoter sequences influence not only messenger RNA levels but also other processes downstream of transcription — the localization of the mRNA within the cytoplasm and the mRNA translation rate. Such a mechanism may be an adaption to stressful environmental conditions, enabling selective coordination of protein production at times when overall translation is generally reduced. A universal feature of the response to stress and nutrient limitation is transcriptional upregulation of genes that encode proteins important for survival. Under many such conditions, the overall protein synthesis level is reduced, thereby dampening the stress response at the level of protein expression1. For example, during glucose starvation in Saccharomyces cerevisiae (yeast), translation is rapidly repressed, yet the transcription of many stress- and glucose-repressed genes is increased2,3. Here we show, using ribosomal profiling and microscopy, that this transcriptionally upregulated gene set consists of two classes: one class produces messenger RNAs that are translated during glucose starvation and are diffusely localized in the cytoplasm, including many heat-shock protein mRNAs; and the other class produces mRNAs that are not efficiently translated during glucose starvation and are concentrated in foci that co-localize with P bodies and stress granules, a class that is enriched for mRNAs involved in glucose metabolism. Surprisingly, the information specifying the differential localization and protein production of these two classes of mRNA is encoded in the promoter sequence: promoter responsiveness to heat-shock factor 1 (Hsf1) specifies diffuse cytoplasmic localization and higher protein production on glucose starvation. Thus, promoter sequences can influence not only the levels of mRNAs but also the subcellular localization of mRNAs and the efficiency with which they are translated, enabling cells to tailor protein production to the environmental conditions.},
   author = {Brian M. Zid and Erin K. O'Shea},
   doi = {10.1038/nature13578},
   issn = {1476-4687},
   issue = {7520},
   journal = {Nature 2014 514:7520},
   keywords = {RNA metabolism,Translation},
   month = {8},
   pages = {117-121},
   pmid = {25119046},
   publisher = {Nature Publishing Group},
   title = {Promoter sequences direct cytoplasmic localization and translation of mRNAs during starvation in yeast},
   volume = {514},
   url = {https://www.nature.com/articles/nature13578},
   year = {2014},
}
@article{Siepel2005,
   abstract = {We have conducted a comprehensive search for conserved elements in vertebrate genomes, using genome-wide multiple alignments of five vertebrate species (human, mouse, rat, chicken, and Fugu rubripes). Parallel searches have been performed with multiple alignments of four insect species (three species of Drosophila and Anopheles gambiae), two species of Caenorhabditis, and seven species of Saccharomyces. Conserved elements were identified with a computer program called phastCons, which is based on a two-state phylogenetic hidden Markov model (phylo-HMM). PhastCons works by fitting a phylo-HMM to the data by maximum likelihood, subject to constraints designed to calibrate the model across species groups, and then predicting conserved elements based on this model. The predicted elements cover roughly 3%-8% of the human genome (depending on the details of the calibration procedure) and substantially higher fractions of the more compact Drosophila melanogaster (37%-53%), Caenorhabditis elegans (18%-37%), and Saccharaomyces cerevisiae (47%-68%) genomes. From yeasts to vertebrates, in order of increasing genome size and general biological complexity, increasing fractions of conserved bases are found to lie outside of the exons of known protein-coding genes. In all groups, the most highly conserved elements (HCEs), by log-odds score, are hundreds or thousands of bases long. These elements share certain properties with ultraconserved elements, but they tend to be longer and less perfectly conserved, and they overlap genes of somewhat different functional categories. In vertebrates, HCEs are associated with the 3′ UTRs of regulatory genes, stable gene deserts, and megabase-sized regions rich in moderately conserved noncoding sequences. Noncoding HCEs also show strong statistical evidence of an enrichment for RNA secondary structure. ©2005 by Cold Spring Harbor Laboratory Press.},
   author = {Adam Siepel and Gill Bejerano and Jakob S. Pedersen and Angie S. Hinrichs and Minmei Hou and Kate Rosenbloom and Hiram Clawson and John Spieth and La Deana W. Hillier and Stephen Richards and George M. Weinstock and Richard K. Wilson and Richard A. Gibbs and W. James Kent and Webb Miller and David Haussler},
   issn = {1088-9051},
   issue = {8},
   journal = {Genome Research},
   month = {8},
   pages = {1034-1050},
   publisher = {Cold Spring Harbor Laboratory Press},
   title = {Evolutionarily conserved elements in vertebrate, insect, worm, and yeast genomes},
   volume = {15},
   year = {2005},
}
@article{Dhillon2020,
   abstract = {Gene expression in Saccharomyces cerevisiae is regulated at multiple levels. Genomic and epigenomic mapping of transcription factors and chromatin factors has led to the delineation of various modular regulatory elements—enhancers (upstream activating sequences), core promoters, 50 untranslated regions (50 UTRs) and transcription terminators/30 untranslated regions (30 UTRs). However, only a few of these elements have been tested in combinations with other elements and the functional interactions between the different modular regulatory elements remain under explored. We describe a simple and rapid approach to build a combinatorial library of regulatory elements and have used this library to study 26 different enhancers, core promoters, 50 UTRs and transcription terminators/30 UTRs to estimate the contribution of individual regulatory parts in gene expression. Our combinatorial analysis shows that while enhancers initiate gene expression, core promoters modulate the levels of enhancer-mediated expression and can positively or negatively affect expression from even the strongest enhancers. Principal component analysis (PCA) indicates that enhancer and promoter function can be explained by a single principal component while UTR function involves multiple functional components. The PCA also highlights outliers and suggest differences in mechanisms of regulation by individual elements. Our data also identify numerous regulatory cassettes composed of different individual regulatory elements that exhibit equivalent gene expression levels. These data thus provide a catalog of elements that could in future be used in the design of synthetic regulatory circuits.},
   author = {Namrita Dhillon and Robert Shelansky and Brent Townshend and Miten Jain and Hinrich Boeger and Drew Endy and Rohinton Kamakaka},
   issn = {2397-7000},
   issue = {1},
   journal = {Synthetic biology (Oxford, England)},
   keywords = {MEDLINE,NCBI,NIH,NLM,Namrita Dhillon,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,PMC7402160,PubMed Abstract,Robert Shelansky,Rohinton Kamakaka,doi:10.1093/synbio/ysaa007,pmid:32775697},
   publisher = {Synth Biol (Oxf)},
   title = {Permutational analysis of Saccharomyces cerevisiae regulatory elements},
   volume = {5},
   year = {2020},
}
@article{Savarese2006,
   abstract = {In this issue of Cell, Axel and colleagues (Lomvardas et al., 2006) report that a single enhancer of an odorant receptor (OR) gene cluster interacts with multiple OR gene promoters on different chromosomes. This study suggests a mechanism that allows olfactory sensory neurons to choose randomly and express only one out of more than 1000 OR genes. © 2006 Elsevier Inc. All rights reserved.},
   author = {Fabio Savarese and Rudolf Grosschedl},
   doi = {10.1016/j.cell.2006.07.008},
   issn = {00928674},
   issue = {2},
   journal = {Cell},
   month = {7},
   pages = {248-250},
   pmid = {16873057},
   publisher = {Elsevier B.V.},
   title = {Blurring cis and trans in Gene Regulation},
   volume = {126},
   url = {http://www.cell.com/article/S0092867406009019/fulltext http://www.cell.com/article/S0092867406009019/abstract https://www.cell.com/cell/abstract/S0092-8674(06)00901-9},
   year = {2006},
}
@article{Will2011,
   abstract = {Pre-mRNA splicing is catalyzed by the spliceosome, a multimegadalton ribonucleoprotein (RNP) complex comprised of five snRNPs and numerous proteins. Intricate RNA-RNA and RNP networks, which serve to align the reactive groups of the pre-mRNA for catalysis, are formed and repeatedly rearranged during spliceosome assembly and catalysis. Both the conformation and composition of the spliceosome are highly dynamic, affording the splicing machinery its accuracy and flexibility, and these remarkable dynamics are largely conserved between yeast and metazoans. Because of its dynamic and complex nature, obtaining structural information about the spliceosome represents a major challenge. Electron microscopy has revealed the general morphology of several spliceosomal complexes and their snRNP subunits, and also the spatial arrangement of some of their components. X-ray and NMR studies have provided high resolution structure information about spliceosomal proteins alone or complexed with one or more binding partners. The extensive interplay of RNA and proteins in aligning the pre-mRNA's reactive groups, and the presence of both RNA and protein at the core of the splicing machinery, suggest that the spliceosome is an RNPenzyme. However, elucidation of the precise nature of the spliceosome's active site, awaits the generation of a high-resolution structure of its RNP core. © 2011 Cold Spring Harbor Laboratory Press.},
   author = {Cindy L. Will and Reinhard Lührmann},
   doi = {10.1101/CSHPERSPECT.A003707},
   issn = {19430264},
   issue = {7},
   journal = {Cold Spring Harbor Perspectives in Biology},
   month = {7},
   pages = {1-2},
   pmid = {21441581},
   publisher = {Cold Spring Harbor Laboratory Press},
   title = {Spliceosome Structure and Function},
   volume = {3},
   url = {/pmc/articles/PMC3119917/ /pmc/articles/PMC3119917/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3119917/},
   year = {2011},
}
@article{Li2015,
   abstract = {The majority of the human genome consists of non-coding regions that have been called junk DNA. However, recent studies have unveiled that these regions contain cis-regulatory elements, such as promoters, enhancers, silencers, insulators, etc. These regulatory elements can play crucial roles in controlling gene expressions in specific cell types, conditions, and developmental stages. Disruption to these regions could contribute to phenotype changes. Precisely identifying regulatory elements is key to deciphering the mechanisms underlying transcriptional regulation. Cis-regulatory events are complex processes that involve chromatin accessibility, transcription factor binding, DNA methylation, histone modifications, and the interactions between them. The development of next-generation sequencing techniques has allowed us to capture these genomic features in depth. Applied analysis of genome sequences for clinical genetics has increased the urgency for detecting these regions. However, the complexity of cis-regulatory events and the deluge of sequencing data require accurate and efficient computational approaches, in particular, machine learning techniques. In this review, we describe machine learning approaches for predicting transcription factor binding sites, enhancers, and promoters, primarily driven by next-generation sequencing data. Data sources are provided in order to facilitate testing of novel methods. The purpose of this review is to attract computational experts and data scientists to advance this field.},
   author = {Yifeng Li and Chih yu Chen and Alice M. Kaye and Wyeth W. Wasserman},
   doi = {10.1016/J.BIOSYSTEMS.2015.10.002},
   issn = {0303-2647},
   journal = {Biosystems},
   keywords = {Cis-regulatory elements,Data integration,Deep learning,Enhancers,Ensemble learning,Gene regulation,Machine learning,Promoters},
   month = {12},
   pages = {6-17},
   pmid = {26499213},
   publisher = {Elsevier},
   title = {The identification of cis-regulatory elements: A review from a machine learning perspective},
   volume = {138},
   year = {2015},
}
@article{Bleichert2010,
   abstract = {Ribonucleoproteins (RNPs) play key roles in many cellular processes and often function as RNP enzymes. Similar to proteins, some of these RNPs exist and function as multimers, either momomeric or heteromeric. While in some cases the mechanistic function of multimerization is well understood, the functional consequences of multimerization of other RNPs remain enigmatic. In this review we will discuss the function and organization of small RNPs that exist as stable multimers, including RNPs catalyzing RNA chemical modifications, telomerase RNP, and RNPs involved in pre-mRNA splicing. © 2010 Informa Healthcare USA, Inc.},
   author = {Franziska Bleichert and Susan J. Baserga},
   doi = {10.3109/10409238.2010.496772},
   issn = {10409238},
   issue = {5},
   journal = {Critical reviews in biochemistry and molecular biology},
   keywords = {Ribonucleoprotein,U11/U12 di-snRNP,U4/U6 di-snRNP,U4/U6.U5 tri-snRNP,box C/D sRNP,box C/D snoRNP,multimerization,telomerase},
   month = {10},
   pages = {331},
   pmid = {20572804},
   publisher = {NIH Public Access},
   title = {Ribonucleoprotein multimers and their functions},
   volume = {45},
   url = {/pmc/articles/PMC2939948/ /pmc/articles/PMC2939948/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2939948/},
   year = {2010},
}
@article{Spitz2012,
   abstract = {How do transcription factors lead to defined developmental programs? The ways in which transcription factors act at enhancer elements and how enhancer activity is established during development are discussed in this Review, which brings together genetic and genomic evidence. Developmental progression is driven by specific spatiotemporal domains of gene expression, which give rise to stereotypically patterned embryos even in the presence of environmental and genetic variation. Views of how transcription factors regulate gene expression are changing owing to recent genome-wide studies of transcription factor binding and RNA expression. Such studies reveal patterns that, at first glance, seem to contrast with the robustness of the developmental processes they encode. Here, we review our current knowledge of transcription factor function from genomic and genetic studies and discuss how different strategies, including extensive cooperative regulation (both direct and indirect), progressive priming of regulatory elements, and the integration of activities from multiple enhancers, confer specificity and robustness to transcriptional regulation during development.},
   author = {François Spitz and Eileen E.M. Furlong},
   doi = {10.1038/nrg3207},
   issn = {1471-0064},
   issue = {9},
   journal = {Nature Reviews Genetics 2012 13:9},
   keywords = {Developmental biology,Functional genomics,Gene expression,Gene regulation,Transcription factors},
   month = {8},
   pages = {613-626},
   pmid = {22868264},
   publisher = {Nature Publishing Group},
   title = {Transcription factors: from enhancer binding to developmental control},
   volume = {13},
   url = {https://www.nature.com/articles/nrg3207},
   year = {2012},
}
@article {Kosuri2013,
	author = {Kosuri, Sriram and Goodman, Daniel B. and Cambray, Guillaume and Mutalik, Vivek K. and Gao, Yuan and Arkin, Adam P. and Endy, Drew and Church, George M.},
	title = {Composability of regulatory sequences controlling transcription and translation in Escherichia coli},
	volume = {110},
	number = {34},
	pages = {14024--14029},
	year = {2013},
	publisher = {National Academy of Sciences},
	abstract = {The inability to predict heterologous gene expression levels precisely hinders our ability to engineer biological systems. Using well-characterized regulatory elements offers a potential solution only if such elements behave predictably when combined. We synthesized 12,563 combinations of common promoters and ribosome binding sites and simultaneously measured DNA, RNA, and protein levels from the entire library. Using a simple model, we found that RNA and protein expression were within twofold of expected levels 80\% and 64\% of the time, respectively. The large dataset allowed quantitation of global effects, such as translation rate on {mRNA} stability and {mRNA} secondary structure on translation rate. However, the worst 5\% of constructs deviated from prediction by 13-fold on average, which could hinder large-scale genetic engineering projects. The ease and scale this of approach indicates that rather than relying on prediction or standardization, we can screen synthetic libraries for desired behavior.},
	issn = {0027-8424},
	eprint = {https://www.pnas.org/content/110/34/14024.full.pdf},
	journal = {Proceedings of the National Academy of Sciences}
}
@article{Guidotti2018,
   abstract = {In recent years, many accurate decision support systems have been constructed as black boxes, that is as systems that hide their internal logic to the user. This lack of explanation constitutes bot...},
   author = {Riccardo Guidotti and Anna Monreale and Salvatore Ruggieri and Franco Turini and Fosca Giannotti and Dino Pedreschi},
   doi = {10.1145/3236009},
   issn = {15577341},
   issue = {5},
   journal = {ACM Computing Surveys (CSUR)},
   keywords = {Open the black box,explanations,interpretability,transparent models},
   month = {8},
   publisher = {
		ACM
		PUB27
		New York, NY, USA
	},
   title = {A Survey of Methods for Explaining Black Box Models},
   volume = {51},
   url = {https://dl.acm.org/doi/10.1145/3236009},
   year = {2018},
}
@article{Jumper2021,
   abstract = {Proteins are essential to life, and understanding their structure can facilitate a mechanistic understanding of their function. Through an enormous experimental effort1–4, the structures of around 100,000 unique proteins have been determined5, but this represents a small fraction of the billions of known protein sequences6,7. Structural coverage is bottlenecked by the months to years of painstaking effort required to determine a single protein structure. Accurate computational approaches are needed to address this gap and to enable large-scale structural bioinformatics. Predicting the three-dimensional structure that a protein will adopt based solely on its amino acid sequence—the structure prediction component of the ‘protein folding problem’8—has been an important open research problem for more than 50&nbsp;years9. Despite recent progress10–14, existing methods fall far&nbsp;short of atomic accuracy, especially when no homologous structure is available. Here we provide the first computational method that can regularly predict protein structures with atomic accuracy even in cases in which no similar structure is known. We validated an entirely redesigned version of our neural network-based model, AlphaFold, in the challenging 14th Critical Assessment of protein Structure Prediction (CASP14)15, demonstrating accuracy competitive with experimental structures in a majority of cases and greatly outperforming other methods. Underpinning the latest version of AlphaFold is a novel machine learning approach that incorporates physical and biological knowledge about protein structure, leveraging multi-sequence alignments, into the design of the deep learning algorithm. AlphaFold predicts protein structures with an accuracy competitive with experimental structures in the majority of cases using a novel deep learning architecture.},
   author = {John Jumper and Richard Evans and Alexander Pritzel and Tim Green and Michael Figurnov and Olaf Ronneberger and Kathryn Tunyasuvunakool and Russ Bates and Augustin Žídek and Anna Potapenko and Alex Bridgland and Clemens Meyer and Simon A.A. Kohl and Andrew J. Ballard and Andrew Cowie and Bernardino Romera-Paredes and Stanislav Nikolov and Rishub Jain and Jonas Adler and Trevor Back and Stig Petersen and David Reiman and Ellen Clancy and Michal Zielinski and Martin Steinegger and Michalina Pacholska and Tamas Berghammer and Sebastian Bodenstein and David Silver and Oriol Vinyals and Andrew W. Senior and Koray Kavukcuoglu and Pushmeet Kohli and Demis Hassabis},
   doi = {10.1038/s41586-021-03819-2},
   issn = {1476-4687},
   issue = {7873},
   journal = {Nature 2021 596:7873},
   keywords = {Computational biophysics,Machine learning,Protein structure predictions,Structural biology},
   month = {7},
   pages = {583-589},
   pmid = {34265844},
   publisher = {Nature Publishing Group},
   title = {Highly accurate protein structure prediction with AlphaFold},
   volume = {596},
   url = {https://www.nature.com/articles/s41586-021-03819-2},
   year = {2021},
}
@article{Botstein2010,
   abstract = {Three articles from the early years of Molecular Biology of the Cell (MBoC) have had remarkably many citations in the literature since their publication ∼10 years ago. As a coauthor of these articles and the former editor of MBoC, I was asked for possible explanations. I believe the answer lies in the unusual nature of these articles: each presents and summarizes gene expression data for nearly every gene in the yeast or human genomes. Continuing interest in the data themselves by cell biologists, rather than results or conclusions drawn by the authors, best accounts for the citation history. The flatness of the numbers of citations over time, the continuing high rate of accesses to individual Web sites set up to allow searching and display of the underlying data, and the large fraction of citations in journals focused on mathematics and computation all support the same conclusion: it's the data. © 2009 by The American Society for Cell Biology.},
   author = {David Botstein},
   doi = {10.1091/MBC.E09-07-0575/ASSET/IMAGES/LARGE/ZMK0011092730001.JPEG},
   issn = {10591524},
   issue = {1},
   journal = {Molecular Biology of the Cell},
   month = {1},
   pages = {4-6},
   pmid = {20048255},
   publisher = { The American Society for Cell Biology},
   title = {It's the data!},
   volume = {21},
   url = {https://www.molbiolcell.org/doi/10.1091/mbc.e09-07-0575},
   year = {2010},
}
@web_page{EBI2021,
   title = {EMBL-EBI Highlights 2021},
   author={EMBL-EBI},
   year = 2021,
   url = {https://www.embl.org/documents/document/embl-ebi-highlights-2021/},
}
@web_page{EBI2012,
   title = {EMBL-EBI Annual Scientific Report 2012 – EMBL Documents},
   author={EMBL-EBI},
   year = {2012},
   url = {https://www.embl.org/documents/document/embl-ebi-annual-scientific-report-2012/},
}

@article{Royal2012,
   abstract = {The Royal Society calls for a shift in the attitude of scientists and others, including funders, research institutions and publishers, towards data accessibility, curation and dissemination.},
   author = {The {Royal Society}},
   doi = {10.1038/ncb2558},
   issn = {1476-4679},
   issue = {8},
   journal = {Nature Cell Biology 2012 14:8},
   keywords = {Publishing,Research data},
   month = {8},
   pages = {775-775},
   pmid = {22854808},
   publisher = {Nature Publishing Group},
   title = {The data deluge},
   volume = {14},
   url = {https://www.nature.com/articles/ncb2558},
   year = {2012},
}
@article{Leonelli2019,
   abstract = {The availability of big data has the potential to transform many areas of the life sciences and usher in new ways of doing research. Here, I argue that big data biology also raises fundamental questions in the philosophy of science: for example, what is a good dataset, and how can reliable knowledge be extracted from big data? Collaborations between biologists, data scientists and philosophers of science will help us to answer these and other questions.},
   author = {Sabina Leonelli},
   doi = {10.7554/ELIFE.47381},
   issn = {2050084X},
   journal = {eLife},
   month = {4},
   pmid = {30950793},
   publisher = {eLife Sciences Publications, Ltd},
   title = {The challenges of big data biology},
   volume = {8},
   url = {/pmc/articles/PMC6450665/ /pmc/articles/PMC6450665/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6450665/},
   year = {2019},
}

@article{Baker2016,
   author = {Monya Baker},
   doi = {10.1038/533452a},
   issn = {0028-0836},
   issue = {7604},
   journal = {Nature},
   month = {5},
   pages = {452-454},
   title = {1,500 scientists lift the lid on reproducibility},
   volume = {533},
   year = {2016},
}
@article{Trafimow2015,
   abstract = {The Basic and Applied Social Psychology (BASP) 2014 Editorial emphasized that the null hypothesis significance testing procedure (NHSTP) is invalid, and thus authors would be not required to perfor...},
   author = {David Trafimow and Michael Marks},
   doi = {10.1080/01973533.2015.1012991},
   issn = {01973533},
   issue = {1},
   journal = {https://doi.org/10.1080/01973533.2015.1012991},
   month = {1},
   pages = {1-2},
   publisher = { Taylor & Francis Group },
   title = {Editorial},
   volume = {37},
   url = {https://www.tandfonline.com/doi/abs/10.1080/01973533.2015.1012991},
   year = {2015},
}

@article{Garijo2013,
   abstract = {How easy is it to reproduce the results found in a typical computational biology paper? Either through experience or intuition the reader will already know that the answer is with difficulty or not at all. In this paper we attempt to quantify this difficulty by reproducing a previously published paper for different classes of users (ranging from users with little expertise to domain experts) and suggest ways in which the situation might be improved. Quantification is achieved by estimating the time required to reproduce each of the steps in the method described in the original paper and make them part of an explicit workflow that reproduces the original results. Reproducing the method took several months of effort, and required using new versions and new software that posed challenges to reconstructing and validating the results. The quantification leads to “reproducibility maps” that reveal that novice researchers would only be able to reproduce a few of the steps in the method, and that only expert researchers with advance knowledge of the domain would be able to reproduce the method in its entirety. The workflow itself is published as an online resource together with supporting software and data. The paper concludes with a brief discussion of the complexities of requiring reproducibility in terms of cost versus benefit, and a desiderata with our observations and guidelines for improving reproducibility. This has implications not only in reproducing the work of others from published papers, but reproducing work from one’s own laboratory.},
   author = {Daniel Garijo and Sarah Kinnings and Li Xie and Lei Xie and Yinliang Zhang and Philip E. Bourne and Yolanda Gil},
   doi = {10.1371/JOURNAL.PONE.0080278},
   issn = {1932-6203},
   issue = {11},
   journal = {PLOS ONE},
   keywords = {Computational biology,Computer software,Open source software,Protein structure,Protein structure comparison,Reproducibility,Scientists,Software tools},
   month = {11},
   pages = {e80278},
   pmid = {24312207},
   publisher = {Public Library of Science},
   title = {Quantifying Reproducibility in Computational Biology: The Case of the Tuberculosis Drugome},
   volume = {8},
   url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0080278},
   year = {2013},
}
@article{Ioannidis2009,
   abstract = {Four teams of analysts attempted exact reproduction of results of 18 microarray experiments published in the journal in 2005–2006 using the data and analytical methods detailed in the original publications. In addition to MIAME criteria, the authors recommend publication of an explicit record of the analytical protocols used. Given the complexity of microarray-based gene expression studies, guidelines encourage transparent design and public data availability. Several journals require public data deposition and several public databases exist. However, not all data are publicly available, and even when available, it is unknown whether the published results are reproducible by independent scientists. Here we evaluated the replication of data analyses in 18 articles on microarray-based gene expression profiling published in Nature Genetics in 2005–2006. One table or figure from each article was independently evaluated by two teams of analysts. We reproduced two analyses in principle and six partially or with some discrepancies; ten could not be reproduced. The main reason for failure to reproduce was data unavailability, and discrepancies were mostly due to incomplete data annotation or specification of data processing and analysis. Repeatability of published microarray studies is apparently limited. More strict publication rules enforcing public data availability and explicit description of data processing and analysis should be considered.},
   author = {John P.A. Ioannidis and David B. Allison and Catherine A. Ball and Issa Coulibaly and Xiangqin Cui and Aedín C. Culhane and Mario Falchi and Cesare Furlanello and Laurence Game and Giuseppe Jurman and Jon Mangion and Tapan Mehta and Michael Nitzberg and Grier P. Page and Enrico Petretto and Vera Van Noort},
   doi = {10.1038/ng.295},
   issn = {1546-1718},
   issue = {2},
   journal = {Nature Genetics 2009 41:2},
   keywords = {Agriculture,Animal Genetics and Genomics,Biomedicine,Cancer Research,Gene Function,Human Genetics,general},
   month = {1},
   pages = {149-155},
   pmid = {19174838},
   publisher = {Nature Publishing Group},
   title = {Repeatability of published microarray gene expression analyses},
   volume = {41},
   url = {https://www.nature.com/articles/ng.295},
   year = {2009},
}
@article{Chattopadhyay2019,
   abstract = {Identified genetic variants from genome wide association studies frequently show only modest effects on the disease risk, leading to the "missing heritability" problem. An avenue, to account for a part of this "missingness" is to evaluate gene-gene interactions (epistasis) thereby elucidating their effect on complex diseases. This can potentially help with identifying gene functions, pathways, and drug targets. However, the exhaustive evaluation of all possible genetic interactions among millions of single nucleotide polymorphisms (SNPs) raises several issues, otherwise known as the "curse of dimensionality". The dimensionality involved in the epistatic analysis of such exponentially growing SNPs diminishes the usefulness of traditional, parametric statistical methods. With the immense popularity of multifactor dimensionality reduction (MDR), a non-parametric method, proposed in 2001, that classifies multi-dimensional genotypes into one-dimensional binary approaches, led to the emergence of a fast-growing collection of methods that were based on the MDR approach. Moreover, machine-learning (ML) methods such as random forests and neural networks (NNs), deep-learning (DL) approaches, and hybrid approaches have also been applied profusely, in the recent years, to tackle this dimensionality issue associated with whole genome gene-gene interaction studies. However, exhaustive searching in MDR based approaches or variable selection in ML methods, still pose the risk of missing out on relevant SNPs. Furthermore, interpretability issues are a major hindrance for DL methods. To minimize this loss of information, Python based tools such as PySpark can potentially take advantage of distributed computing resources in the cloud, to bring back smaller subsets of data for further local analysis. Parallel computing can be a powerful resource that stands to fight this "curse". PySpark supports all standard Python libraries and C extensions thus making it convenient to write codes to deliver dramatic improvements in processing speed for extraordinarily large sets of data.},
   author = {Amrita Chattopadhyay and Tzu-Pin Lu},
   doi = {10.21037/ATM.2019.12.87},
   issn = {23055839},
   issue = {24},
   journal = {Annals of Translational Medicine},
   keywords = {Gene-gene interaction,PySpark,deep-learning (DL),machine-learning (ML),multifactor dimensionality reduction (MDR),parallel computing},
   month = {12},
   pages = {813-813},
   pmid = {32042829},
   publisher = {AME Publications},
   title = {Gene-gene interaction: the curse of dimensionality},
   volume = {7},
   url = {/pmc/articles/PMC6989881/ /pmc/articles/PMC6989881/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6989881/},
   year = {2019},
}
@article{Cortes2015,
   abstract = {To date, no systematic study has assessed the effect of random experimental errors on the predictive power of QSAR models. To address this shortage, we have benchmarked the noise sensitivity of 12 learning algorithms on 12 data sets (15,840 models in total), namely the following: Support Vector Machines (SVM) with radial and polynomial (Poly) kernels, Gaussian Process (GP) with radial and polynomial kernels, Relevant Vector Machines (radial kernel), Random Forest (RF), Gradient Boosting Machines (GBM), Bagged Regression Trees, Partial Least Squares, and k-Nearest Neighbors. Model performance on the test set was used as a proxy to monitor the relative noise sensitivity of these algorithms as a function of the level of simulated noise added to the bioactivities from the training set. The noise was simulated by sampling from Gaussian distributions with increasingly larger variances, which ranged from zero to the range of pIC50 values comprised in a given data set. General trends were identified by designing a full-factorial experiment, which was analyzed with a normal linear model. Overall, GBM displayed low noise tolerance, although its performance was comparable to RF, SVM Radial, SVM Poly, GP Poly, and GP Radial at low noise levels. Of practical relevance, we show that the bag fraction parameter has a marked influence on the noise sensitivity of GBM, suggesting that low values (e.g., 0.1-0.2) for this parameter should be set when modeling noisy data. The remaining 11 algorithms display a comparable noise tolerance, as a smooth and linear degradation of model performance is observed with the level of noise. However, SVM Poly and GP Poly display significant noise sensitivity at high noise levels in some cases. Overall, these results provide a practical guide to make informed decisions about which algorithm and parameter values to use according to the noise level present in the data. (Graph Presented).},
   author = {Isidro Cortes-Ciriano and Andreas Bender and Thérèse E. Malliavin},
   doi = {10.1021/ACS.JCIM.5B00101/ASSET/IMAGES/LARGE/CI-2015-00101E_0002.JPEG},
   issn = {1549960X},
   issue = {7},
   journal = {Journal of Chemical Information and Modeling},
   month = {7},
   pages = {1413-1425},
   pmid = {26038978},
   publisher = {American Chemical Society},
   title = {Comparing the Influence of Simulated Experimental Errors on 12 Machine Learning Algorithms in Bioactivity Modeling Using 12 Diverse Data Sets},
   volume = {55},
   url = {https://pubs.acs.org/doi/full/10.1021/acs.jcim.5b00101},
   year = {2015},
}
@article{Kaiser2019,
   abstract = {Machine learning continues to make strident advances in the prediction of desired properties concerning drug development. Problematically, the efficacy of machine learning in these arenas is reliant upon highly accurate and abundant data. These two limitations, high accuracy and abundance, are often taken together; however, insight into the dataset accuracy limitation of contemporary machine learning algorithms may yield insight into whether non-bench experimental sources of data may be used to generate useful machine learning models where there is a paucity of experimental data. We took highly accurate data across six kinase types, one GPCR, one polymerase, a human protease, and HIV protease, and intentionally introduced error at varying population proportions in the datasets for each target. With the generated error in the data, we explored how the retrospective accuracy of a Na&iuml;ve Bayes Network, a Random Forest Model, and a Probabilistic Neural Network model decayed as a function of error. Additionally, we explored the ability of a training dataset with an error profile resembling that produced by the Free Energy Perturbation method (FEP+) to generate machine learning models with useful retrospective capabilities. The categorical error tolerance was quite high for a Na&iuml;ve Bayes Network algorithm averaging 39% error in the training set required to lose predictivity on the test set. Additionally, a Random Forest tolerated a significant degree of categorical error introduced into the training set with an average error of 29% required to lose predictivity. However, we found the Probabilistic Neural Network algorithm did not tolerate as much categorical error requiring an average of 20% error to lose predictivity. Finally, we found that a Na&iuml;ve Bayes Network and a Random Forest could both use datasets with an error profile resembling that of FEP+. This work demonstrates that computational methods of known error distribution like FEP+ may be useful in generating machine learning models not based on extensive and expensive in vitro-generated datasets.},
   author = {Thomas M. Kaiser and Pieter B. Burger},
   doi = {10.3390/MOLECULES24112115},
   issn = {1420-3049},
   issue = {11},
   journal = {Molecules 2019, Vol. 24, Page 2115},
   keywords = {FEP,Naïve Bayes Network,Neural Network,Random Forest,anaplastic lymphoma kinase (ALK),cheminformatics,drug discovery,error,machine learning},
   month = {6},
   pages = {2115},
   pmid = {31167452},
   publisher = {Multidisciplinary Digital Publishing Institute},
   title = {Error Tolerance of Machine Learning Algorithms across Contemporary Biological Targets},
   volume = {24},
   url = {https://www.mdpi.com/1420-3049/24/11/2115/htm https://www.mdpi.com/1420-3049/24/11/2115},
   year = {2019},
}
@article{Schmitt2021,
   abstract = {Background: An increasing number of studies within digital pathology show the potential of artificial intelligence (AI) to diagnose cancer using histological whole slide images, which requires large and diverse data sets. While diversification may result in more generalizable AI-based systems, it can also introduce hidden variables. If neural networks are able to distinguish/learn hidden variables, these variables can introduce batch effects that compromise the accuracy of classification systems.
Objective: The objective of the study was to analyze the learnability of an exemplary selection of hidden variables (patient age, slide preparation date, slide origin, and scanner type) that are commonly found in whole slide image data sets in digital pathology and could create batch effects.
Methods: We trained four separate convolutional neural networks (CNNs) to learn four variables using a data set of digitized whole slide melanoma images from five different institutes. For robustness, each CNN training and evaluation run was repeated multiple times, and a variable was only considered learnable if the lower bound of the 95% confidence interval of its mean balanced accuracy was above 50.0%.
Results: A mean balanced accuracy above 50.0% was achieved for all four tasks, even when considering the lower bound of the 95% confidence interval. Performance between tasks showed wide variation, ranging from 56.1% (slide preparation date) to 100% (slide origin).
Conclusions: Because all of the analyzed hidden variables are learnable, they have the potential to create batch effects in dermatopathology data sets, which negatively affect AI-based classification systems. Practitioners should be aware of these and similar pitfalls when developing and evaluating such systems and address these and potentially other batch effect variables in their data sets through sufficient data set stratification.},
   author = {Max Schmitt and Roman Christoph Maron and Achim Hekler and Albrecht Stenzinger and Axel Hauschild and Michael Weichenthal and Markus Tiemann and Dieter Krahl and Heinz Kutzner and Jochen Sven Utikal and Sebastian Haferkamp and Jakob Nikolas Kather and Frederick Klauschen and Eva Krieghoff-Henning and Stefan Fröhling and Christof von Kalle and Titus Josef Brinker},
   doi = {10.2196/23436},
   issn = {14388871},
   issue = {2},
   journal = {J Med Internet Res 2021;23(2):e23436 https://www.jmir.org/2021/2/e23436},
   keywords = {artifacts,artificial intelligence,clinical pathology,convolutional neural networks,deep learning,digital pathology,machine learning,neural networks,pathology,pitfalls},
   month = {2},
   pages = {e23436},
   pmid = {33528370},
   publisher = {Journal of Medical Internet Research},
   title = {Hidden Variables in Deep Learning Digital Pathology and Their Potential to Cause Batch Effects: Prediction Model Study},
   volume = {23},
   url = {https://www.jmir.org/2021/2/e23436},
   year = {2021},
}
@article{Tang2019,
   abstract = {Extracting inherent valuable knowledge from omics big data remains as a daunting problem in bioinformatics and computational biology. Deep learning, as an emerging branch from machine learning, has exhibited unprecedented performance in quite a few applications from academia and industry. We highlight the difference and similarity in widely utilized models in deep learning studies, through discussing their basic structures, and reviewing diverse applications and disadvantages. We anticipate the work can serve as a meaningful perspective for further development of its theory, algorithm and application in bioinformatic and computational biology.},
   author = {Binhua Tang and Zixiang Pan and Kang Yin and Asif Khateeb},
   doi = {10.3389/FGENE.2019.00214/BIBTEX},
   issn = {16648021},
   issue = {MAR},
   journal = {Frontiers in Genetics},
   keywords = {Algorithm,Application,Bioinformatics,Computational biology,Deep learning},
   pages = {214},
   publisher = {Frontiers Media S.A.},
   title = {Recent advances of deep learning in bioinformatics and computational biology},
   volume = {10},
   year = {2019},
}
@article{Liang2015,
   abstract = {Identification of cancer subtypes plays an important role in revealing useful insights into disease pathogenesis and advancing personalized therapy. The recent development of high-throughput sequencing technologies has enabled the rapid collection of multi-platform genomic data (e.g., gene expression, miRNA expression, and DNA methylation) for the same set of tumor samples. Although numerous integrative clustering approaches have been developed to analyze cancer data, few of them are particularly designed to exploit both deep intrinsic statistical properties of each input modality and complex cross-modality correlations among multi-platform input data. In this paper, we propose a new machine learning model, called multimodal deep belief network (DBN), to cluster cancer patients from multi-platform observation data. In our integrative clustering framework, relationships among inherent features of each single modality are first encoded into multiple layers of hidden variables, and then a joint latent model is employed to fuse common features derived from multiple input modalities. A practical learning algorithm, called contrastive divergence (CD), is applied to infer the parameters of our multimodal DBN model in an unsupervised manner. Tests on two available cancer datasets show that our integrative data analysis approach can effectively extract a unified representation of latent features to capture both intra- and cross-modality correlations, and identify meaningful disease subtypes from multi-platform cancer data. In addition, our approach can identify key genes and miRNAs that may play distinct roles in the pathogenesis of different cancer subtypes. Among those key miRNAs, we found that the expression level of miR-29a is highly correlated with survival time in ovarian cancer patients. These results indicate that our multimodal DBN based data analysis approach may have practical applications in cancer pathogenesis studies and provide useful guidelines for personalized cancer therapy.},
   author = {Muxuan Liang and Zhizhong Li and Ting Chen and Jianyang Zeng},
   doi = {10.1109/TCBB.2014.2377729},
   issn = {15455963},
   issue = {4},
   journal = {IEEE/ACM Transactions on Computational Biology and Bioinformatics},
   keywords = {Multi-platform cancer data analysis,clinical data,genomic data,identification of cancer subtypes,multimodal deep belief network,restricted Boltzmann machine},
   month = {7},
   pages = {928-937},
   pmid = {26357333},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Integrative Data Analysis of Multi-Platform Cancer Data with a Multimodal Deep Learning Approach},
   volume = {12},
   year = {2015},
}
@article{Xie2017,
   abstract = {Background: Gene expression is a key intermediate level that genotypes lead to a particular trait. Gene expression is affected by various factors including genotypes of genetic variants. With an aim of delineating the genetic impact on gene expression, we build a deep auto-encoder model to assess how good genetic variants will contribute to gene expression changes. This new deep learning model is a regression-based predictive model based on the MultiLayer Perceptron and Stacked Denoising Auto-encoder (MLP-SAE). The model is trained using a stacked denoising auto-encoder for feature selection and a multilayer perceptron framework for backpropagation. We further improve the model by introducing dropout to prevent overfitting and improve performance. Results: To demonstrate the usage of this model, we apply MLP-SAE to a real genomic datasets with genotypes and gene expression profiles measured in yeast. Our results show that the MLP-SAE model with dropout outperforms other models including Lasso, Random Forests and the MLP-SAE model without dropout. Using the MLP-SAE model with dropout, we show that gene expression quantifications predicted by the model solely based on genotypes, align well with true gene expression patterns. Conclusion: We provide a deep auto-encoder model for predicting gene expression from SNP genotypes. This study demonstrates that deep learning is appropriate for tackling another genomic problem, i.e., building predictive models to understand genotypes' contribution to gene expression. With the emerging availability of richer genomic data, we anticipate that deep learning models play a bigger role in modeling and interpreting genomics.},
   author = {Rui Xie and Jia Wen and Andrew Quitadamo and Jianlin Cheng and Xinghua Shi},
   doi = {10.1186/S12864-017-4226-0/FIGURES/6},
   issn = {14712164},
   issue = {9},
   journal = {BMC Genomics},
   keywords = {Deep learning,Gene expression,Multilayer perceptron,Predictive model,Stacked denoising auto-encoder},
   month = {11},
   pages = {39-49},
   pmid = {29219072},
   publisher = {BioMed Central Ltd.},
   title = {A deep auto-encoder model for gene expression prediction},
   volume = {18},
   url = {https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-017-4226-0},
   year = {2017},
}
@article{Caruana2015,
   abstract = {In machine learning often a tradeoff must be made between accuracy and intelligibility. More accurate models such as boosted trees, random forests, and neural nets usually are not intelligible, but more intelligible models such as logistic regression, naive-Bayes, and single decision trees often have significantly worse accuracy. This tradeoff sometimes limits the accuracy of models that can be applied in mission-critical applications such as healthcare where being able to understand, validate, edit, and trust a learned model is important. We present two case studies where high-performance generalized additive models with pairwise interactions (GA2Ms) are applied to real healthcare problems yielding intelligible models with state-of-the-art accuracy. In the pneumonia risk prediction case study, the intelligible model uncovers surprising patterns in the data that previously had prevented complex learned models from being fielded in this domain, but because it is intelligible and modular allows these patterns to be recognized and removed. In the 30-day hospital readmission case study, we show that the same methods scale to large datasets containing hundreds of thousands of patients and thousands of attributes while remaining intelligible and providing accuracy comparable to the best (unintelligible) machine learning methods.},
   author = {Rich Caruana and Yin Lou and Johannes Gehrke and Paul Koch and Marc Sturm and Noémie Elhadad},
   doi = {10.1145/2783258.2788613},
   isbn = {9781450336642},
   journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
   keywords = {Additive models,Classification,Healthcare,Intelligibility,Interaction detection,Logistic regression,Risk prediction},
   month = {8},
   pages = {1721-1730},
   publisher = {Association for Computing Machinery},
   title = {Intelligible Models for HealthCare: Predicting Pneumonia Risk and Hospital 30-day Readmission},
   volume = {2015-August},
   url = {https://www.microsoft.com/en-us/research/publication/intelligible-models-healthcare-predicting-pneumonia-risk-hospital-30-day-readmission/},
   year = {2015},
}
@article{Ribeiro2016,
   abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an in-terpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
   year = {2016},
   author = {Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin},
   city = {New York, NY, USA},
   doi = {10.1145/2939672},
   isbn = {9781450342322},
   journal = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
   publisher = {ACM},
   title = {"Why Should I Trust You?" Explaining the Predictions of Any Classifier},
   url = {http://dx.doi.org/10.1145/2939672.2939778},
}
@article{Wu2015,
   abstract = {A drastic amount of data have been and are being generated in bioinformatics studies. In the analysis of such data, the standard modeling approaches can be challenged by the heavy-tailed errors and outliers in response variables, the contamination in predictors (which may be caused by, for instance, technical problems in microarray gene expression studies), model mis-specification and others. Robust methods are needed to tackle these challenges. When there are a large number of predictors, variable selection can be as important as estimation. As a generic variable selection and regularization tool, penalization has been extensively adopted. In this article, we provide a selective review of robust penalized variable selection approaches especially designed for high-dimensional data from bioinformatics and biomedical studies. We discuss the robust loss functions, penalty functions and computational algorithms. The theoretical properties and implementation are also briefly examined. Application examples of the robust penalization approaches in representative bioinformatics and biomedical studies are also illustrated.},
   author = {Cen Wu and Shuangge Ma},
   doi = {10.1093/BIB/BBU046},
   issn = {1467-5463},
   issue = {5},
   journal = {Briefings in Bioinformatics},
   keywords = {Bioinformatics study,Penalization,Variable selection,robust methods},
   month = {9},
   pages = {873-883},
   pmid = {25479793},
   publisher = {Oxford Academic},
   title = {A selective review of robust variable selection with applications in bioinformatics},
   volume = {16},
   url = {https://academic.oup.com/bib/article/16/5/873/217215},
   year = {2015},
}
@article{Wall2005,
   abstract = {This chapter describes gene expression analysis by Singular Value Decomposition (SVD), emphasizing initial characterization of the data. We describe SVD methods for visualization of gene expression data, representation of the data using a smaller number of variables, and detection of patterns in noisy gene expression data. In addition, we describe the precise relation between SVD analysis and Principal Component Analysis (PCA) when PCA is calculated using the covariance matrix, enabling our descriptions to apply equally well to either method. Our aim is to provide definitions, interpretations, examples, and references that will serve as resources for understanding and extending the application of SVD and PCA to gene expression analysis.},
   author = {Michael E. Wall and Andreas Rechtsteiner and Luis M. Rocha},
   doi = {10.1007/0-306-47815-3_5/COVER},
   journal = {A Practical Approach to Microarray Data Analysis},
   month = {12},
   pages = {91-109},
   publisher = {Kluwer Academic Publishers},
   title = {Singular Value Decomposition and Principal Component Analysis},
   url = {https://link.springer.com/chapter/10.1007/0-306-47815-3_5},
   year = {2005},
}
@article{Molinaro2005,
   abstract = {Motivation: In genomic studies, thousands of features are collected on relatively few samples. One of the goals of these studies is to build classifiers to predict the outcome of future observations. There are three inherent steps to this process: feature selection, model selection and prediction assessment. With a focus on prediction assessment, we compare several methods for estimating the 'true' prediction error of a prediction model in the presence of feature selection. Results: For small studies where features are selected from thousands of candidates, the resubstitution and simple split-sample estimates are seriously biased. In these small samples, leave-one-out cross-validation (LOOCV), 10-fold cross-validation (CV) and the .632+ bootstrap have the smallest bias for diagonal discriminant analysis, nearest neighbor and classification trees. LOOCV and 10-fold CV have the smallest bias for linear discriminant analysis. Additionally, LOOCV, 5- and 10-fold CV, and the .632+ bootstrap have the lowest mean square error. The .632+ bootstrap is quite biased in small sample sizes with strong signal-to-noise ratios. Differences in performance among resampling methods are reduced as the number of specimens available increase.},
   author = {Annette M. Molinaro and Richard Simon and Ruth M. Pfeiffer},
   doi = {10.1093/BIOINFORMATICS/BTI499},
   issn = {1367-4803},
   issue = {15},
   journal = {Bioinformatics},
   month = {8},
   pages = {3301-3307},
   pmid = {15905277},
   publisher = {Oxford Academic},
   title = {Prediction error estimation: a comparison of resampling methods},
   volume = {21},
   url = {https://academic.oup.com/bioinformatics/article/21/15/3301/195433},
   year = {2005},
}
@article{Lawlor2015,
   abstract = {There is a lack of software engineering skills in bioinformatic contexts. We discuss the consequences of this lack, examine existing explanations and remedies to the problem, point out their shortc...},
   author = {Brendan Lawlor and Paul Walsh},
   doi = {10.1080/21655979.2015.1050162},
   issn = {21655987},
   issue = {4},
   journal = {http://dx.doi.org/10.1080/21655979.2015.1050162},
   keywords = {bioinformatics,microbial biotechnology,process,software,software engineering,survey},
   month = {1},
   pages = {193-203},
   pmid = {25996054},
   publisher = {Taylor & Francis},
   title = {Engineering bioinformatics: building reliability, performance and productivity into bioinformatics software},
   volume = {6},
   url = {https://www.tandfonline.com/doi/abs/10.1080/21655979.2015.1050162},
   year = {2015},
}
@article{Ching2018,
   abstract = {Deep learning describes a class of machine learning algorithms that are capable of combining raw inputs into layers of intermediate features. These algorithms have recently shown impressive results...},
   author = {Travers Ching and Daniel S. Himmelstein and Brett K. Beaulieu-Jones and Alexandr A. Kalinin and Brian T. Do and Gregory P. Way and Enrico Ferrero and Paul Michael Agapow and Michael Zietz and Michael M. Hoffman and Wei Xie and Gail L. Rosen and Benjamin J. Lengerich and Johnny Israeli and Jack Lanchantin and Stephen Woloszynek and Anne E. Carpenter and Avanti Shrikumar and Jinbo Xu and Evan M. Cofer and Christopher A. Lavender and Srinivas C. Turaga and Amr M. Alexandari and Zhiyong Lu and David J. Harris and Dave Decaprio and Yanjun Qi and Anshul Kundaje and Yifan Peng and Laura K. Wiley and Marwin H.S. Segler and Simina M. Boca and S. Joshua Swamidass and Austin Huang and Anthony Gitter and Casey S. Greene},
   doi = {10.1098/RSIF.2017.0387},
   issn = {17425662},
   issue = {141},
   journal = {Journal of The Royal Society Interface},
   keywords = {deep learning,genomics,machine learning,precision medicine},
   pmid = {29618526},
   publisher = {
The Royal Society
},
   title = {Opportunities and obstacles for deep learning in biology and medicine},
   volume = {15},
   url = {https://royalsocietypublishing.org/doi/10.1098/rsif.2017.0387},
   year = {2018},
}
@article{Prins2015,
   author = {Pjotr Prins and Joep De Ligt and Artem Tarasov and Ritsert C. Jansen and Edwin Cuppen and Philip E. Bourne},
   doi = {10.1038/nbt.3240},
   issn = {1546-1696},
   issue = {7},
   journal = {Nature Biotechnology 2015 33:7},
   keywords = {Careers,Data mining,Genome informatics,Software},
   month = {7},
   pages = {686-687},
   pmid = {26154002},
   publisher = {Nature Publishing Group},
   title = {Toward effective software solutions for big biology},
   volume = {33},
   url = {https://www.nature.com/articles/nbt.3240},
   year = {2015},
}
@article{Attwood2019,
   abstract = {Bioinformatics is now intrinsic to life science research, but the past decade has witnessed a continuing deficiency in this essential expertise. Basic data stewardship is still taught relatively rarely in life science education programmes, creating a chasm between theory and practice, and fuelling demand for bioinformatics training across all educational levels and career roles. Concerned by this, surveys have been conducted in recent years to monitor bioinformatics and computational training needs worldwide. This article briefly reviews the principal findings of a number of these studies. We see that there is still a strong appetite for short courses to improve expertise and confidence in data analysis and interpretation; strikingly, however, the most urgent appeal is for bioinformatics to be woven into the fabric of life science degree programmes. Satisfying the relentless training needs of current and future generations of life scientists will require a concerted response from stakeholders across the globe, who need to deliver sustainable solutions capable of both transforming education curricula and cultivating a new cadre of trainer scientists.},
   author = {Teresa K. Attwood and Sarah Blackford and Michelle D. Brazas and Angela Davies and Maria Victoria Schneider},
   doi = {10.1093/BIB/BBX100},
   issn = {1467-5463},
   issue = {2},
   journal = {Briefings in Bioinformatics},
   keywords = {bioinformatics training,computational and statistical competency,data science,skills gap,training survey,training trainers},
   month = {3},
   pages = {398-404},
   pmid = {28968751},
   publisher = {Oxford Academic},
   title = {A global perspective on evolving bioinformatics and data science training needs},
   volume = {20},
   url = {https://academic.oup.com/bib/article/20/2/398/4096809},
   year = {2019},
}
@article{Walker2002,
   abstract = {in the mid 1990s for the analysis and quantifica-tion of nucleic acids, real-time PCR is a molecular biological technique gaining rapidly in popularity. It is based on the technique of the polymerase chain reaction (PCR) that was first envisioned by Kary Mullis almost 20 years ago, during a moonlit drive through the redwood hills of California (1). The technology of PCR (2) has become one of the most influential discoveries of the molecular biology revolution and one for which Mullis received the Nobel Prize in 1993. Because of the impact of PCR and the thermostable Taq DNA polymerase (the enzyme responsible for the PCR revolution), the pair was named as the first "Molecule of the Year" by Science in 1989 (3). In many ways, the recent development of real-time PCR seems set to change the general use of PCR. The advancement provided by the real-time version of PCR is due to its unique ability to monitor the complete DNA amplification process. During conventional PCR, the two strands of a DNA molecule are subjected to a series of heating and cooling cycles that result in DNA strand separation, oligonucleotide primer anneal-ing, and thermostable Taq DNA polymerase-directed primer extension, ultimately generating two identical daughter strands. Iterative cycling of the process exponentially amplifies the number of original DNA molecules, hence the term PCR (4). After completion of the PCR reaction, amplification products are analyzed by size-fractionation of the amplified sample with the use of gel electrophoresis. In the mid 1990s, researchers showed that the 5′ nuclease activity of the Taq DNA polymerase could be exploited as a method to indirectly assess the level of DNA amplification with the use of specific fluorescent probes (5), eliminating the need for electrophoresis. Around the same time, researchers showed that real-time monitoring of the DNA amplification within the PCR reaction tube during the PCR could be achieved by using fluorescent DNA binding dyes, which is known as kinetic PCR (6). The coupling of these two processes (7, 8) led to today's technology of fluorescence detection real-time PCR. In general, analysis of amplification during real-time PCR has been achieved by detecting the fluorescence that is either directly or indirectly associated with the accumulation of the newly amplified DNA (see figure, above). The detection system that is almost synonymous with real-time PCR is the "Taqman" system (8), which uses a fluorescence resonance energy transfer (FRET) probe as a reporter system. A FRET probe is a short oligonucleotide that is complementary to one of the strands. The probe contains a "reporter" and a "quencher" fluorescent molecule at the 5′ and 3′ end of the probe, respectively. This probe is included in the real-time PCR reaction along with the required forward and reverse PCR primers. The quencher fluorochrome on the probe, because it is in such close proximity to the reporter, is able to quench the fluorescence of the reporter. As the Taq DNA polymerase enzyme replicates the new strand of DNA, the nuclease activity degrades the FRET probe at the 5′ end, which is bound to template DNA strand, in a manner much like the PacMan video game character. This degradation releases the reporter fluorochrome from its proximity to the quencher, resulting in fluorescence of the reporter. Accumulation of fluorescent reporter molecules, as a result of amplification of the target, can then be detected by an appropriate optical sensing system such as the Taqman, an "indirect" system that detects the accumulation of fluorescence rather than the amplified DNA itself. In contrast, a commonly used "direct" method uses a fluorescent DNA (SYBR green) that binds nonspecifically to double-stranded DNA, and the accumulation of the fluorescence bound to the amplified DNA target is measured. The "Molecular Beacon" technology is another direct approach that uses FRET-based fluorescent probes to bind the amplified DNA. In the unbound state, the quencher and reporter fluorochromes are maintained in close proximity via a hairpin loop designed into the sequence of the probe. Binding of the probe at a target sequence-specific region to its complementary strand on the amplified target DNA separates the two fluorochromes, thereby alleviating the FRET interference and allowing the reporter to fluoresce. Related systems that use FRET-based PCR primers incorporated into the amplified DNA have also been developed (9). In these systems, the reporter and quencher fluorochromes are maintained in a hairpin loop structure via a sequence that is added to the 5′ end of one of the PCR primers. Disruption of the hairpin loop structure during incorporation of the primer into the amplified DNA product results in loss of the FRET interference, leading to fluorescence of the reporter molecule. Choosing a detection system is a major consideration in developing a real-time PCR assay, and each type of system has its pros and cons. The decision is often a compromise between desired specificity, assay development time, and cost per assay. An inherent property of PCR that is exploited in real-time PCR is that the more copies of nucleic acid one starts with, the fewer cycles of template amplification it takes to make a specific number of},
   author = {Nigel J. Walker},
   doi = {10.1126/SCIENCE.296.5567.557/ASSET/61F189A9-ECD5-4BD8-A350-BF5523C6FC15/ASSETS/GRAPHIC/557-3.GIF},
   issn = {00368075},
   issue = {5567},
   journal = {Science},
   month = {4},
   pmid = {11964485},
   publisher = {American Association for the Advancement of Science},
   title = {A technique whose time has come},
   volume = {296},
   url = {https://www.science.org/doi/10.1126/science.296.5567.557},
   year = {2002},
}
@article{Dreier2022,
   abstract = {Background: Next-generation sequencing (NGS) methods and especially 16S rRNA gene amplicon sequencing have become indispensable tools in microbial ecology. While they have opened up new possibilities for studying microbial communities, they also have one drawback, namely providing only relative abundances and thus compositional data. Quantitative PCR (qPCR) has been used for years for the quantification of bacteria. However, this method requires the development of specific primers and has a low throughput. The constraint of low throughput has recently been overcome by the development of high-throughput qPCR (HT-qPCR), which allows for the simultaneous detection of the most prevalent bacteria in moderately complex systems, such as cheese and other fermented dairy foods. In the present study, the performance of the two approaches, NGS and HT-qPCR, was compared by analyzing the same DNA samples from 21 Raclette du Valais protected designation of origin (PDO) cheeses. Based on the results obtained, the differences, accuracy, and usefulness of the two approaches were studied in detail. Results: The results obtained using NGS (non-targeted) and HT-qPCR (targeted) show considerable agreement in determining the microbial composition of the cheese DNA samples studied, albeit the fundamentally different nature of these two approaches. A few inconsistencies in species detection were observed, particularly for less abundant ones. The detailed comparison of the results for 15 bacterial species/groups measured by both methods revealed a considerable bias for certain bacterial species in the measurements of the amplicon sequencing approach. We identified as probable origin to this PCR bias due to primer mismatches, variations in the number of copies for the 16S rRNA gene, and bias introduced in the bioinformatics analysis. Conclusion: As the normalized microbial composition results of NGS and HT-qPCR agreed for most of the 21 cheese samples analyzed, both methods can be considered as complementary and reliable for studying the microbial composition of cheese. Their combined application proved to be very helpful in identifying potential biases and overcoming methodological limitations in the quantitative analysis of the cheese microbiota.},
   author = {Matthias Dreier and Marco Meola and Hélène Berthoud and Noam Shani and Daniel Wechsler and Pilar Junier},
   doi = {10.1186/S12866-022-02451-Y},
   issn = {1471-2180},
   issue = {1},
   journal = {BMC microbiology},
   keywords = {16S / genetics*,Bacteria / classification,Bacteria / genetics*,Bacteria / isolation & purification,Bacterial / genetics,Cheese / microbiology*,Computational Biology,DNA,High-Throughput Nucleotide Sequencing / methods*,High-Throughput Screening Assays / methods,MEDLINE,Marco Meola,Matthias Dreier,Microbiota / genetics*,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,PMC8819918,Pilar Junier,PubMed Abstract,RNA,Real-Time Polymerase Chain Reaction / methods*,Ribosomal,Sequence Analysis,doi:10.1186/s12866-022-02451-y,pmid:35130830},
   month = {12},
   pmid = {35130830},
   publisher = {BMC Microbiol},
   title = {High-throughput qPCR and 16S rRNA gene amplicon sequencing as complementary methods for the investigation of the cheese microbiota},
   volume = {22},
   url = {https://pubmed.ncbi.nlm.nih.gov/35130830/},
   year = {2022},
}
@article{Swillens2008,
   abstract = {Amplification of a cDNA product by quantitative polymerase chain reaction (qPCR) gives rise to fluorescence sigmoidal curves from which absolute or relative target gene content of the sample is inferred. Besides comparative Ct methods that require the construction of a reference standard curve, other methods that focus on the analysis of the sole amplification curve have been proposed more recently. Among them, the so-called sigmoidal curve fitting (SCF) method rests on the fitting of an empirical sigmoidal model to the experimental amplification data points, leading to the prediction of the amplification efficiency and to the calculation of the initial copy number in the sample. The implicit assumption of this method is that the sigmoidal model may describe an amplification curve quantitatively even in the portion of the curve where the fluorescence signal is hidden in the noise band. The theoretical basis of the SCF method was revisited here for defining the class of experimental amplification curves for which the method might be relevant. Applying the SCF method to six well-characterized different PCR assays illustrated possible pitfalls leading to biased estimates of the amplification efficiency and, thus, of the target gene content of a sample. © 2007 Elsevier Inc. All rights reserved.},
   author = {Stéphane Swillens and Barbara Dessars and Hakim El Housni},
   doi = {10.1016/J.AB.2007.10.019},
   issn = {0003-2697},
   issue = {2},
   journal = {Analytical Biochemistry},
   keywords = {Amplification efficiency,Quantitative real-time PCR,SCF method,Sigmoidal curve fitting,Sigmoidal model},
   month = {2},
   pages = {370-376},
   pmid = {17996715},
   publisher = {Academic Press},
   title = {Revisiting the sigmoidal curve fitting applied to quantitative real-time PCR data},
   volume = {373},
   year = {2008},
}
@article{Schena1995,
   abstract = {A high-capacity system was developed to monitor the expression of many genes in parallel. Microarrays prepared by high-speed robotic printing of complementary DNAs on glass were used for quantitative expression measurements of the corresponding genes. Because of the small format and high density of the arrays, hybridization volumes of 2 microliters could be used that enabled detection of rare transcripts in probe mixtures derived from 2 micrograms of total cellular messenger RNA. Differential expression measurements of 45 Arabidopsis genes were made by means of simultaneous, two-color fluorescence hybridization.},
   author = {Mark Schena and Dari Shalon and Ronald W. Davis and Patrick O. Brown},
   doi = {10.1126/SCIENCE.270.5235.467},
   issn = {00368075},
   issue = {5235},
   journal = {Science},
   pages = {467-470},
   pmid = {7569999},
   title = {Quantitative monitoring of gene expression patterns with a complementary DNA microarray},
   volume = {270},
   url = {https://www.science.org},
   year = {1995},
}
@article{Gasch2000,
   abstract = {We explored genomic expression patterns in the yeast Saccharomyces cerevisiae responding to diverse environmental transitions. DNA microarrays were used to measure changes in transcript levels over time for almost every yeast gene, as cells responded to temperature shocks, hydrogen peroxide, the superoxide-generating drug menadione, the sulfhydryl-oxidizing agent diamide, the disulfide-reducing agent dithiothreitol, hyper- and hypo-osmotic shock, amino acid starvation, nitrogen source depletion, and progression into stationary phase. A large set of genes (~ 900) showed a similar drastic response to almost all of these environmental changes. Additional features of the genomic responses were specialized for specific conditions. Promoter analysis and subsequent characterization of the responses of mutant strains implicated the transcription factors Yap1p, as well as Msn2p and Msn4p, in mediating specific features of the transcriptional response, while the identification of novel sequence elements provided clues to novel regulators. Physiological themes in the genomic responses to specific environmental stresses provided insights into the effects of those stresses on the cell.},
   author = {A. P. Gasch and P. T. Spellman and C. M. Kao and O. Carmel-Harel and M. B. Eisen and G. Storz and D. Botstein and P. O. Brown},
   doi = {10.1091/MBC.11.12.4241/ASSET/IMAGES/LARGE/MK1201389008.JPEG},
   issn = {10591524},
   issue = {12},
   journal = {Molecular Biology of the Cell},
   month = {10},
   pages = {4241-4257},
   pmid = {11102521},
   publisher = {American Society for Cell Biology},
   title = {Genomic expression programs in the response of yeast cells to environmental changes},
   volume = {11},
   url = {https://www.molbiolcell.org/doi/10.1091/mbc.11.12.4241},
   year = {2000},
}
@article{Gui2005,
   abstract = {Combining information across genes in the statistical analysis of microarray data is desirable because of the relatively small number of data points obtained for each individual gene. Here we develop an estimator of the error variance that can borrow information across genes using the James-Stein shrinkage concept. A new test statistic (FS) is constructed using this estimator. The new statistic is compared with other statistics used to test for differential expression: the gene-specific F test (F1), the pooled-variance F statistic (F3), a hybrid statistic (F2) that uses the average of the individual and pooled variances, the regularized t-statistic, the posterior odds statistic B, and the SAM t-test. The F S-test shows best or nearly best power for detecting differentially expressed genes over a wide range of simulated data in which the variance components associated with individual genes are either homogeneous or heterogeneous. Thus FS provides a powerful and robust approach to test differential expression of genes that utilizes information not available in individual gene testing approaches and does not suffer from biases of the pooled variance approach. © Oxford University Press 2005; all rights reserved.},
   author = {Xiangqin Gui and J. T.Gene Hwang and Jing Qiu and Natalie J. Blades and Gary A. Churchill},
   doi = {10.1093/BIOSTATISTICS/KXH018},
   issn = {1465-4644},
   issue = {1},
   journal = {Biostatistics},
   keywords = {ANOVA model,F statistic,Linear mixed model,Permutation,Shrinkage estimator,Variance microarray},
   month = {1},
   pages = {59-75},
   pmid = {15618528},
   publisher = {Oxford Academic},
   title = {Improved statistical tests for differential gene expression by shrinking variance components estimates},
   volume = {6},
   url = {https://academic.oup.com/biostatistics/article/6/1/59/379501},
   year = {2005},
}
@article{TseWen1983,
   abstract = {The present studies investigate the potential of simultaneous multiple determinations of specific cell surface antigens in one reaction incubation by employing orderly arranged antibody spots on a solid surface. Antibodies of distinct specificities were coated on very small areas in close proximity forming matrix-like arrays on glass cover slips. These antibody spots were found to be capable of serving as minute specific immunoadsorbents for cells bearing on their surface the antigens with which the antibodies reacted. Antibody spots of 1.0, 0.5 and 0.25 mm diameter could adsorb maximally about 17,000, 4500, and 1100 mononuclear cells. An area of 1 cm2 could be coated with 25, 100, or 400 of these spots, respectively. In matrixes that contained anti-Lyt 2.1 and anti-Lyt 2.2 antibody spots, AKR (Lyt 2.1+) thymocytes adhered only to anti-Lyt 2.1 spots, BALB/c (Lyt 2.2+) thymocytes only to anti-Lyt 2.2 spots, and thymocytes of (AKR × BALB/c) F1 to both spots. The potential of this method for determining allotypes of HLA antigens and for determining in a mixed cell population the proportions of subsets bearing specific differentiation antigens is discussed. © 1983.},
   author = {TseWen Chang},
   doi = {10.1016/0022-1759(83)90318-6},
   issn = {0022-1759},
   issue = {1-2},
   journal = {Journal of Immunological Methods},
   keywords = {HLA antigen typing,antibody matrix,cell subset determination,immunoadherence},
   month = {12},
   pages = {217-223},
   pmid = {6606681},
   publisher = {Elsevier},
   title = {Binding of cells to matrixes of distinct antibodies coated on solid surface},
   volume = {65},
   year = {1983},
}
@book_section{Smyth2005,
   author = {G. K. Smyth},
   editor = {Gentleman R. and Carey V. and Dudoit S. and Irizarry R. and Huber W.},
   journal = {Bioinformatics and Computational Biology Solutions using R and Bioconductor},
   pages = {397-420},
   publisher = {Springer},
   title = {Limma: linear models for microarray data},
   year = {2005},
}
@article{Lander2001,
   abstract = {The human genome holds an extraordinary trove of information about human development, physiology, medicine and evolution. Here we report the results of an international collaboration to produce and make freely available a draft sequence of the human genome. We also present an initial analysis of the data, describing some of the insights that can be gleaned from the sequence.},
   author = {Eric S. Lander and Lauren M. Linton and Bruce Birren and Chad Nusbaum and Michael C. Zody and Jennifer Baldwin and Keri Devon and Ken Dewar and Michael Doyle and William Fitzhugh and Roel Funke and Diane Gage and Katrina Harris and Andrew Heaford and John Howland and Lisa Kann and Jessica Lehoczky and Rosie Levine and Paul McEwan and Kevin McKernan and James Meldrim and Jill P. Mesirov and Cher Miranda and William Morris and Jerome Naylor and Christina Raymond and Mark Rosetti and Ralph Santos and Andrew Sheridan and Carrie Sougnez and Nicole Stange-Thomann and Nikola Stojanovic and Aravind Subramanian and Dudley Wyman and Jane Rogers and John Sulston and Rachael Ainscough and Stephan Beck and David Bentley and John Burton and Christopher Clee and Nigel Carter and Alan Coulson and Rebecca Deadman and Panos Deloukas and Andrew Dunham and Ian Dunham and Richard Durbin and Lisa French and Darren Grafham and Simon Gregory and Tim Hubbard and Sean Humphray and Adrienne Hunt and Matthew Jones and Christine Lloyd and Amanda McMurray and Lucy Matthews and Simon Mercer and Sarah Milne and James C. Mullikin and Andrew Mungall and Robert Plumb and Mark Ross and Ratna Shownkeen and Sarah Sims and Robert H. Waterston and Richard K. Wilson and Ladeana W. Hillier and John D. McPherson and Marco A. Marra and Elaine R. Mardis and Lucinda A. Fulton and Asif T. Chinwalla and Kymberlie H. Pepin and Warren R. Gish and Stephanie L. Chissoe and Michael C. Wendl and Kim D. Delehaunty and Tracie L. Miner and Andrew Delehaunty and Jason B. Kramer and Lisa L. Cook and Robert S. Fulton and Douglas L. Johnson and Patrick J. Minx and Sandra W. Clifton and Trevor Hawkins and Elbert Branscomb and Paul Predki and Paul Richardson and Sarah Wenning and Tom Slezak and Norman Doggett and Jan Fang Cheng and Anne Olsen and Susan Lucas and Christopher Elkin and Edward Uberbacher and Marvin Frazier and Richard A. Gibbs and Donna M. Muzny and Steven E. Scherer and John B. Bouck and Erica J. Sodergren and Kim C. Worley and Catherine M. Rives and James H. Gorrell and Michael L. Metzker and Susan L. Naylor and Raju S. Kucherlapati and David L. Nelson and George M. Weinstock and Yoshiyuki Sakaki and Asao Fujiyama and Masahira Hattori and Tetsushi Yada and Atsushi Toyoda and Takehiko Itoh and Chiharu Kawagoe and Hidemi Watanabe and Yasushi Totoki and Todd Taylor and Jean Weissenbach and Roland Heilig and William Saurin and Francois Artiguenave and Philippe Brottier and Thomas Bruls and Eric Pelletier and Catherine Robert and Patrick Wincker and André Rosenthal and Matthias Platzer and Gerald Nyakatura and Stefan Taudien and Andreas Rump and Douglas R. Smith and Lynn Doucette-Stamm and Marc Rubenfield and Keith Weinstock and Mei Lee Hong and Joann Dubois and Huanming Yang and Jun Yu and Jian Wang and Guyang Huang and Jun Gu and Leroy Hood and Lee Rowen and Anup Madan and Shizen Qin and Ronald W. Davis and Nancy A. Federspiel and A. Pia Abola and Michael J. Proctor and Bruce A. Roe and Feng Chen and Huaqin Pan and Juliane Ramser and Hans Lehrach and Richard Reinhardt and W. Richard McCombie and Melissa De La Bastide and Neilay Dedhia and Helmut Blöcker and Klaus Hornischer and Gabriele Nordsiek and Richa Agarwala and L. Aravind and Jeffrey A. Bailey and Alex Bateman and Serafim Batzoglou and Ewan Birney and Peer Bork and Daniel G. Brown and Christopher B. Burge and Lorenzo Cerutti and Hsiu Chuan Chen and Deanna Church and Michele Clamp and Richard R. Copley and Tobias Doerks and Sean R. Eddy and Evan E. Eichler and Terrence S. Furey and James Galagan and James G.R. Gilbert and Cyrus Harmon and Yoshihide Hayashizaki and David Haussler and Henning Hermjakob and Karsten Hokamp and Wonhee Jang and L. Steven Johnson and Thomas A. Jones and Simon Kasif and Arek Kaspryzk and Scot Kennedy and W. James Kent and Paul Kitts and Eugene V. Koonin and Ian Korf and David Kulp and Doron Lancet and Todd M. Lowe and Aoife McLysaght and Tarjei Mikkelsen and John V. Moran and Nicola Mulder and Victor J. Pollara and Chris P. Ponting and Greg Schuler and Jörg Schultz and Guy Slater and Arian F.A. Smit and Elia Stupka and Joseph Szustakowki and Danielle Thierry-Mieg and Jean Thierry-Mieg and Lukas Wagner and John Wallis and Raymond Wheeler and Alan Williams and Yuri I. Wolf and Kenneth H. Wolfe and Shiaw Pyng Yang and Ru Fang Yeh and Francis Collins and Mark S. Guyer and Jane Peterson and Adam Felsenfeld and Kris A. Wetterstrand and Richard M. Myers and Jeremy Schmutz and Mark Dickson and Jane Grimwood and David R. Cox and Maynard V. Olson and Rajinder Kaul and Christopher Raymond and Nobuyoshi Shimizu and Kazuhiko Kawasaki and Shinsei Minoshima and Glen A. Evans and Maria Athanasiou and Roger Schultz and Aristides Patrinos and Michael J. Morgan},
   doi = {10.1038/35057062},
   issn = {1476-4687},
   issue = {6822},
   journal = {Nature 2001 409:6822},
   keywords = {Humanities and Social Sciences,Science,multidisciplinary},
   month = {2},
   pages = {860-921},
   pmid = {11237011},
   publisher = {Nature Publishing Group},
   title = {Initial sequencing and analysis of the human genome},
   volume = {409},
   url = {https://www.nature.com/articles/35057062},
   year = {2001},
}
@article{Huber2015,
   abstract = {A Perspective on the open-source and open-development software project Bioconductor provides an overview for prospective users and developers dealing with high-throughput data in genomics and molecular biology. Bioconductor is an open-source, open-development software project for the analysis and comprehension of high-throughput data in genomics and molecular biology. The project aims to enable interdisciplinary research, collaboration and rapid development of scientific software. Based on the statistical programming language R, Bioconductor comprises 934 interoperable packages contributed by a large, diverse community of scientists. Packages cover a range of bioinformatic and statistical applications. They undergo formal initial review and continuous automated testing. We present an overview for prospective users and contributors.},
   author = {Wolfgang Huber and Vincent J. Carey and Robert Gentleman and Simon Anders and Marc Carlson and Benilton S. Carvalho and Hector Corrada Bravo and Sean Davis and Laurent Gatto and Thomas Girke and Raphael Gottardo and Florian Hahne and Kasper D. Hansen and Rafael A. Irizarry and Michael Lawrence and Michael I. Love and James MaCdonald and Valerie Obenchain and Andrzej K. Oles̈ and Hervé Pagès and Alejandro Reyes and Paul Shannon and Gordon K. Smyth and Dan Tenenbaum and Levi Waldron and Martin Morgan},
   doi = {10.1038/nmeth.3252},
   issn = {1548-7105},
   issue = {2},
   journal = {Nature Methods 2015 12:2},
   keywords = {Computational platforms and environments},
   month = {1},
   pages = {115-121},
   pmid = {25633503},
   publisher = {Nature Publishing Group},
   title = {Orchestrating high-throughput genomic analysis with Bioconductor},
   volume = {12},
   url = {https://www.nature.com/articles/nmeth.3252},
   year = {2015},
}
@article{Ritchie2015,
   abstract = {limma is an R/Bioconductor software package that provides an integrated solution for analysing data from gene expression experiments. It contains rich features for handling complex experimental designs and for information borrowing to overcome the problem of small sample sizes. Over the past decade, limma has been a popular choice for gene discovery through differential expression analyses of microarray and high-throughput PCR data. The package contains particularly strong facilities for reading, normalizing and exploring such data. Recently, the capabilities of limma have been significantly expanded in two important directions. First, the package can now perform both differential expression and differential splicing analyses of RNA sequencing (RNA-seq) data. All the downstream analysis tools previously restricted to microarray data are now available for RNA-seq as well. These capabilities allow users to analyse both RNA-seq and microarray data with very similar pipelines. Second, the package is now able to go past the traditional gene-wise expression analyses in a variety of ways, analysing expression profiles in terms of co-regulated sets of genes or in terms of higher-order expression signatures. This provides enhanced possibilities for biological interpretation of gene expression differences. This article reviews the philosophy and design of the limma package, summarizing both new and historical features, with an emphasis on recent enhancements and features that have not been previously described.},
   author = {Matthew E. Ritchie and Belinda Phipson and Di Wu and Yifang Hu and Charity W. Law and Wei Shi and Gordon K. Smyth},
   doi = {10.1093/NAR/GKV007},
   issn = {0305-1048},
   issue = {7},
   journal = {Nucleic Acids Research},
   keywords = {genes,rna,sequence analysis, rna},
   month = {4},
   pages = {e47-e47},
   pmid = {25605792},
   publisher = {Oxford Academic},
   title = {limma powers differential expression analyses for RNA-sequencing and microarray studies},
   volume = {43},
   url = {https://academic.oup.com/nar/article/43/7/e47/2414268},
   year = {2015},
}
@article{Sanger1977,
   abstract = {A new method for determining nucleotide sequences in DNA is described. It is similar to the "plus and minus" method [Sanger, F. & Coulson, A. R. (1975) J. Mol. Biol. 94,441-4481 but makes use of the 2',3'-dideoxy and arabinonu-cleoside analogues of the normal deoxynucleoside triphosphates, which act as specific chain-terminating inhibitors of DNA polymerase. The technique has been applied to the DNA of bacteriophage 4bX174 and is more rapid and more accurate than either the plus or the minus method. The "plus and minus" method (1) is a relatively rapid and simple technique that has made possible the determination of the sequence of the genome of bacteriophage 4X174 (2). It depends on the use of DNA polymerase to transcribe specific regions of the DNA under controlled conditions. Although the method is considerably more rapid and simple than other available techniques, neither the "plus" nor the "minus" method is completely accurate, and in order to establish a sequence both must be used together, and sometimes confirma-tory data are necessary. W. M. Barnes (J. Mol. Biol., in press) has recently developed a third method, involving ribo-substitution , which has certain advantages over the plus and minus method, but this has not yet been extensively exploited. Another rapid and simple method that depends on specific chemical degradation of the DNA has recently been described by Maxam and Gilbert (3), and this has also been used extensively for DNA sequencing. It has the advantage over the plus and minus method that it can be applied to double-stranded DNA, but it requires a strand separation or equivalent frac-tionation of each restriction enzyme fragment studied, which makes it somewhat more laborious. This paper describes a further method using DNA poly-merase, which makes use of inhibitors that terminate the newly synthesized chains at specific residues.},
   author = {F. Sanger and S. Nicklen and A. R. Coulson},
   doi = {10.1073/PNAS.74.12.5463},
   issn = {00278424},
   issue = {12},
   journal = {Proceedings of the National Academy of Sciences of the United States of America},
   pages = {5463-5467},
   pmid = {271968},
   title = {DNA sequencing with chain-terminating inhibitors.},
   volume = {74},
   url = {https://www.pnas.org},
   year = {1977},
}
@article{Rusk2007,
   abstract = {Different sequencing technologies, at a glance.},
   author = {Nicole Rusk and Veronique Kiermer},
   doi = {10.1038/nmeth1155},
   issn = {1548-7105},
   issue = {1},
   journal = {Nature Methods 2008 5:1},
   keywords = {Bioinformatics,Biological Microscopy,Biological Techniques,Biomedical Engineering/Biotechnology,Life Sciences,Proteomics,general},
   month = {12},
   pages = {15-15},
   pmid = {18175411},
   publisher = {Nature Publishing Group},
   title = {Primer: Sequencing—the next generation},
   volume = {5},
   url = {https://www.nature.com/articles/nmeth1155},
   year = {2007},
}
@article{Risca2015,
   abstract = {Paired-end sequencing has enabled a variety of new methods for high-throughput interrogation of both genome structure and chromatin architecture. Here, we discuss how the paired-end paradigm can be used to interpret sequencing data as biophysical measurements of in vivo chromatin structure that report on single molecules in single cells.},
   author = {Viviana I. Risca and William J. Greenleaf},
   doi = {10.1016/J.TCB.2015.08.004},
   issn = {0962-8924},
   issue = {12},
   journal = {Trends in Cell Biology},
   keywords = {Chromatin,Chromosome structure,In vivo measurements,Paired-end sequencing},
   month = {12},
   pages = {716-719},
   pmid = {26437592},
   publisher = {Elsevier Current Trends},
   title = {Beyond the Linear Genome: Paired-End Sequencing as a Biophysical Tool},
   volume = {25},
   year = {2015},
}
@article{Hu2021,
   abstract = {Since the days of Sanger sequencing, next-generation sequencing technologies have significantly evolved to provide increased data output, efficiencies, and applications. These next generations of technologies can be categorized based on read length. This review provides an overview of these technologies as two paradigms: short-read, or “second-generation,” technologies, and long-read, or “third-generation,” technologies. Herein, short-read sequencing approaches are represented by the most prevalent technologies, Illumina and Ion Torrent, and long-read sequencing approaches are represented by Pacific Biosciences and Oxford Nanopore technologies. All technologies are reviewed along with reported advantages and disadvantages. Until recently, short-read sequencing was thought to provide high accuracy limited by read-length, while long-read technologies afforded much longer read-lengths at the expense of accuracy. Emerging developments for third-generation technologies hold promise for the next wave of sequencing evolution, with the co-existence of longer read lengths and high accuracy.},
   author = {Taishan Hu and Nilesh Chitnis and Dimitri Monos and Anh Dinh},
   doi = {10.1016/J.HUMIMM.2021.02.012},
   issn = {0198-8859},
   issue = {11},
   journal = {Human Immunology},
   keywords = {Long-read sequencing,Next-generation sequencing,Short-read sequencing},
   month = {11},
   pages = {801-811},
   pmid = {33745759},
   publisher = {Elsevier},
   title = {Next-generation sequencing technologies: An overview},
   volume = {82},
   year = {2021},
}
@article{Jain2016,
   abstract = {Nanopore DNA strand sequencing has emerged as a competitive, portable technology. Reads exceeding 150 kilobases have been achieved, as have in-field detection and analysis of clinical pathogens. We summarize key technical features of the Oxford Nanopore MinION, the dominant platform currently available. We then discuss pioneering applications executed by the genomics community.},
   author = {Miten Jain and Hugh E. Olsen and Benedict Paten and Mark Akeson},
   doi = {10.1186/S13059-016-1103-0},
   issn = {1474-760X},
   issue = {1},
   journal = {Genome Biology 2016 17:1},
   keywords = {Animal Genetics and Genomics,Bioinformatics,Evolutionary Biology,Human Genetics,Microbial Genetics and Genomics,Plant Genetics and Genomics},
   month = {11},
   pages = {1-11},
   publisher = {BioMed Central},
   title = {The Oxford Nanopore MinION: delivery of nanopore sequencing to the genomics community},
   volume = {17},
   url = {https://link.springer.com/articles/10.1186/s13059-016-1103-0 https://link.springer.com/article/10.1186/s13059-016-1103-0},
   year = {2016},
}
@article{Granneman2009,
   abstract = {The U3 small nucleolar ribonucleoprotein (snoRNP) plays an essential role in ribosome biogenesis but, like many RNA-protein complexes, its architecture is poorly understood. To address this problem, binding sites for the snoRNP proteins Nop1, Nop56, Nop58, and Rrp9 were mapped by UV cross-linking and analysis of cDNAs. Cross-linked protein-RNA complexes were purified under highly-denaturing conditions, ensuring that only direct interactions were detected. Recovered RNA fragments were amplified after linker ligation and cDNA synthesis. Cross-linking was successfully performed either in vitro on purified complexes or in vivo in living cells. Cross-linking sites were precisely mapped either by Sanger sequencing of multiple cloned fragments or direct, high-throughput Solexa sequencing. Analysis of RNAs associated with the snoRNP proteins revealed remarkably high signal-to-noise ratios and identified specific binding sites for each of these proteins on the U3 RNA. The results were consistent with previous data, demonstrating the reliability of the method, but also provided insights into the architecture of the U3 snoRNP. The snoRNP proteins were also cross-linked to pre-rRNA fragments, with preferential association at known sites of box C/D snoRNA function. This finding demonstrates that the snoRNP proteins directly contact the pre-rRNA substrate, suggesting roles in snoRNA recruitment. The techniques reported here should be widely applicable to analyses of RNA-protein interactions.},
   author = {Sander Granneman and Grzegorz Kudla and Elisabeth Petfalski and David Tollervey},
   doi = {10.1073/PNAS.0901997106/SUPPL_FILE/0901997106SI.PDF},
   issn = {00278424},
   issue = {24},
   journal = {Proceedings of the National Academy of Sciences of the United States of America},
   keywords = {RNA modification,RNA processing,RNP structure,Ribosome synthesis,Yeast},
   month = {6},
   pages = {9613-9618},
   pmid = {19482942},
   publisher = {
National Academy of Sciences},
   title = {Identification of protein binding sites on U3 snoRNA and pre-rRNA by UV cross-linking and high-throughput analysis of cDNAs},
   volume = {106},
   url = {https://www.pnas.org/doi/abs/10.1073/pnas.0901997106},
   year = {2009},
}
@article{Craig2008,
   abstract = {Targeted regions of the human genome are resequenced in multiplex with Illumina technology, and the pipeline is evaluated for polymorphism discovery and genotyping. We developed a generalized framework for multiplexed resequencing of targeted human genome regions on the Illumina Genome Analyzer using degenerate indexed DNA bar codes ligated to fragmented DNA before sequencing. Using this method, we simultaneously sequenced the DNA of multiple HapMap individuals at several Encyclopedia of DNA Elements (ENCODE) regions. We then evaluated the use of Bayes factors for discovering and genotyping polymorphisms. For polymorphisms that were either previously identified within the Single Nucleotide Polymorphism database (dbSNP) or visually evident upon re-inspection of archived ENCODE traces, we observed a false positive rate of 11.3% using strict thresholds for predicting variants and 69.6% for lax thresholds. Conversely, false negative rates were 10.8–90.8%, with false negatives at stricter cut-offs occurring at lower coverage (&lt;10 aligned reads). These results suggest that &gt;90% of genetic variants are discoverable using multiplexed sequencing provided sufficient coverage at the polymorphic base.},
   author = {David W. Craig and John V. Pearson and Szabolcs Szelinger and Aswin Sekar and Margot Redman and Jason J. Corneveaux and Traci L. Pawlowski and Trisha Laub and Gary Nunn and Dietrich A. Stephan and Nils Homer and Matthew J. Huentelman},
   doi = {10.1038/nmeth.1251},
   issn = {1548-7105},
   issue = {10},
   journal = {Nature Methods 2008 5:10},
   keywords = {Bioinformatics,Biological Microscopy,Biological Techniques,Biomedical Engineering/Biotechnology,Life Sciences,Proteomics,general},
   month = {9},
   pages = {887-893},
   pmid = {18794863},
   publisher = {Nature Publishing Group},
   title = {Identification of genetic variants using bar-coded multiplexed sequencing},
   volume = {5},
   url = {https://www.nature.com/articles/nmeth.1251},
   year = {2008},
}
@article{Iserman2020,
   abstract = {Heat-induced phase separation of a helicase promotes a switch in translation from housekeeping transcripts to stress-response transcripts.},
   author = {Christiane Iserman and Christine Desroches Altamirano and Ceciel Jegers and Ulrike Friedrich and Taraneh Zarin and Anatol W. Fritsch and Matthäus Mittasch and Antonio Domingues and Lena Hersemann and Marcus Jahnel and Doris Richter and Ulf Peter Guenther and Matthias W. Hentze and Alan M. Moses and Anthony A. Hyman and Günter Kramer and Moritz Kreysing and Titus M. Franzmann and Simon Alberti},
   doi = {10.1016/J.CELL.2020.04.009},
   issn = {0092-8674},
   issue = {4},
   journal = {Cell},
   keywords = {5′,Ded1p, UTR, chaperone, condensate, cytosolic pH, evolutionary adaptation, heat shock response, heat stress, phase separation, ribosomal scanning},
   month = {5},
   pages = {818-831.e19},
   pmid = {32359423},
   publisher = {Cell Press},
   title = {Condensation of Ded1p Promotes a Translational Switch from Housekeeping to Stress Protein Production},
   volume = {181},
   year = {2020},
}
@article{Stark2019,
   abstract = {Over the past decade, RNA sequencing (RNA-seq) has become an indispensable tool for transcriptome-wide analysis of differential gene expression and differential splicing of mRNAs. However, as next-generation sequencing technologies have developed, so too has RNA-seq. Now, RNA-seq methods are available for studying many different aspects of RNA biology, including single-cell gene expression, translation (the translatome) and RNA structure (the structurome). Exciting new applications are being explored, such as spatial transcriptomics (spatialomics). Together with new long-read and direct RNA-seq technologies and better computational tools for data analysis, innovations in RNA-seq are contributing to a fuller understanding of RNA biology, from questions such as when and where transcription occurs to the folding and intermolecular interactions that govern RNA function. This Review discusses advances in RNA-sequencing technologies and methods over the past decade and outlines adaptations that are enabling a fuller understanding of RNA biology, from when and where an RNA is expressed to the structures it adopts.},
   author = {Rory Stark and Marta Grzelak and James Hadfield},
   doi = {10.1038/s41576-019-0150-2},
   issn = {1471-0064},
   issue = {11},
   journal = {Nature Reviews Genetics 2019 20:11},
   keywords = {Gene expression,Gene expression analysis,Gene expression profiling,Next,RNA,RNA metabolism,RNA sequencing,Transcriptomics,generation sequencing},
   month = {7},
   pages = {631-656},
   pmid = {31341269},
   publisher = {Nature Publishing Group},
   title = {RNA sequencing: the teenage years},
   volume = {20},
   url = {https://www.nature.com/articles/s41576-019-0150-2},
   year = {2019},
}
@article{Jovic2022,
   abstract = {Single-cell RNA sequencing (scRNA-seq) technology has become the state-of-the-art approach for unravelling the heterogeneity and complexity of RNA transcripts within individual cells, as well as revealing the composition of different cell types and functions within highly organized tissues/organs/organisms. Since its first discovery in 2009, studies based on scRNA-seq provide massive information across different fields making exciting new discoveries in better understanding the composition and interaction of cells within humans, model animals and plants. In this review, we provide a concise overview about the scRNA-seq technology, experimental and computational procedures for transforming the biological and molecular processes into computational and statistical data. We also provide an explanation of the key technological steps in implementing the technology. We highlight a few examples on how scRNA-seq can provide unique information for better understanding health and diseases. One important application of the scRNA-seq technology is to build a better and high-resolution catalogue of cells in all living organism, commonly known as atlas, which is key resource to better understand and provide a solution in treating diseases. While great promises have been demonstrated with the technology in all areas, we further highlight a few remaining challenges to be overcome and its great potentials in transforming current protocols in disease diagnosis and treatment.},
   author = {Dragomirka Jovic and Xue Liang and Hua Zeng and Lin Lin and Fengping Xu and Yonglun Luo},
   doi = {10.1002/CTM2.694},
   issn = {2001-1326},
   issue = {3},
   journal = {Clinical and Translational Medicine},
   month = {3},
   pmid = {35352511},
   publisher = {Wiley-Blackwell},
   title = {Single‐cell RNA sequencing technologies and applications: A brief overview},
   volume = {12},
   url = {/pmc/articles/PMC8964935/ /pmc/articles/PMC8964935/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8964935/},
   year = {2022},
}
@article{DiTommaso2015,
   abstract = {Genomic pipelines consist of several pieces of third party software and, because of their experimental nature, frequent changes and updates are commonly necessary thus raising serious deployment and reproducibility issues. Docker containers are emerging as a possible solution for many of these problems, as they allow the packaging of pipelines in an isolated and self-contained manner. This makes it easy to distribute and execute pipelines in a portable manner across a wide range of computing platforms. Thus, the question that arises is to what extent the use of Docker containers might affect the performance of these pipelines. Here we address this question and conclude that Docker containers have only a minor impact on the performance of common genomic pipelines, which is negligible when the executed jobs are long in terms of computational time.},
   author = {Paolo Di Tommaso and Emilio Palumbo and Maria Chatzou and Pablo Prieto and Michael L. Heuer and Cedric Notredame},
   doi = {10.7717/PEERJ.1273/SUPP-1},
   issn = {21678359},
   issue = {9},
   journal = {PeerJ},
   keywords = {Bioinformatics,Docker,Pipelines,Virtualisation,Workflow},
   month = {9},
   pages = {e1273},
   publisher = {PeerJ Inc.},
   title = {The impact of Docker containers on the performance of genomic pipelines},
   volume = {2015},
   url = {https://peerj.com/articles/1273},
   year = {2015},
}
@article{Conesa2016,
   abstract = {RNA-sequencing (RNA-seq) has a wide variety of applications, but no single analysis pipeline can be used in all cases. We review all of the major steps in RNA-seq data analysis, including experimental design, quality control, read alignment, quantification of gene and transcript levels, visualization, differential gene expression, alternative splicing, functional analysis, gene fusion detection and eQTL mapping. We highlight the challenges associated with each step. We discuss the analysis of small RNAs and the integration of RNA-seq with other functional genomics techniques. Finally, we discuss the outlook for novel technologies that are changing the state of the art in transcriptomics.},
   author = {Ana Conesa and Pedro Madrigal and Sonia Tarazona and David Gomez-Cabrero and Alejandra Cervera and Andrew McPherson and Michal Wojciech Szcześniak and Daniel J. Gaffney and Laura L. Elo and Xuegong Zhang and Ali Mortazavi},
   doi = {10.1186/S13059-016-0881-8},
   issn = {1474-760X},
   issue = {1},
   journal = {Genome Biology 2016 17:1},
   keywords = {Animal Genetics and Genomics,Bioinformatics,Evolutionary Biology,Human Genetics,Microbial Genetics and Genomics,Plant Genetics and Genomics},
   month = {1},
   pages = {1-19},
   pmid = {26813401},
   publisher = {BioMed Central},
   title = {A survey of best practices for RNA-seq data analysis},
   volume = {17},
   url = {https://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-0881-8},
   year = {2016},
}
@article{Auer2010,
   abstract = {Next-generation sequencing technologies are quickly becoming the preferred approach for characterizing and quantifying entire genomes. Even though data produced from these technologies are proving to be the most informative of any thus far, very little attention has been paid to fundamental design aspects of data collection and analysis, namely sampling, randomization, replication, and blocking. We discuss these concepts in an RNA sequencing framework. Using simulations we demonstrate the benefits of collecting replicated RNA sequencing data according to well known statistical designs that partition the sources of biological and technical variation. Examples of these designs and their corresponding models are presented with the goal of testing differential expression. Copyright © 2010 by the Genetics Society of America.},
   author = {Paul L. Auer and R. W. Doerge},
   doi = {10.1534/GENETICS.110.114983},
   issn = {00166731},
   issue = {2},
   journal = {Genetics},
   month = {6},
   pages = {405-416},
   pmid = {20439781},
   publisher = {Oxford Academic},
   title = {Statistical Design and Analysis of RNA Sequencing Data},
   volume = {185},
   url = {https://academic.oup.com/genetics/article/185/2/405/6096908},
   year = {2010},
}
@article{Sultan2014,
   abstract = {Background: Gene expression analysis by RNA sequencing is now widely used in a number of applications surveying the whole transcriptomes of cells and tissues. The recent introduction of ribosomal RNA depletion protocols, such as RiboZero, has extended the view of the polyadenylated transcriptome to the poly(A)- fraction of the RNA. However, substantial amounts of intronic transcriptional activity has been reported in RiboZero protocols, raising issues regarding their potential nuclear origin and the impact on the actual sequence depth in exonic regions. Results: Using HEK293 human cells as source material, we assessed here the impact of the two commonly used RNA extraction methods and of the library construction protocols (rRNA depletion versus mRNA) on 1) the relative abundance of intronic reads and 2) on the estimation of gene expression values. We benchmarked the rRNA depletion-based sequencing with a specific analysis of the cytoplasmic and nuclear transcriptome fractions, suggesting that the large majority of the intronic reads correspond to unprocessed nuclear transcripts rather than to independent transcriptional units. We show that Qiagen or TRIzol extraction methods retain differentially nuclear RNA species, and that consequently, rRNA depletion-based RNA sequencing protocols are particularly sensitive to the extraction methods. Conclusions: We could show that the combination of Trizol-based RNA extraction with rRNA depletion sequencing protocols led to the largest fraction of intronic reads, after the sequencing of the nuclear transcriptome. We discuss here the impact of the various strategies on gene expression and alternative splicing estimation measures. Further, we propose guidelines and a double selection strategy for minimizing the expression biases, without loss of information.},
   author = {Marc Sultan and Vyacheslav Amstislavskiy and Thomas Risch and Moritz Schuette and Simon Dökel and Meryem Ralser and Daniela Balzereit and Hans Lehrach and Marie Laure Yaspo},
   doi = {10.1186/1471-2164-15-675/COMMENTS},
   issn = {14712164},
   issue = {1},
   journal = {BMC Genomics},
   keywords = {Intronic reads,RNA extraction,RNA-Seq,poly(A)+ selection,rRNA depletion},
   month = {8},
   pages = {1-13},
   pmid = {25113896},
   publisher = {BioMed Central Ltd.},
   title = {Influence of RNA extraction methods and library selection schemes on RNA-seq data},
   volume = {15},
   url = {https://bmcgenomics.biomedcentral.com/articles/10.1186/1471-2164-15-675},
   year = {2014},
}
@article{Balazs2019,
   abstract = {Background: Alternative polyadenylation is commonly examined using cDNA sequencing, which is known to be affected by template-switching artifacts. However, the effects of such template-switching artifacts on alternative polyadenylation are generally disregarded, while alternative polyadenylation artifacts are attributed to internal priming. Results: Here, we analyzed both long-read cDNA sequencing and direct RNA sequencing data of two organisms, generated by different sequencing platforms. We developed a filtering algorithm which takes into consideration that template-switching can be a source of artifactual polyadenylation when filtering out spurious polyadenylation sites. The algorithm outperformed the conventional internal priming filters based on comparison to direct RNA sequencing data. We also showed that the polyadenylation artifacts arise in cDNA sequencing at consecutive stretches of as few as three adenines. There was no substantial difference between the lengths of poly(A) tails at the artifactual and the true transcriptional end sites even though it is expected that internal priming artifacts have shorter poly(A) tails than genuine polyadenylated reads. Conclusions: Our findings suggest that template switching plays an important role in the generation of spurious polyadenylation and support the need for more rigorous filtering of artifactual polyadenylation sites in cDNA data, or that alternative polyadenylation should be annotated using native RNA sequencing.},
   author = {Zsolt Balázs and Dóra Tombácz and Zsolt Csabai and Norbert Moldován and Michael Snyder and Zsolt Boldogkoi},
   doi = {10.1186/S12864-019-6199-7/FIGURES/3},
   issn = {14712164},
   issue = {1},
   journal = {BMC Genomics},
   keywords = {Direct RNA sequencing,Internal priming,Long-read sequencing,Polyadenylation,RNA sequencing,Template switching,cDNA sequencing},
   month = {11},
   pages = {1-10},
   pmid = {31703623},
   publisher = {BioMed Central Ltd.},
   title = {Template-switching artifacts resemble alternative polyadenylation},
   volume = {20},
   url = {https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-019-6199-7},
   year = {2019},
}
@article{Dohm2008,
   abstract = {Novel sequencing technologies permit the rapid production of large sequence data sets. These technologies are likely to revolutionize genetics and biomedical research, but a thorough characterization of the ultra-short read output is necessary. We generated and analyzed two Illumina 1G ultra-short read data sets, i.e. 2.8 million 27 mer reads from a Beta vulgaris genomic clone and 12.3 million 36 mers from the Helicobacter acinonychis genome. We found that error rates range from 0.3% at the beginning of reads to 3.8% at the end of reads. Wrong base calls are frequently preceded by base G. Base substitution error frequencies vary by 10- to 11-fold, with A > C transversion being among the most frequent and C > G transversions among the least frequent substitution errors. Insertions and deletions of single bases occur at very low rates. When simulating re-sequencing we found a 20-fold sequencing coverage to be sufficient to compensate errors by correct reads. The read coverage of the sequenced regions is biased; the highest read density was found in intervals with elevated GC content. High Solexa quality scores are over-optimistic and low scores underestimate the data quality. Our results show different types of biases and ways to detect them. Such biases have implications on the use and interpretation of Solexa data, for de novo sequencing, re-sequencing, the identification of single nucleotide polymorphisms and DNA methylation sites, as well as for transcriptome analysis.},
   author = {Juliane C. Dohm and Claudio Lottaz and Tatiana Borodina and Heinz Himmelbauer},
   doi = {10.1093/NAR/GKN425},
   issn = {0305-1048},
   issue = {16},
   journal = {Nucleic Acids Research},
   keywords = {beta vulgaris,datasets,genome,helicobacter,sequence analysis, dna},
   month = {9},
   pages = {105},
   pmid = {18660515},
   publisher = {Oxford Academic},
   title = {Substantial biases in ultra-short read data sets from high-throughput DNA sequencing},
   volume = {36},
   url = {https://academic.oup.com/nar/article/36/16/e105/6334555},
   year = {2008},
}
@article{Oshlack2009,
   abstract = {Background: Several recent studies have demonstrated the effectiveness of deep sequencing for transcriptome analysis (RNA-seq) in mammals. As RNA-seq becomes more affordable, whole genome transcriptional profiling is likely to become the platform of choice for species with good genomic sequences. As yet, a rigorous analysis methodology has not been developed and we are still in the stages of exploring the features of the data. Results: We investigated the effect of transcript length bias in RNA-seq data using three different published data sets. For standard analyses using aggregated tag counts for each gene, the ability to call differentially expressed genes between samples is strongly associated with the length of the transcript. Conclusion: Transcript length bias for calling differentially expressed genes is a general feature of current protocols for RNA-seq technology. This has implications for the ranking of differentially expressed genes, and in particular may introduce bias in gene set testing for pathway analysis and other multi-gene systems biology analyses. © 2009 Oshlack and Wakefield; licensee BioMed Central Ltd.},
   author = {Alicia Oshlack and Matthew J. Wakefield},
   doi = {10.1186/1745-6150-4-14/FIGURES/3},
   issn = {17456150},
   issue = {1},
   journal = {Biology Direct},
   keywords = {Life Sciences,general},
   month = {4},
   pages = {1-10},
   pmid = {19371405},
   publisher = {BioMed Central},
   title = {Transcript length bias in RNA-seq data confounds systems biology},
   volume = {4},
   url = {https://biologydirect.biomedcentral.com/articles/10.1186/1745-6150-4-14},
   year = {2009},
}
@article{KL2016,
   author = {{Knowledge Exchange}},
   title = {Research Software Sustainability: Report on Knowledge Exchange workshop},
   url = {https://www.knowledge-exchange.info/event/software-sustainability},
   year = {2016},
}
@book{Thomas1999,
   author = {David Thomas and Andrew Hunt},
   title = {The Pragmatic Programmer},
   url = {https://pragprog.com/titles/tpp20/the-pragmatic-programmer-20th-anniversary-edition/},
   year = {1999},
}
@article{Lannelongue2021,
   author = {Loïc Lannelongue and Jason Grealey and Alex Bateman and Michael Inouye},
   doi = {10.1371/JOURNAL.PCBI.1009324},
   isbn = {1111111111},
   issn = {1553-7358},
   issue = {9},
   journal = {PLOS Computational Biology},
   keywords = {Carbon dioxide,Carbon sequestration,Computer hardware,Computer software,Electricity,Environmental impacts,Global warming,Life cycles},
   month = {9},
   pages = {e1009324},
   pmid = {34543272},
   publisher = {Public Library of Science},
   title = {Ten simple rules to make your computing more environmentally sustainable},
   volume = {17},
   url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009324},
   year = {2021},
}
@article{Karyakin2017,
   abstract = {e growing appetite for in-memory computing is increasing mem-ory's share of total server power consumption. However, memory power consumption in database management systems is not well understood. .is paper presents an empirical characterization of memory power consumption in database systems, for both analytical and transactional workloads. Our results indicate that memory power optimization will be eeective only if it can reduce background power through more aggressive use of low power memory idle states.},
   author = {Alexey Karyakin and Kenneth Salem},
   city = {New York, NY, USA},
   doi = {10.1145/3076113},
   isbn = {9781450350259},
   journal = {Proceedings of the 13th International Workshop on Data Management on New Hardware},
   publisher = {ACM},
   title = {An Analysis of Memory Power Consumption in Database Systems},
   volume = {9},
   year = {2017},
}
@article{CCEE2020,
   author = {{Copenhagen Centre on Energy Efficiency}},
   title = {Greenhouse gas emissions in the ICT sector: Trends and methodologies},
   url = {https://c2e2.unepccc.org/wp-content/uploads/sites/3/2020/03/greenhouse-gas-emissions-in-the-ict-sector.pdf},
   year = {2020},
}
@article{McKiernan2016,
   abstract = {Open access, open data, open source and other open scholarship practices are growing in popularity and necessity. However, widespread adoption of these practices has not yet been achieved. One reason is that researchers are uncertain about how sharing their work will affect their careers. We review literature demonstrating that open research is associated with increases in citations, media attention, potential collaborators, job opportunities and funding opportunities. These findings are evidence that open research practices bring significant benefits to researchers relative to more traditional closed practices.},
   author = {Erin C. McKiernan and Philip E. Bourne and C. Titus Brown and Stuart Buck and Amye Kenall and Jennifer Lin and Damon McDougall and Brian A. Nosek and Karthik Ram and Courtney K. Soderberg and Jeffrey R. Spies and Kaitlin Thaney and Andrew Updegrove and Kara H. Woo and Tal Yarkoni},
   doi = {10.7554/ELIFE.16800},
   issn = {2050084X},
   issue = {JULY},
   journal = {eLife},
   month = {7},
   pmid = {27387362},
   publisher = {eLife Sciences Publications, Ltd},
   title = {How open science helps researchers succeed},
   volume = {5},
   url = {/pmc/articles/PMC4973366/ /pmc/articles/PMC4973366/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4973366/},
   year = {2016},
}
@article{Kane2006,
   abstract = {Background: Agile is an iterative approach to software development that relies on strong collaboration and automation to keep pace with dynamic environments. We have successfully used agile development approaches to create and maintain biomedical software, including software for bioinformatics. This paper reports on a qualitative study of our experiences using these methods. Results: We have found that agile methods are well suited to the exploratory and iterative nature of scientific inquiry. They provide a robust framework for reproducing scientific results and for developing clinical support systems. The agile development approach also provides a model for collaboration between software engineers and researchers. We present our experience using agile methodologies in projects at six different biomedical software development organizations. The organizations include academic, commercial and government development teams, and included both bioinformatics and clinical support applications. We found that agile practices were a match for the needs of our biomedical projects and contributed to the success of our organizations. Conclusion: We found that the agile development approach was a good fit for our organizations, and that these practices should be applicable and valuable to other biomedical software development efforts. Although we found differences in how agile methods were used, we were also able to identify a set of core practices that were common to all of the groups, and that could be a focus for others seeking to adopt these methods. © 2006 Kane et al; licensee BioMed Central Ltd.},
   author = {David W. Kane and Moses M. Hohman and Ethan G. Cerami and Michael W. McCormick and Karl F. Kuhlmman and Jeff A. Byrd},
   doi = {10.1186/1471-2105-7-273/TABLES/4},
   issn = {14712105},
   issue = {1},
   journal = {BMC Bioinformatics},
   keywords = {Algorithms,Bioinformatics,Computational Biology/Bioinformatics,Computer Appl. in Life Sciences,Microarrays},
   month = {5},
   pages = {1-12},
   pmid = {16734914},
   publisher = {BioMed Central},
   title = {Agile methods in biomedical software development: A multi-site experience report},
   volume = {7},
   url = {https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-7-273},
   year = {2006},
}

@article{Schwaber2020,
   author = {Ken Schwaber and Jeff Sutherland},
   title = {The Scrum Guide},
   url = {https://www.scrum.org/resources/scrum-guide},
   year = {2020},
}

@book{Beck2004,
author = {Beck, Kent and Andres, Cynthia},
title = {Extreme Programming Explained: Embrace Change (2nd Edition)},
year = {2004},
isbn = {0321278658},
publisher = {Addison-Wesley Professional},
abstract = {Whether you have a small team that is already closely aligned with your customers or a large team in a gigantic or multinational organization, you will find in these pages a wealth of ideas to challenge, inspire, and encourage you and your team members to substantially improve your software development.You will discover how to: Involve the whole team-XP style Increase technical collaboration through pair programming and continuous integration Reduce defects through developer testing Align business and technical decisions through weekly and quarterly planning Improve teamwork by setting up an informative, shared workspaceYou will also find many other concrete ideas for improvement, all based on a philosophy that emphasizes simultaneously increasing the humanity and effectiveness of software development.Every team can improve. Every team can begin improving today. Improvement is possible-beyond what we can currently imagine. Extreme Programming Explained, Second Edition, offers ideas to fuel your improvement for years to come.}
}
@article{Barker2022,
   abstract = {Research software is a fundamental and vital part of research, yet significant challenges to discoverability, productivity, quality, reproducibility, and sustainability exist. Improving the practice of scholarship is a common goal of the open science, open source, and FAIR (Findable, Accessible, Interoperable and Reusable) communities and research software is now being understood as a type of digital object to which FAIR should be applied. This emergence reflects a maturation of the research community to better understand the crucial role of FAIR research software in maximising research value. The FAIR for Research Software (FAIR4RS) Working Group has adapted the FAIR Guiding Principles to create the FAIR Principles for Research Software (FAIR4RS Principles). The contents and context of the FAIR4RS Principles are summarised here to provide the basis for discussion of their adoption. Examples of implementation by organisations are provided to share information on how to maximise the value of research outputs, and to encourage others to amplify the importance and impact of this work.},
   author = {Michelle Barker and Neil P. Chue Hong and Daniel S. Katz and Anna-Lena Lamprecht and Carlos Martinez-Ortiz and Fotis Psomopoulos and Jennifer Harrow and Leyla Jael Castro and Morane Gruenpeter and Paula Andrea Martinez and Tom Honeyman},
   doi = {10.1038/s41597-022-01710-x},
   issn = {2052-4463},
   issue = {1},
   journal = {Scientific Data 2022 9:1},
   keywords = {Policy,Research management},
   month = {10},
   pages = {1-6},
   publisher = {Nature Publishing Group},
   title = {Introducing the FAIR Principles for research software},
   volume = {9},
   url = {https://www.nature.com/articles/s41597-022-01710-x},
   year = {2022},
}
@article{Gentleman2004,
   abstract = {The Bioconductor project is an initiative for the collaborative creation of extensible software for computational biology and bioinformatics. The goals of the project include: fostering collaborative development and widespread use of innovative software, reducing barriers to entry into interdisciplinary scientific research, and promoting the achievement of remote reproducibility of research results. We describe details of our aims and methods, identify current challenges, compare Bioconductor to other open bioinformatics projects, and provide working examples.},
   author = {Robert C Gentleman and Vincent J Carey and Douglas M Bates and Ben Bolstad and Marcel Dettling and Sandrine Dudoit and Byron Ellis and Laurent Gautier and Yongchao Ge and Jeff Gentry and Kurt Hornik and Torsten Hothorn and Wolfgang Huber and Stefano Iacus and Rafael Irizarry and Friedrich Leisch and Cheng Li and Martin Maechler and Anthony J Rossini and Gunther Sawitzki and Colin Smith and Gordon Smyth and Luke Tierney and Jean YH Yang and Jianhua Zhang},
   doi = {10.1186/GB-2004-5-10-R80},
   issn = {1474-760X},
   issue = {10},
   journal = {Genome Biology 2004 5:10},
   keywords = {Animal Genetics and Genomics,Bioinformatics,Evolutionary Biology,Human Genetics,Microbial Genetics and Genomics,Plant Genetics and Genomics},
   month = {9},
   pages = {1-16},
   publisher = {BioMed Central},
   title = {Bioconductor: open software development for computational biology and bioinformatics},
   volume = {5},
   url = {https://link.springer.com/articles/10.1186/gb-2004-5-10-r80 https://link.springer.com/article/10.1186/gb-2004-5-10-r80},
   year = {2004},
}
@article{Community2022,
   author = {{The Turing Way Community}},
   doi = {10.5281/ZENODO.6909298},
   keywords = {collaboration,community,data science,ethics,handbook,reproducibility,research practices},
   month = {7},
   title = {The Turing Way: A handbook for reproducible, ethical and collaborative research},
   url = {https://doi.org/10.5281/zenodo.6909298#.Y1fMu931ndY.mendeley},
   year = {2022},
}
@article{Goble2014,
   abstract = {Modern scientific research isn't possible without software. However, its vital role is often overlooked by funders, universities, assessment committees, and even the research community itself. This is a serious issue that needs urgent attention. This article raises a number of points concerning quality, code review, and openness; development practices and training in scientific computing; career recognition of research software engineers; and sustainability models for funding scientific software. We must get software recognized to be the first-class experimental scientific instrument that it is and get 'better software for better research.' © 1997-2012 IEEE.},
   author = {Carole Goble},
   doi = {10.1109/MIC.2014.88},
   issn = {10897801},
   issue = {5},
   journal = {IEEE Internet Computing},
   keywords = {engineering,scientific software,sustainability},
   pages = {4-8},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Better software, better research},
   volume = {18},
   year = {2014},
}
@article{Hermann2022,
   abstract = {The reuse of research software needs good documentation, however, the documentation in particular is often criticized. Especially in non-IT specific disciplines, the lack of documentation is attributed to the lack of training, the lack of time or missing rewards. This article addresses the hypothesis that scientists do document but do not know exactly what they need to document, why, and for whom. In order to evaluate the actual documentation practice of research software, we examined existing recommendations, and we evaluated their implementation in everyday practice using a concrete example from the engineering sciences and compared the findings with best practice examples. To get a broad overview of what documentation of research software entailed, we defined categories and used them to conduct the research. Our results show that the big picture of what documentation of research software means is missing. Recommendations do not consider the important role of researchers, who write research software, whose documentation takes mainly place in their research articles. Moreover, we show that research software always has a history that influences the documentation.},
   author = {Sibylle Hermann and Jörg Fehr},
   doi = {10.1038/s41598-022-10376-9},
   isbn = {0123456789},
   issn = {2045-2322},
   issue = {1},
   journal = {Scientific Reports 2022 12:1},
   keywords = {Engineering,Mechanical engineering},
   month = {4},
   pages = {1-11},
   pmid = {35449149},
   publisher = {Nature Publishing Group},
   title = {Documenting research software in engineering science},
   volume = {12},
   url = {https://www.nature.com/articles/s41598-022-10376-9},
   year = {2022},
}
@article{Schwarz1978,
author = {Gideon Schwarz},
title = {{Estimating the Dimension of a Model}},
volume = {6},
journal = {The Annals of Statistics},
number = {2},
publisher = {Institute of Mathematical Statistics},
pages = {461 -- 464},
keywords = {Akaike information criterion, asymptotics, dimension},
year = {1978},
doi = {10.1214/aos/1176344136},
URL = {https://doi.org/10.1214/aos/1176344136}
}
@article{Akaike1971,
   author = {Hirotogu Akaike},
   issue = {44},
   journal = {Research Memo.},
   publisher = {Inst. Statist. Math.},
   title = {Determination of the number of factors by an extended maximum likelihood principle},
   year = {1971},
}

@article{Dunham2012,
   abstract = {The human genome encodes the blueprint of life, but the function of the vast majority of its nearly three billion bases is unknown. The Encyclopedia of DNA Elements (ENCODE) project has systematically mapped regions of transcription, transcription factor association, chromatin structure and histone modification. These data enabled us to assign biochemical functions for 80% of the genome, in particular outside of the well-studied protein-coding regions. Many discovered candidate regulatory elements are physically associated with one another and with expressed genes, providing new insights into the mechanisms of gene regulation. The newly identified elements also show a statistical correspondence to sequence variants linked to human disease, and can thereby guide interpretation of this variation. Overall, the project provides new insights into the organization and regulation of our genes and genome, and is an expansive resource of functional annotations for biomedical research. This overview of the ENCODE project outlines the data accumulated so far, revealing that 80% of the human genome now has at least one biochemical function assigned to it; the newly identified functional elements should aid the interpretation of results of genome-wide association studies, as many correspond to sites of association with human disease. The Encyclopedia of DNA Elements (ENCODE) project has systematically mapped regions of transcription, transcription-factor association, chromatin structure and histone modification. In this overview, the Consortium guides the readers through the project itself, the data and their integrated analyses. Eighty per cent of the human genome now has at least one biochemical function assigned to it. In addition to expanding our understanding of how gene expression is regulated on a genome-wide scale, the newly identified functional elements should help researchers to interpret the results of genome-wide associated studies because many correspond to sites associated with human disease.},
   author = {Ian Dunham and Anshul Kundaje and Shelley F. Aldred and Patrick J. Collins and Carrie A. Davis and Francis Doyle and Charles B. Epstein and Seth Frietze and Jennifer Harrow and Rajinder Kaul and Jainab Khatun and Bryan R. Lajoie and Stephen G. Landt and Bum Kyu Lee and Florencia Pauli and Kate R. Rosenbloom and Peter Sabo and Alexias Safi and Amartya Sanyal and Noam Shoresh and Jeremy M. Simon and Lingyun Song and Nathan D. Trinklein and Robert C. Altshuler and Ewan Birney and James B. Brown and Chao Cheng and Sarah Djebali and Xianjun Dong and Jason Ernst and Terrence S. Furey and Mark Gerstein and Belinda Giardine and Melissa Greven and Ross C. Hardison and Robert S. Harris and Javier Herrero and Michael M. Hoffman and Sowmya Iyer and Manolis Kellis and Pouya Kheradpour and Timo Lassmann and Qunhua Li and Xinying Lin and Georgi K. Marinov and Angelika Merkel and Ali Mortazavi and Stephen C.J. Parker and Timothy E. Reddy and Joel Rozowsky and Felix Schlesinger and Robert E. Thurman and Jie Wang and Lucas D. Ward and Troy W. Whitfield and Steven P. Wilder and Weisheng Wu and Hualin S. Xi and Kevin Y. Yip and Jiali Zhuang and Bradley E. Bernstein and Eric D. Green and Chris Gunter and Michael Snyder and Michael J. Pazin and Rebecca F. Lowdon and Laura A.L. Dillon and Leslie B. Adams and Caroline J. Kelly and Julia Zhang and Judith R. Wexler and Peter J. Good and Elise A. Feingold and Gregory E. Crawford and Job Dekker and Laura Elnitski and Peggy J. Farnham and Morgan C. Giddings and Thomas R. Gingeras and Roderic Guigó and Timothy J. Hubbard and W. James Kent and Jason D. Lieb and Elliott H. Margulies and Richard M. Myers and John A. Stamatoyannopoulos and Scott A. Tenenbaum and Zhiping Weng and Kevin P. White and Barbara Wold and Yanbao Yu and John Wrobel and Brian A. Risk and Harsha P. Gunawardena and Heather C. Kuiper and Christopher W. Maier and Ling Xie and Xian Chen and Tarjei S. Mikkelsen and Shawn Gillespie and Alon Goren and Oren Ram and Xiaolan Zhang and Li Wang and Robbyn Issner and Michael J. Coyne and Timothy Durham and Manching Ku and Thanh Truong and Matthew L. Eaton and Alex Dobin and Andrea Tanzer and Julien Lagarde and Wei Lin and Chenghai Xue and Brian A. Williams and Chris Zaleski and Maik Röder and Felix Kokocinski and Rehab F. Abdelhamid and Tyler Alioto and Igor Antoshechkin and Michael T. Baer and Philippe Batut and Ian Bell and Kimberly Bell and Sudipto Chakrabortty and Jacqueline Chrast and Joao Curado and Thomas Derrien and Jorg Drenkow and Erica Dumais and Jackie Dumais and Radha Duttagupta and Megan Fastuca and Kata Fejes-Toth and Pedro Ferreira and Sylvain Foissac and Melissa J. Fullwood and Hui Gao and David Gonzalez and Assaf Gordon and Cédric Howald and Sonali Jha and Rory Johnson and Philipp Kapranov and Brandon King and Colin Kingswood and Guoliang Li and Oscar J. Luo and Eddie Park and Jonathan B. Preall and Kimberly Presaud and Paolo Ribeca and Daniel Robyr and Xiaoan Ruan and Michael Sammeth and Kuljeet Singh Sandhu and Lorain Schaeffer and Lei Hoon See and Atif Shahab and Jorgen Skancke and Ana Maria Suzuki and Hazuki Takahashi and Hagen Tilgner and Diane Trout and Nathalie Walters and Huaien Wang and Yoshihide Hayashizaki and Alexandre Reymond and Stylianos E. Antonarakis and Gregory J. Hannon and Yijun Ruan and Piero Carninci and Cricket A. Sloan and Katrina Learned and Venkat S. Malladi and Matthew C. Wong and Galt P. Barber and Melissa S. Cline and Timothy R. Dreszer and Steven G. Heitner and Donna Karolchik and Vanessa M. Kirkup and Laurence R. Meyer and Jeffrey C. Long and Morgan Maddren and Brian J. Raney and Linda L. Grasfeder and Paul G. Giresi and Anna Battenhouse and Nathan C. Sheffield and Kimberly A. Showers and Darin London and Akshay A. Bhinge and Christopher Shestak and Matthew R. Schaner and Seul Ki Kim and Zhuzhu Z. Zhang and Piotr A. Mieczkowski and Joanna O. Mieczkowska and Zheng Liu and Ryan M. McDaniell and Yunyun Ni and Naim U. Rashid and Min Jae Kim and Sheera Adar and Zhancheng Zhang and Tianyuan Wang and Deborah Winter and Damian Keefe and Vishwanath R. Iyer and Meizhen Zheng and Ping Wang and Jason Gertz and Jost Vielmetter and E. Christopher Partridge and Katherine E. Varley and Clarke Gasper and Anita Bansal and Shirley Pepke and Preti Jain and Henry Amrhein and Kevin M. Bowling and Michael Anaya and Marie K. Cross and Michael A. Muratet and Kimberly M. Newberry and Kenneth McCue and Amy S. Nesmith and Katherine I. Fisher-Aylor and Barbara Pusey and Gilberto DeSalvo and Stephanie L. Parker and Sreeram Balasubramanian and Nicholas S. Davis and Sarah K. Meadows and Tracy Eggleston and J. Scott Newberry and Shawn E. Levy and Devin M. Absher and Wing H. Wong and Matthew J. Blow and Axel Visel and Len A. Pennachio and Hanna M. Petrykowska and Alexej Abyzov and Bronwen Aken and Daniel Barrell and Gemma Barson and Andrew Berry and Alexandra Bignell and Veronika Boychenko and Giovanni Bussotti and Claire Davidson and Gloria Despacio-Reyes and Mark Diekhans and Iakes Ezkurdia and Adam Frankish and James Gilbert and Jose Manuel Gonzalez and Ed Griffiths and Rachel Harte and David A. Hendrix and Toby Hunt and Irwin Jungreis and Mike Kay and Ekta Khurana and Jing Leng and Michael F. Lin and Jane Loveland and Zhi Lu and Deepa Manthravadi and Marco Mariotti and Jonathan Mudge and Gaurab Mukherjee and Cedric Notredame and Baikang Pei and Jose Manuel Rodriguez and Gary Saunders and Andrea Sboner and Stephen Searle and Cristina Sisu and Catherine Snow and Charlie Steward and Electra Tapanari and Michael L. Tress and Marijke J. Van Baren and Stefan Washietl and Laurens Wilming and Amonida Zadissa and Zhengdong Zhang and Michael Brent and David Haussler and Alfonso Valencia and Nick Addleman and Roger P. Alexander and Raymond K. Auerbach and Suganthi Balasubramanian and Keith Bettinger and Nitin Bhardwaj and Alan P. Boyle and Alina R. Cao and Philip Cayting and Alexandra Charos and Yong Cheng and Catharine Eastman and Ghia Euskirchen and Joseph D. Fleming and Fabian Grubert and Lukas Habegger and Manoj Hariharan and Arif Harmanci and Sushma Iyengar and Victor X. Jin and Konrad J. Karczewski and Maya Kasowski and Phil Lacroute and Hugo Lam and Nathan Lamarre-Vincent and Jin Lian and Marianne Lindahl-Allen and Renqiang Min and Benoit Miotto and Hannah Monahan and Zarmik Moqtaderi and Xinmeng J. Mu and Henriette O'Geen and Zhengqing Ouyang and Dorrelyn Patacsil and Debasish Raha and Lucia Ramirez and Brian Reed and Minyi Shi and Teri Slifer and Heather Witt and Linfeng Wu and Xiaoqin Xu and Koon Kiu Yan and Xinqiong Yang and Kevin Struhl and Sherman M. Weissman and Luiz O. Penalva and Subhradip Karmakar and Raj R. Bhanvadia and Alina Choudhury and Marc Domanus and Lijia Ma and Jennifer Moran and Alec Victorsen and Thomas Auer and Lazaro Centanin and Michael Eichenlaub and Franziska Gruhl and Stephan Heermann and Burkhard Hoeckendorf and Daigo Inoue and Tanja Kellner and Stephan Kirchmaier and Claudia Mueller and Robert Reinhardt and Lea Schertel and Stephanie Schneider and Rebecca Sinn and Beate Wittbrodt and Jochen Wittbrodt and Gaurav Jain and Gayathri Balasundaram and Daniel L. Bates and Rachel Byron and Theresa K. Canfield and Morgan J. Diegel and Douglas Dunn and Abigail K. Ebersol and Tristan Frum and Kavita Garg and Erica Gist and R. Scott Hansen and Lisa Boatman and Eric Haugen and Richard Humbert and Audra K. Johnson and Ericka M. Johnson and Tattyana V. Kutyavin and Kristen Lee and Dimitra Lotakis and Matthew T. Maurano and Shane J. Neph and Fiedencio V. Neri and Eric D. Nguyen and Hongzhu Qu and Alex P. Reynolds and Vaughn Roach and Eric Rynes and Minerva E. Sanchez and Richard S. Sandstrom and Anthony O. Shafer and Andrew B. Stergachis and Sean Thomas and Benjamin Vernot and Jeff Vierstra and Shinny Vong and Hao Wang and Molly A. Weaver and Yongqi Yan and Miaohua Zhang and Joshua M. Akey and Michael Bender and Michael O. Dorschner and Mark Groudine and Michael J. MacCoss and Patrick Navas and George Stamatoyannopoulos and Kathryn Beal and Alvis Brazma and Paul Flicek and Nathan Johnson and Margus Lukk and Nicholas M. Luscombe and Daniel Sobral and Juan M. Vaquerizas and Serafim Batzoglou and Arend Sidow and Nadine Hussami and Sofia Kyriazopoulou-Panagiotopoulou and Max W. Libbrecht and Marc A. Schaub and Webb Miller and Peter J. Bickel and Balazs Banfai and Nathan P. Boley and Haiyan Huang and Jingyi Jessica Li and William Stafford Noble and Jeffrey A. Bilmes and Orion J. Buske and Avinash D. Sahu and Peter V. Kharchenko and Peter J. Park and Dannon Baker and James Taylor and Lucas Lochovsky},
   doi = {10.1038/nature11247},
   issn = {1476-4687},
   issue = {7414},
   journal = {Nature 2012 489:7414},
   keywords = {Functional genomics,Genetic variation,Genome,Molecular biology,wide association studies},
   month = {9},
   pages = {57-74},
   pmid = {22955616},
   publisher = {Nature Publishing Group},
   title = {An integrated encyclopedia of DNA elements in the human genome},
   volume = {489},
   url = {https://www.nature.com/articles/nature11247},
   year = {2012},
}
@article{Corbett2018,
   abstract = {A large number of mutations in genes that encode RNA binding proteins cause human disease. Many of these RNA binding proteins mediate key steps in post-transcriptional regulation of gene expression from mRNA processing to eventual decay in the cytoplasm. Surprisingly, these RNA binding proteins, which are ubiquitously expressed and play fundamental roles in gene expression, are often altered in tissue-specific disease. Mutations linked to disease impact nearly every post-transcriptional processing step and cause diverse disease phenotypes in a variety of specific tissues. This review summarizes steps in post-transcriptional regulation of gene expression that have been linked to disease providing specific examples of some of the many genes affected. Finally, recent advances that hold promise for treatment of some of these diseases are presented.},
   author = {Anita H. Corbett},
   doi = {10.1016/J.CEB.2018.02.011},
   issn = {0955-0674},
   journal = {Current Opinion in Cell Biology},
   month = {6},
   pages = {96-104},
   pmid = {29518673},
   publisher = {Elsevier Current Trends},
   title = {Post-transcriptional regulation of gene expression and human disease},
   volume = {52},
   year = {2018},
}
@article{Hoerl1970,
   abstract = {In multiple regression it is shown that parameter estimates based on minimum residual sum of squares have a high probability of being unsatisfactory, if not incorrect, if the prediction vectors are not orthogonal. Proposed is an estimation procedure based on adding small positive quantities to the diagonal of X'X. Introduced is the ridge trace, a method for showing in two dimensions the effects of nonorthogonality. It is then shown how to augment X'X to obtain biased estimates with smaller mean square error.},
   author = {Arthur E. Hoerl and Robert W. Kennard},
   issue = {1},
   journal = {Technometrics}, 
   pages = {55},
   publisher = {JSTOR},
   title = {Ridge Regression: Biased Estimation for Nonorthogonal Problems},
   volume = {12},
   year = {1970},
}
@article{Tibshirani1996,
 ISSN = {00359246},
 URL = {http://www.jstor.org/stable/2346178},
 abstract = {We propose a new method for estimation in linear models. The `lasso' minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described.},
 author = {Robert Tibshirani},
 journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
 number = {1},
 pages = {267--288},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {Regression Shrinkage and Selection via the Lasso},
 urldate = {2022-10-27},
 volume = {58},
 year = {1996}
}

@article{Zou2005,
   abstract = {We propose the elastic net, a new regularization and variable selection method. Real world data and a simulation study show that the elastic net often outperforms the lasso, while enjoying a similar sparsity of representation. In addition, the elastic net encourages a grouping effect, where strongly correlated predictors tend to be in or out of the model together. The elastic net is particularly useful when the number of predictors (p) is much bigger than the number of observations (n). By contrast, the lasso is not a very satisfactory variable selection method in the p ≫ n case. An algorithm called LARS-EN is proposed for computing elastic net regularization paths efficiently, much like algorithm LARS does for the lasso. © 2005 Royal Statistical Society.},
   author = {Hui Zou and Trevor Hastie},
   doi = {10.1111/J.1467-9868.2005.00503.X},
   issn = {1467-9868},
   issue = {2},
   journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
   keywords = {Grouping effect,LARS algorithm,Lasso,Penalization,Variable selection,p≫n problem},
   month = {4},
   pages = {301-320},
   title = {Regularization and variable selection via the elastic net},
   volume = {67},
   url = {https://onlinelibrary.wiley.com/doi/full/10.1111/j.1467-9868.2005.00503.x https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2005.00503.x https://rss.onlinelibrary.wiley.com/doi/10.1111/j.1467-9868.2005.00503.x},
   year = {2005},
}
@article{Hochberg1995,
author = {Benjamini, Yoav and Hochberg, Yosef},
year = {1995},
month = {11},
pages = {289 - 300},
title = {Controlling The False Discovery Rate - A Practical And Powerful Approach To Multiple Testing},
volume = {57},
journal = {J. Royal Statist. Soc., Series B},
doi = {10.1111/j.2517-6161.1995.tb02031.x}
}
@article{Bonferroni1936,
author = {Bonferroni, C. E.},
year = {1936},
title = {Teoria statistica delle classi e calcolo delle probabilità},
journal = {Pubblicazioni del R Istituto Superiore di Scienze Economiche e Commerciali di Firenze},
}
@article{Hastie2009,
   author = {Trevor Hastie and Robert Tibshirani and Jerome Friedman},
   city = {New York, NY},
   doi = {10.1007/978-0-387-84858-7},
   isbn = {978-0-387-84857-0},
   publisher = {Springer New York},
   title = {The Elements of Statistical Learning},
   url = {http://link.springer.com/10.1007/978-0-387-84858-7},
   year = {2009},
}
@article{Gelman2014,
   abstract = {Now in its third edition, this classic book is widely considered the leading text on Bayesian methods, lauded for its accessible, practical approach to analyzing data and solving research problems. Bayesian Data Analysis, Third Edition continues to take an applied approach to analysis using up-to-date Bayesian methods. The authors—all leaders in the statistics community—introduce basic concepts from a data-analytic perspective before presenting advanced methods. Throughout the text, numerous worked examples drawn from real applications and research emphasize the use of Bayesian inference in practice. New to the Third Edition Four new chapters on nonparametric modeling Coverage of weakly informative priors and boundary-avoiding priors Updated discussion of cross-validation and predictive information criteria Improved convergence monitoring and effective sample size calculations for iterative simulation Presentations of Hamiltonian Monte Carlo, variational Bayes, and expectation propagation New and revised software code The book can be used in three different ways. For undergraduate students, it introduces Bayesian inference starting from first principles. For graduate students, the text presents effective current approaches to Bayesian modeling and computation in statistics and related fields. For researchers, it provides an assortment of Bayesian methods in applied statistics. Additional materials, including data sets used in the examples, solutions to selected exercises, and software instructions, are available on the book’s web page.},
   author = {Andrew Gelman and John B B Carlin and Hal S S Stern and Donald B B Rubin},
   doi = {10.1007/s13398-014-0173-7.2},
   isbn = {9781439840955},
   issn = {1467-9280},
   journal = {Book},
   pages = {675},
   pmid = {25052830},
   title = {Bayesian Data Analysis, Third Edition (Texts in Statistical Science)},
   url = {https://www.routledge.com/Bayesian-Data-Analysis/Gelman-Carlin-Stern-Dunson-Vehtari-Rubin/p/book/9781439840955},
   year = {2014},
}

@book{Rasmussen2005,
    author = {Carl Edward Rasmussen and Christopher K. I. Williams},
    isbn = {9780262256834},
    title = "{Regression}",
    booktitle = "{Gaussian Processes for Machine Learning}",
    publisher = {The MIT Press},
    year = {2005},
    month = {11},
    doi = {10.7551/mitpress/3206.003.0005},
    url = {https://doi.org/10.7551/mitpress/3206.003.0005},
    eprint = {https://direct.mit.edu/book/chapter-pdf/270787/9780262256834\_cab.pdf},
}
@article{Cox1946,
author = {Cox,R. T. },
title = {Probability, Frequency and Reasonable Expectation},
journal = {American Journal of Physics},
volume = {14},
number = {1},
pages = {1-13},
year = {1946},
doi = {10.1119/1.1990764},
URL = {https://doi.org/10.1119/1.1990764},
eprint = {https://doi.org/10.1119/1.1990764}
}
@article{Paquin2007,
   abstract = {In S. cerevisiae, the ASH1 {mRNA} is localized at the bud tip of late-anaphase cells, resulting in the exclusive sorting of Ash1p to the daughter cell nucleus. While the mechanism behind the localization of this transcript has been well studied, the regulation of its translation is still poorly understood. We now report that the RNA binding protein Khd1 interacts with the ASH1 {mRNA} localization element E1 and with the C-terminal domain of eIF4G1 to regulate the translation of this transcript. Khd1p reduces translation initiation on the ASH1 {mRNA} and diminishes Ash1p leakage into the mother cell nucleus. Furthermore, we show that the casein kinase Yck1p phosphorylates Khd1p at the plasma membrane, disrupting the Khd1p-RNA complex and releasing its translational repression on the ASH1 {mRNA}. This study reveals how, by linking {mRNA} sorting and translational activation, Khd1p and Yck1p regulate the spatiotemporal expression of a cell fate determinant. © 2007 Elsevier Inc. All rights reserved.},
   author = {Nicolas Paquin and Marie Ménade and Guillaume Poirier and Damiane Donato and Emmanuel Drouet and Pascal Chartrand},
   issn = {10972765},
   issue = {6},
   journal = {Molecular Cell},
   keywords = {RNA,SIGNALING},
   month = {6},
   pages = {795-809},
   publisher = {Elsevier},
   title = {Local Activation of Yeast {ASH1} {mRNA} Translation through Phosphorylation of {Khd1p} by the Casein Kinase {Yck1p}},
   volume = {26},
   year = {2007},
}

@article{Jansen2009,
   abstract = {Spatial control of gene expression, at the level of both transcription and translation, is critical for cellular differentiation [1-4]. In budding yeast, the conserved Ndr/warts kinase Cbk1 localizes to the new daughter cell, where it acts as a cell fate determinant. Cbk1 both induces a daughter-specific transcriptional program and promotes morphogenesis in a less well-defined role [5-8]. Cbk1 is essential in cells expressing functional Ssd1, an RNA-binding protein of unknown function [9-11]. We show here that Cbk1 inhibits Ssd1 in vivo. Loss of this regulation dramatically slows bud expansion, leading to highly aberrant cell wall organization at the site of cell growth. Ssd1 associates with specific {mRNA}s, a significant number of which encode cell wall remodeling proteins. Translation of these messages is rapidly and specifically suppressed when Cbk1 is inhibited; this suppression requires Ssd1. Transcription of several of these Ssd1-associated {mRNA}s is also regulated by Cbk1, indicating that the kinase controls both the transcription and translation of daughter-specific {mRNA}s. This work suggests a novel system by which cells coordinate localized expression of genes involved in processes critical for cell growth and division. © 2009 Elsevier Ltd. All rights reserved.},
   author = {Jaclyn M. Jansen and Antony G. Wanless and Christopher W. Seidel and Eric L. Weiss},
   issn = {09609822},
   issue = {24},
   journal = {Current Biology},
   keywords = {RNA,SIGNALING},
   month = {12},
   pages = {2114-2120},
   publisher = {Elsevier},
   title = {Cbk1 Regulation of the RNA-Binding Protein {Ssd1} Integrates Cell Fate with Translational Control},
   volume = {19},
   year = {2009},
}


@Article{Bayne2021,
author = {Bayne, Rosemary A and Jayachandran, Uma and Kasprowicz, Aleksandra and Bresson, Stefan and Tollervey, David and Wallace, Edward W J and Cook, Atlanta G},
title = "{Yeast Ssd1 is a non-enzymatic member of the RNase II family with an alternative RNA recognition site}",
journal = {Nucleic Acids Research},
volume = {50},
number = {5},
pages = {2923-2937},
year = {2021},
month = {07},
abstract = "{Ssd1, a conserved fungal RNA-binding protein, is important in stress responses, cell division and virulence. Ssd1 is closely related to Dis3L2 of the RNase II family of nucleases, but lacks catalytic activity and likely suppresses translation of bound mRNAs. Previous studies identified RNA motifs enriched in Ssd1-associated transcripts, yet the sequence requirements for Ssd1 binding are not defined. Here, we identify precise binding sites of Ssd1 on RNA using in vivo cross-linking and cDNA analysis. These sites are enriched in 5′ untranslated regions of a subset of mRNAs encoding cell wall proteins. We identified a conserved bipartite motif that binds Ssd1 with high affinity in vitro. Active RNase II enzymes have a characteristic, internal RNA binding path; the Ssd1 crystal structure at 1.9 Å resolution shows that remnants of regulatory sequences block this path. Instead, RNA binding activity has relocated to a conserved patch on the surface of the protein. Structure-guided mutations of this surface prevent Ssd1 from binding RNA in vitro and phenocopy Ssd1 deletion in vivo. These studies provide a new framework for understanding the function of a pleiotropic post-transcriptional regulator of gene expression and give insights into the evolution of regulatory and binding elements in the RNase II family.}",
issn = {0305-1048},
}


@article{Deng2008,
   abstract = {Translational repression during {mRNA} transport is essential for spatial restriction of protein production. In the yeast Saccharomyces cerevisae, silencing of ASH1 {mRNA} before it is localized to the bud cortex in late anaphase is critical for asymmetric segregation of Ash1p to the daughter cell nucleus. Puf6p, an ASH1 {mRNA}-binding protein, has been implicated in this process as a translational repressor, but the underlying mechanism is unknown. Here, we used yeast extract-based in vitro translation assays, which recapitulate translation and phosphorylation, to characterize the mechanism of Puf6p-mediated translational regulation. We report that Puf6p interferes with the conversion of the 48S complex to the 80S complex during initiation, and this repression by Puf6p is mediated through the general translation factor eIF5B (Fun12p in S. cerevisiae). Puf6p interacts with Fun12p via the PUF domain, and this interaction is RNA-dependent and essential for translational repression by Puf6p. This repression is relieved by phosphorylation of the N-terminal region of Puf6p mediated by protein kinase CK2 (casein kinase II). Inhibition of phosphorylation at Ser31, Ser34, and Ser35 of Puf6p increases its translational repression and results in ASH1 {mRNA} delocalization. Our results indicate that Puf6p suppresses the translation initiation of ASH1 {mRNA} via interaction with Fun12p during its transport, and this repression can be released by CK2 phosphorylation in the N-terminal region of Puf6p when the {mRNA} reaches the bud tip. © 2008 by Cold Spring Harbor Laboratory Press.},
   author = {Yingfeng Deng and Robert H. Singer and Wei Gu},
   issn = {08909369},
   issue = {8},
   journal = {Genes and Development},
   keywords = {RNA localization,RNA transport,Translational regulation},
   month = {4},
   pages = {1037-1050},
   publisher = {Cold Spring Harbor Laboratory Press},
   title = {Translation of {ASH1} {mRNA} is repressed by {Puf6p-Fun12p/eIF5B} interaction and released by {CK2} phosphorylation},
   volume = {22},
   year = {2008},
}


@article{Niednery2014,
   abstract = {Asymmetric, motor-protein dependent transport of {mRNA}s and subsequent localized translation is an important mechanism of gene regulation. Due to the high complexity of such motile particles, our mechanistic understanding of {mRNA} localization is limited. Over the last two decades, ASH1 {mRNA} localization in budding yeast has served as comparably simple and accessible model system. Recent advances have helped to draw an increasingly clear picture on the molecular mechanisms governing ASH1 {mRNA} localization from its co-transcriptional birth to its delivery at the site of destination. These new insights help to better understand the requirement of initial nuclear mRNPs, the molecular basis of specific {mRNA}-cargo recognition via cis-acting RNA elements, the different stages of RNP biogenesis and reorganization, as well as activation of the motile activity upon cargo binding. We discuss these aspects in context of published findings from other model organisms.},
   author = {Annika Niednery and Franziska T. Edelmanny and Dierk Niessing},
   issn = {15558584},
   issue = {8},
   journal = {RNA Biology},
   keywords = {ASH1 {mRNA},Endoplasmic reticulum,Loc1p,MRNP,Myo4p,Myosin,RNA-binding protein,She2p,She3p,{mRNA} localization},
   month = {8},
   pages = {998-1009},
   publisher = {Landes Bioscience},
   title = {Of social molecules: The interactive assembly of {ASH1} {mRNA}-transport complexes in yeast},
   volume = {11},
   year = {2014},
}

@article{Sil1996,
   abstract = {S. cerevisiae cells exhibit asymmetric determination of cell fate. Cell division yields a mother cell, which is competent to transcribe the HO gene and switch mating type, and a daughter cell, which is not. We have isolated a mutant in which daughters transcribe HO and switch mating type. This mutation defines the ASH1 gene (asymmetric synthesis of HO). Deletion and overexpression of ASH1 cause reciprocal cell fate transformations: in ash1Δ strains, daughters switch mating type as efficiently as mothers. Conversely, overexpression of ASH1 inhibits switching in mother cells. Ash1p has a zinc finger motif related to those of GATA transcriptional regulators. Ash1p is localized to the daughter nucleus in cells that have undergone nuclear division. Thus, Ash1p is a cell fate determinant that is asymmetrically localized to the daughter nucleus where it inhibits HO transcription.},
   author = {Anita Sil and Ira Herskowitz},
   issn = {00928674},
   issue = {5},
   journal = {Cell},
   month = {3},
   pages = {711-722},
   publisher = {Elsevier B.V.},
   title = {Identification of an asymmetrically localized determinant, {Ash1p}, required for lineage-specific transcription of the yeast {HO} gene},
   volume = {84},
   year = {1996},
}
@article{Berchowitz2013,
   abstract = {Production of haploid gametes from diploid progenitor cells is mediated by a specialized cell division, meiosis, where two divisions, meiosis I and II, follow a single S phase. Errors in progression from meiosis I to meiosis II lead to aneuploid and polyploid gametes, but the regulatory mechanisms controlling this transition are poorly understood. Here, we demonstrate that the conserved kinase Ime2 regulates the timing and order of the meiotic divisions by controlling translation. Ime2 coordinates translational activation of a cluster of genes at the meiosis I-meiosis II transition, including the critical determinant of the meiotic chromosome segregation pattern CLB3. We further show that Ime2 mediates translational control through the meiosis-specific RNA-binding protein Rim4. Rim4 inhibits translation of CLB3 during meiosis I by interacting with the 59 untranslated region (UTR) of CLB3. At the onset of meiosis II, Ime2 kinase activity rises and triggers a decrease in Rim4 protein levels, thereby alleviating translational repression. Our results elucidate a novel developmentally regulated translational control pathway that establishes the meiotic chromosome segregation pattern. © 2013 Berchowitz et al.},
   author = {Luke E. Berchowitz and Aaron S. Gajadhar and Folkert J. van Werven and Alexandra A. De Rosa and Mariya L. Samoylova and Gloria A. Brar and Yifeng Xu and Che Xiao and Bruce Futcher and Jonathan S. Weissman and Forest M. White and Angelika Amon},
   issn = {15495477},
   issue = {19},
   journal = {Genes and Development},
   keywords = {Cyclins,Gametogenesis,Kinase,Meiosis,RNA-binding protein,Translational control,Untranslated region},
   month = {10},
   pages = {2147-2163},
   publisher = {Cold Spring Harbor Laboratory Press},
   title = {A developmentally regulated translational control pathway establishes the meiotic chromosome segregation pattern},
   volume = {27},
   year = {2013},
}
@article{Olsen1999,
   abstract = {lin-4 encodes a small RNA that is complementary to sequences in the 3' untranslated region (UTR) of lin-14 {mRNA} and that acts to developmentally repress the accumulation of LIN-14 protein. This repression is essential for the proper timing of numerous events of Caenorhabditis elegans larval development. We have investigated the mechanism of lin-4 RNA action by examining the fate of lin-14 {mRNA} in vivo during the time that lin-4 RNA is expressed. Our results indicate that the rate of synthesis of lin-14 {mRNA}, its state of polyadenylation, its abundance in the cytoplasmic fraction, and its polysomal sedimentation profile do not change in response to the accumulation of lin-4 RNA. Our results indicate that association of lin-4 RNA with the 3' UTR of lin-14 {mRNA} permits normal biogenesis of lin-14 {mRNA}, and normal translational initiation, but inhibits step(s) thereafter, such as translational elongation and/or the release of stable LIN-14 protein.},
   author = {Philip H. Olsen and Victor Ambros},
   issn = {00121606},
   issue = {2},
   journal = {Developmental Biology},
   keywords = {C. elegans,Heterochronic genes,Lin-4 RNA,Polyribosomes,Translation},
   month = {12},
   pages = {671-680},
   publisher = {Academic Press Inc.},
   title = {The {lin-4} regulatory {RNA} controls developmental timing in {Caenorhabditis} elegans by blocking {LIN-14} protein synthesis after the initiation of translation},
   volume = {216},
   year = {1999},
}
@article{Lee1993,
   abstract = {lin-4 is essential for the normal temporal control of diverse postembryonic developmental events in C. elegans. lin-4 acts by negatively regulating the level of LIN-14 protein, creating a temporal decrease in LIN-14 protein starting in the first larval stage (L1). We have cloned the C. elegans lin-4 locus by chromosomal walking and transformation rescue. We used the C. elegans clone to isolate the gene from three other Caenorhabditis species; all four Caenorhabditis clones functionally rescue the lin-4 null allele of C. elegans. Comparison of the lin-4 genomic sequence from these four species and site-directed mutagenesis of potential open reading frames indicated that lin-4 does not encode a protein. Two small lin-4 transcripts of approximately 22 and 61 nt were identified in C. elegans and found to contain sequences complementary to a repeated sequence element in the 3′ untranslated region (UTR) of lin-14 {mRNA}, suggesting that lin-4 regulates lin-14 translation via an antisense RNA-RNA interaction. © 1993.},
   author = {Rosalind C. Lee and Rhonda L. Feinbaum and Victor Ambros},
   issn = {00928674},
   issue = {5},
   journal = {Cell},
   month = {12},
   pages = {843-854},
   publisher = {Cell},
   title = {The {C. elegans} heterochronic gene {lin-4} encodes small RNAs with antisense complementarity to {lin-14}},
   volume = {75},
   year = {1993},
}
@article{Wightman1993,
   abstract = {During C. elegans development, the temporal pattern of many cell lineages is specified by graded activity of the heterochronic gene Lin-14. Here we demonstrate that a temporal gradient in Lin-14 protein is generated posttranscriptionally by multiple elements in the lin-14 3′UTR that are regulated by the heterochronic gene Lin-4. The lin-14 3′UTR is both necessary and sufficient to confer lin-4-mediated posttranscriptional temporal regulation. The function of the lin-14 3′UTR is conserved between C. elegans and C. briggsae. Among the conserved sequences are seven elements that are each complementary to the lin-4 RNAs. A reporter gene bearing three of these elements shows partial temporal gradient activity. These data suggest a molecular mechanism for Lin-14p temporal gradient formation: the lin-4 RNAs base pair to sites in the lin-14 3′UTR to form multiple RNA duplexes that down-regulate lin-14 translation. © 1993.},
   author = {Bruce Wightman and Ilho Ha and Gary Ruvkun},
   issn = {00928674},
   issue = {5},
   journal = {Cell},
   month = {12},
   pages = {855-862},
   publisher = {Cell Press},
   title = {Posttranscriptional regulation of the heterochronic gene {lin-14} by {lin-4} mediates temporal pattern formation in {C. elegans}},
   volume = {75},
   year = {1993},
}



@article{Greener2021,
   abstract = {The expanding scale and inherent complexity of biological data have encouraged a growing use of machine learning in biology to build informative and predictive models of the underlying biological processes. All machine learning techniques fit models to data; however, the specific methods are quite varied and can at first glance seem bewildering. In this Review, we aim to provide readers with a gentle introduction to a few key machine learning techniques, including the most recently developed and widely used techniques involving deep neural networks. We describe how different techniques may be suited to specific types of biological data, and also discuss some best practices and points to consider when one is embarking on experiments involving machine learning. Some emerging directions in machine learning methodology are also&nbsp;discussed. Machine learning is becoming a widely used tool for the analysis of biological data. However, for experimentalists, proper use of machine learning methods can be challenging. This Review provides an overview of machine learning techniques and provides guidance on their applications in biology.},
   author = {Joe G. Greener and Shaun M. Kandathil and Lewis Moffat and David T. Jones},
   doi = {10.1038/s41580-021-00407-0},
   isbn = {0123456789},
   issn = {1471-0080},
   issue = {1},
   journal = {Nature Reviews Molecular Cell Biology 2021 23:1},
   keywords = {Bioinformatics,Computational biology and bioinformatics},
   month = {9},
   pages = {40-55},
   pmid = {34518686},
   publisher = {Nature Publishing Group},
   title = {A guide to machine learning for biologists},
   volume = {23},
   url = {https://www.nature.com/articles/s41580-021-00407-0},
   year = {2021},
}
@article{Kivioja2011,
   abstract = {Unique molecular identifiers (UMIs) associate distinct sequences with every DNA or RNA molecule and can be counted after amplification to quantify molecules in the original sample. Using UMIs, the authors obtain a digital karyotype of an individual with Down's syndrome and quantify mRNA in Drosophila melanogaster cells. Counting individual RNA or DNA molecules is difficult because they are hard to copy quantitatively for detection. To overcome this limitation, we applied unique molecular identifiers (UMIs), which make each molecule in a population distinct, to genome-scale human karyotyping and mRNA sequencing in Drosophila melanogaster. Use of this method can improve accuracy of almost any next-generation sequencing method, including chromatin immunoprecipitation–sequencing, genome assembly, diagnostics and manufacturing-process control and monitoring.},
   author = {Teemu Kivioja and Anna Vähärautio and Kasper Karlsson and Martin Bonke and Martin Enge and Sten Linnarsson and Jussi Taipale},
   doi = {10.1038/nmeth.1778},
   issn = {1548-7105},
   issue = {1},
   journal = {Nature Methods 2011 9:1},
   keywords = {Next,RNA,generation sequencing},
   month = {11},
   pages = {72-74},
   pmid = {22101854},
   publisher = {Nature Publishing Group},
   title = {Counting absolute numbers of molecules using unique molecular identifiers},
   volume = {9},
   url = {https://www.nature.com/articles/nmeth.1778},
   year = {2011},
}
@article{Garneau2007,
   abstract = {Turnover of mRNA is a key mechanism in regulated gene expression. In addition to turnover pathways for normal transcripts, there are surveillance mechanisms that degrade aberrant mRNAs. mRNA decay is regulated in response to cellular signals and coordinated with other mRNA-metabolic processes. When considering the control of gene expression, the focus has traditionally been on transcriptional regulation. Recently, however, the large contribution made by mRNA decay has become difficult to ignore. Large-scale analyses indicate that as many as half of all changes in the amounts of mRNA in some responses can be attributed to altered rates of decay. In this article, we discuss some of the mechanisms that are used by the cell to mediate and regulate this intriguing process.},
   author = {Nicole L. Garneau and Jeffrey Wilusz and Carol J. Wilusz},
   doi = {10.1038/nrm2104},
   issn = {1471-0080},
   issue = {2},
   journal = {Nature Reviews Molecular Cell Biology 2007 8:2},
   keywords = {Biochemistry,Cancer Research,Cell Biology,Developmental Biology,Life Sciences,Stem Cells,general},
   month = {2},
   pages = {113-126},
   pmid = {17245413},
   publisher = {Nature Publishing Group},
   title = {The highways and byways of mRNA decay},
   volume = {8},
   url = {https://www.nature.com/articles/nrm2104},
   year = {2007},
}
@article{Alberts2017,
   abstract = {As the amount of information in biology expands dramatically, it becomes increasingly important for textbooks to distill the vast amount of scientific knowledge into concise principles and enduring concepts.As with previous editions, Molecular Biology of the Cell, Sixth Edition accomplishes this goal with clear writing and beautiful illustrations. The Sixth Edition has been extensively revised and updated with the latest research in the field of cell biology, and it provides an exceptional framework for teaching and learning. 
The entire illustration program has been greatly enhanced.Protein structures better illustrate structure–function relationships, icons are simpler and more consistent within and between chapters, and micrographs have been refreshed and updated with newer, clearer, or better images. As a new feature, each chapter now contains intriguing openended questions highlighting “What We Don’t Know,” introducing students to challenging areas of future research. Updated end-of-chapter problems reflect new research discussed in the text, and these problems have been expanded to all chapters by adding questions on developmental biology, tissues and stem cells, pathogens, and the immune system.},
   author = {Bruce Alberts and Alexander Johnson and Julian Lewis and David Morgan and Martin Raff and Keith Roberts and Peter Walter},
   doi = {10.1201/9781315735368},
   isbn = {9781315735368},
   journal = {Molecular Biology of the Cell},
   month = {8},
   pages = {369-438},
   publisher = {W.W. Norton & Company},
   title = {Molecular Biology of the Cell},
   url = {https://www.taylorfrancis.com/books/mono/10.1201/9781315735368/molecular-biology-cell-bruce-alberts},
   year = {2015},
}